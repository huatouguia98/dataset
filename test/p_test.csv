commit_m,add_diff,delet_diff,edit_diff,refactor_type
Improvements to reactTest,"def testReactParallel(self): """""" Test that the ``react`` function works in parallel using Python multiprocessing",def testReactMultiproc(self):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
Native circuits (#905),"@data(False, True) def test_qsvm_binary_directly_statevector(self, use_circuits):",def test_qsvm_binary_directly_statevector(self):,ADD ADD KEEP ADD REP,Add Parameter
Finish rv_names -> rv_mode for dit.shannon.,"def conditional_entropy(dist, rvs_X, rvs_Y, rv_mode=None):","def conditional_entropy(dist, rvs_X, rvs_Y, rv_names=None):",KEEP KEEP KEEP KEEP REP,Rename Parameter
refactor method names removing 'get' prefix,"def all_words(self, documents):","def get_all_words(self, documents):",KEEP REP KEEP,Rename Method
Refactoring of the acquisition functions (WIP),"def evaluate(self, x, t=None):  y_m, y_s2, y_s = self.model.evaluate(x) return y_m - self.nu(t) * y_s   class UniformAcquisition(Acquisition):  def acquire(self, n_values, pending_locations=None, t=None): bounds = np.stack(self.model.bounds) return uniform(bounds[:,0], bounds[:,1] - bounds[:,0])\ .rvs(size=(n_values, self.model.input_dim)) ","def _eval(self, x, t):  y_m, y_s2, y_s = self.model.evaluate(x) return y_m - self.nu(t) * y_s  def acquire(self, n_values, pending_locations=None, t=None): ret = super(LCBSC, self).acquire(n_values, pending_locations) obj = lambda x : self._eval(x, t) minloc, val = stochastic_optimization(obj, self.model.bounds, self.opt_iterations) for i in range(self.n_values): ret[i] = minloc return ret  ",KEEP REP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP REP KEEP REP REP REP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
update based on review comments,"def __init__(self, hyperband, budgets, repetition_id):","def __init__(self, hyperband, budgets, frequency_id):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Add coalesce() and make marginal() call it.,"def parse_rvs(dist, rvs, rv_names=True, unique=True, sort=True):","def parse_rvs(dist, rvs, rv_names=True):",KEEP KEEP KEEP ADD ADD REP,Add Parameter
1043 Handle crossing paths in path follow (#1058),"def run(self, path, x, y, from_pt=None): """""" Run cross track error algorithm :return: cross-track-error and index of nearest point on the path """"""","def run(self, path, x, y):",KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Upgrade gym,"def step(self, action):","def _step(self, action):",KEEP REP KEEP,Rename Method
update HHL components to use Pluggables,def __init__(self): super().__init__(),"def __init__(self, configuration=None): super().__init__(configuration or self.QPE_CONFIGURATION.copy())",KEEP REP REP DEL DEL DEL,Remove Parameter
Core Update (#995),"def __init__(self, path, queue_size=8, fast_count=True, skip_list=None, count=None): logger.debug(""Initializing %s: (path: %s, queue_size: %s, fast_count: %s, skip_list: %s, "" ""count: %s)"", self.__class__.__name__, path, queue_size, fast_count, skip_list, count)","def __init__(self, path, queue_size=8, load_with_hash=False, fast_count=True, skip_list=None): logger.debug(""Initializing %s: (path: %s, queue_size: %s, load_with_hash: %s, "" ""fast_count: %s, skip_list: %s)"", self.__class__.__name__, path, queue_size, load_with_hash, fast_count, skip_list)",KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP REP REP REP REP KEEP KEEP KEEP KEEP REP REP REP,Rename Parameter
Only require email (not invite code),"def test__generate_code(self):  code = _generate_code('testing', 'user@domain.com')","def test_generate_code(self):  code = generate_code('testing', 'user@domain.com')",KEEP REP KEEP KEEP KEEP REP KEEP,Rename Method
[Angelica] Add examples to Sphinx docs.,def _get_training_label_array(self):,def get_training_label_array(self):,KEEP REP,Rename Method
Pass default index into cell extractors,"def extract_10_cells(cells, index): line_index, word, lemma, ctag, tag, feats, head, rel, _, _ = cells try: index = int(line_index) except ValueError:  pass","def extract_10_cells(cells): index, word, lemma, ctag, tag, feats, head, rel, _, _ = cells",KEEP ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD,Add Parameter
Fix st.file_uploader return value (#829),"def __init__( self, main_dg, sidebar_dg, widgets, target=None, name=None, uploaded_file_mgr=None, ):","def __init__(self, main_dg, sidebar_dg, widgets, target=None, name=None, file_manager=None):",KEEP ADD REP KEEP KEEP KEEP KEEP KEEP ADD REP,Rename Parameter
simplify harmonic circuit with just a constant. I don't think the circuit is correct at that point,"def __init__(self, num_qubits, const, x0, delta, tau):","def __init__(self, num_qubits, m, omega, x0, delta, tau):",KEEP KEEP KEEP REP DEL KEEP KEEP KEEP,Remove Parameter
add custom optimization bounds,"def fit(self, n_segments, x_c=None, y_c=None, bounds=None, **kwargs):","def fit(self, n_segments, x_c=None, y_c=None, **kwargs):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def words(self, fileids=None, categories=None):","def words(self, files=None, categories=None):",KEEP KEEP REP KEEP,Rename Parameter
Reorganize methods related parsing and generating InChI layers,def _parse_E_layer(auxinfo):,def parse_E_layer(auxinfo):,KEEP REP,Rename Method
[coordinates/feature reader iterator] truncation of CS moved to mditer exclusively,"def __init__(self, filename, trajlen, chunk=1000, **kwargs):","def __init__(self, filename, chunk=1000, **kwargs):",KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
Adds plot directive to validation curves documentation (#748),"def validation_curve_classifier_knn(path=""images/validation_curve_classifier_knn.png""): X, y = load_game() X = OneHotEncoder().fit_transform(X)","def validation_curve_classifier_alt(path=""images/validation_curve_classifier_alt.png""): data = pd.read_csv(os.path.join(FIXTURES, ""game"", ""game.csv""))  target = ""outcome"" features = [col for col in data.columns if col != target]  X = pd.get_dummies(data[features]) y = data[target]",KEEP REP REP REP DEL DEL DEL DEL DEL KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP KEEP REP DEL DEL DEL,Rename Method
Cleaning up repo. Improving correlation plot. Randomizing selection of samples used for normalization. Adding tests / assertions for toolbox settings. Set normalization scale factor to 1 in softmax layers. More compatibility-fixes for Keras 2. Small speed-up of spiking MaxPooling implementation. Changed online normalization scheme. Added feature to test consecutive samples without reset. Testing of specific samples now possible also with ImageDataGenerator. Added script to analyze statistics of DVS samples.,"def reset_spikevars(self, sample_idx):",def reset_spikevars(self):,KEEP ADD REP,Add Parameter
Implement Pandas styling in st.table (#796),"@parameterized.expand([ ('dataframe', 'data_frame'), ('table', 'table') ]) def test_add_styled_rows_to_unstyled_rows(self, element, proto):",def test_add_styled_rows_to_unstyled_rows(self):,ADD ADD ADD ADD ADD ADD KEEP ADD ADD REP,Add Parameter
[plots]: improved plots,"def _add_ck_subplot(cktest, ax, i, j, ipos=None, jpos=None, y01=True, units='steps', dt=1.):","def _add_ck_subplot(cktest, ax, i, j, y01=True):",KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP,Add Parameter
"- Moved several values to constants (e.g., NODE_RADIUS)","def arrange(self, arrange_algorithm=None):",def arrange(self):,KEEP ADD REP,Add Parameter
add chaos option to web controller,"def __init__(self, use_chaos=False):",def __init__(self):,KEEP ADD REP,Add Parameter
"Force file_watcher_type to ""poll"" for secrets.toml (#2968)","def get_file_watcher_class(watcher_type: str) -> Optional[FileWatcherType]: """"""Return the FileWatcher class that corresponds to the given watcher_type string. Acceptable values are 'auto', 'watchdog', 'poll' and 'none'. """"""","def get_file_watcher_class() -> Optional[FileWatcherType]: """"""Return the class to use for being notified of file changes, based on the",KEEP ADD REP KEEP KEEP KEEP KEEP ADD KEEP ADD ADD KEEP ADD ADD ADD REP REP REP REP REP REP REP REP REP REP,Add Parameter
Add type annotations for image (#4708),"def _normalize_to_bytes( data, width: int, output_format: OutputFormat, ) -> Tuple[bytes, str]:","def _normalize_to_bytes(data, width, output_format):",KEEP ADD ADD ADD ADD ADD ADD ADD REP REP REP,Change Return Type
pep8 + reformatting on pl196x.py,"def __init__(self, corpus_file, tagged, group_by_sent, group_by_para, tagset=None, head_len=0, textids=None):  self._tagged = tagged self._textids = textids  self._group_by_sent = group_by_sent self._group_by_para = group_by_para  StreamBackedCorpusView.__init__(self, corpus_file, startpos=head_len)  _pagesize = 4096  def read_block(self, stream): block = stream.readlines(self._pagesize) block = concat(block) while (block.count('<text id') > block.count('</text>')) \ or block.count('<text id') == 0: tmp = stream.readline() if len(tmp) <= 0: break block += tmp  block = block.replace('\n', '')  textids = TEXTID.findall(block) if self._textids: for tid in textids: if tid not in self._textids: beg = block.find(tid) - 1 end = block[beg:].find('</text>') + len('</text>') block = block[:beg] + block[beg + end:]  output = [] for para_str in PARA.findall(block): para = [] for sent_str in SENT.findall(para_str): if not self._tagged: sent = WORD.findall(sent_str) else: sent = list( map(self._parse_tag, TAGGEDWORD.findall(sent_str))) if self._group_by_sent: para.append(sent) else: para.extend(sent) if self._group_by_para: output.append(para) else: output.extend(para) return output  def _parse_tag(self, tag_word_tuple): (tag, word) = tag_word_tuple if tag.startswith('w'): tag = ANA.search(tag).group(1) else:   tag = TYPE.search(tag).group(1) return word, tag","def __init__(self, corpus_file, tagged, group_by_sent, group_by_para, tagset=None, headLen=0, textids=None): self._tagged = tagged self._textids = textids  self._group_by_sent = group_by_sent self._group_by_para = group_by_para  StreamBackedCorpusView.__init__(self, corpus_file, startpos=headLen)  _pagesize = 4096  def read_block(self, stream): block = stream.readlines(self._pagesize) block = concat(block) while (block.count('<text id') > block.count('</text>')) \ or block.count('<text id') == 0: tmp = stream.readline() if len(tmp) <= 0: break block += tmp  block = block.replace('\n','')  textids = TEXTID.findall(block) if self._textids: for tid in textids: if tid not in self._textids: beg = block.find(tid)-1 end = block[beg: ].find('</text>')+len('</text>') block = block[ :beg]+block[beg+end: ]  output = [] for para_str in PARA.findall(block): para = [] for sent_str in SENT.findall(para_str): if not self._tagged: sent = WORD.findall(sent_str) else: sent = list(map(self._parse_tag, TAGGEDWORD.findall(sent_str))) if self._group_by_sent: para.append(sent) else: para.extend(sent) if self._group_by_para: output.append(para) else: output.extend(para) return output  def _parse_tag(self, tag_word_tuple): (tag, word) = tag_word_tuple if tag.startswith('w'): tag = ANA.search(tag).group(1) else:  tag = TYPE.search(tag).group(1) return (word, tag)",KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP KEEP KEEP ADD REP REP KEEP KEEP ADD ADD REP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP REP REP,Rename Parameter
add unittest for LongDivision,def test_hhl_circuit_diagonal_2x2(self):,def test_hhl_diagonal_2x2_circuit(self):,KEEP REP,Rename Method
Added optional argument directed=True to all connectivity related api-functions. It is now possible to check connectivity using a undirected graph. This might become important for estimation with fixed stationary distribution,"def is_connected(C, directed=True): """"""Check if C is a countmatrix for a completely connected process.  Parameters ---------- C : scipy.sparse matrix Count matrix specifying edge weights. directed : bool, optional Whether to compute connected components for a directed or undirected graph. Default is True.  Returns ------- is_connected: bool True if C is countmatrix for a completely connected process False otherwise. ","def is_connected(C): """"""Return true if C is a countmatrix for a completely connected process.",KEEP REP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Add Parameter
Added weight normalization schedules,"def norm_parameters(parameters, activations, prev_scale_fac, idx):","def norm_parameters(parameters, activations, prev_scale_fac):",KEEP KEEP KEEP ADD REP,Add Parameter
rename: cnf_str -> dimacs_cnf,"def __init__(self, dimacs_cnf, mct_mode='basic'):","def __init__(self, cnf_str, mct_mode='basic'):",KEEP KEEP REP KEEP,Rename Parameter
a rename in examples (not a breaking change),"def _build_graph(self, inputs): image, edgemap = inputs","def _build_graph(self, input_vars): image, edgemap = input_vars",KEEP KEEP REP KEEP KEEP KEEP REP,Rename Parameter
#10 upravy zdroje pro fulltext-dspace a dspace_id identifikatory; drobne upravy a refactoringy,"def saveAsText(self, normalizeTfidf = False):","def saveAsMatrix(self, normalizeTfidf = False):",KEEP REP KEEP KEEP KEEP,Rename Method
Linting,"def reducer(var_x, kernel): shape = tf.shape(var_x) var_x = tf.reshape(var_x, shape=tf.concat([[-1], shape[-3:]], 0)) var_y = tf.nn.depthwise_conv2d(var_x, kernel, strides=[1, 1, 1, 1], padding='VALID') return tf.reshape(var_y, tf.concat([shape[:-3], tf.shape(var_y)[1:]], 0))","def reducer(x, kernel): shape = tf.shape(x) x = tf.reshape(x, shape=tf.concat([[-1], shape[-3:]], 0)) y = tf.nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1], padding='VALID') return tf.reshape(y, tf.concat([shape[:-3],tf.shape(y)[1:]], 0))",KEEP REP KEEP KEEP KEEP REP REP KEEP REP KEEP KEEP KEEP REP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP REP KEEP,Rename Parameter
"refactor create_U_layer, add documentation",def create_U_layer(mol):,def createULayer(mol):,KEEP REP,Rename Method
Add option to run thermo SA with Cantera,"def plot(self, data, top_species=10, top_sensitive_reactions=10, top_sensitive_species=10):","def plot(self, data, top_species=10, top_sensitive_reactions=10):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Add datastore tests,"def __init__(self, *args, **kwargs):","def __init__(self, path, *args, **kwargs):",KEEP KEEP DEL KEEP KEEP,Remove Parameter
Fix tests,"def test_try_resolve_silence_errors(self, capsys, code_conflict, conflicts):","def test_try_resolve_silence_errors(self, capsys, experiment_name_conflict, conflicts):",KEEP KEEP KEEP REP KEEP,Rename Parameter
rename resonance generation algorithms,def generateKekulizedResonanceIsomers(mol):,def getKekulizedResonanceIsomers(mol):,KEEP REP,Rename Method
quantumMechanics section added to input file for QM settings.,"def generateThermoData(self, database, thermoClass=MultiNASA, quantumMechanics=None):","def generateThermoData(self, database, thermoClass=MultiNASA):",KEEP KEEP KEEP ADD REP,Add Parameter
"Generate data with given headers, allow evaluation (TODO)","def create_training_data(self, t_file, da_file, candgen, train_arff_fname, header_file=None):","def create_training_data(self, t_file, da_file, candgen, train_arff_fname):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Add categorical family (#426),"def _prepare_prior(self, prior, kind):","def _prepare_prior(self, prior, type_):",KEEP KEEP KEEP REP,Rename Parameter
Validation without overlaps,"def train(self, fnames, train_trees, valid_trees=None, valid_tree_idxs=None):","def train(self, fnames, train_trees, valid_trees=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Initial refactoring of DependencyGraph.,"@classmethod def _normalize(cls, line):",@staticmethod def _normalize(line):,REP KEEP ADD REP,Add Parameter
[serial-interface] added model_name to access previous models.,"def load(filename, model_name='latest'):",def load(filename):,KEEP ADD REP,Add Parameter
Upgrade bigquery verison to 2.2.0 for aiplatform,"def test_project_with_connected_account_default_credentials(self, mock_access_token):","def test_project_with_connected_account_default_credentials(self, mock_access_token, ApiUrlMock): self._setup_mocks(ApiUrlMock)",KEEP KEEP REP DEL DEL,Remove Parameter
[plots] use axis instead of plt in NetworkPlot,"def __init__(self, A, pos=None, xpos=None, ypos=None, ax=None):","def __init__(self, A, pos=None, xpos=None, ypos=None):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
"Rename wrapper annotation in DeltaGenerator, for clarity. (#346)",def marshall_element(element):,def create_element(element):,KEEP REP,Rename Method
HHL implemented,"def init_args(self, error=None, C=None, negative_evals=False):","def init_args(self, error=None, C=None):",KEEP KEEP KEEP ADD REP,Add Parameter
Prepare version 0.6.1 (#211),def sample_means_summary(self):,def summary_sample_means(self):,KEEP REP,Rename Method
Prefix legacy and arrow commands with _ (#3563),def _arrow_bar_chart(,def arrow_bar_chart(,KEEP REP,Rename Method
implement,"def _recursive_compute_tokens_depth(current_depth, tokens): ",def _recursive_compute_tokens_depth(tokens):,KEEP ADD REP,Add Parameter
Reorientation as vertical/horizontal,"def __init__(self, data, orientation='horizontal', order='degree',","def __init__(self, data, vert=True, order='degree',",KEEP KEEP KEEP REP KEEP,Rename Parameter
Parameter name change num_topics and num_words in HdpModel and DtmModel to be consistent with LdaModel (#755),"def show_topics(self, num_topics=10, num_words=10, log=False, formatted=True):","def show_topics(self, topics=10, topn=10, log=False, formatted=True):",KEEP KEEP REP REP KEEP KEEP,Rename Parameter
Use fixtures for DatabaseView tests,"def test_invalid_attributes(self, create_db_instance):",def test_invalid_attributes(self):,KEEP ADD REP,Add Parameter
Bugfix: Gif Writer,"def _get_items(self) -> Dict[str, Optional[Dict[str, Union[tuple, dict]]]]:",def _get_items(self):,KEEP ADD ADD ADD ADD ADD REP,Change Return Type
[reporter] allow to override description in force_finish (#811),"def _progress_force_finish(self, stage=0, description=None):","def _progress_force_finish(self, stage=0):",KEEP KEEP ADD REP,Add Parameter
100% coverage of dit.convert,def test_DtoSD1():,def test_DtoSD():,KEEP REP,Rename Method
Make data transformation scripts' purposes and assumptions clearer,"def bucketize(buckets_root_path, training_path):","def main(buckets_root_path, training_path):",KEEP REP KEEP,Rename Method
[msm/estimation] Added sparse_return keyword,"def count_matrix_coo_mult(dtrajs, lag, sliding=True, sparse=True):","def count_matrix_coo_mult(dtrajs, lag, sliding=True):",KEEP KEEP KEEP ADD REP,Add Parameter
Renamed adjacent resonance generation methods,def generate_adj_lone_pair_radical_resonance_structures(mol):,def generate_lone_pair_radical_resonance_structures(mol):,KEEP REP,Rename Method
Add `ns_exponent` parameter to control the negative sampling distribution for `*2vec` models. Fix #2090 (#2093),"def __init__(self, max_vocab_size=None, min_count=5, sample=1e-3, sorted_vocab=True, null_word=0, ns_exponent=0.75):","def __init__(self, max_vocab_size=None, min_count=5, sample=1e-3, sorted_vocab=True, null_word=0):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
* Method supported_langs() re-named to langs().,"def _load_lang_ngrams(self, lang): ''' Load single n-gram language file given the ISO 639-3 language code and return its FreqDist '''  crubadan_code = self.iso_to_crubadan(lang) ngram_file = self.root + '/' + unicode(crubadan_code) + '-3grams.txt' import os.path  if not os.path.isfile(ngram_file): raise CrubadanError(""Could not find language n-gram file for ["" + lang + ""]."")  counts = FreqDist()  f = open(ngram_file, 'rU')  for line in f: data = line.decode('utf-8').split(u' ')  ngram = data[1].strip('\n') freq = int(data[0])  counts[ngram] = freq  return counts  def _load_all_ngrams(self): ''' Create a dictionary of every supported language mapping the ISO 639-3 language code to its corresponding n-gram FreqDist. The result can be accessed via ""all_lang_freq"" var '''   valid_files = [] for f in self.fileids(): m = re.search('(\w+)' + re.escape(""-3grams.txt""), f) if m: valid_files.append( m.group() )  for f in valid_files: ngram_file = self.root + '/' + f  import os.path  if os.path.isfile(ngram_file): crubadan_code = f.split('-')[0] iso_code = self.crubadan_to_iso(crubadan_code)  fd = self._load_lang_ngrams(iso_code) self.all_lang_freq[iso_code] = fd ","def load_lang_ngrams(self, lang): ''' Load single n-gram language file given the ISO 639-3 language code and return its FreqDist '''  crubadan_code = self.iso_to_crubadan(lang) ngram_file = self.root + '/' + unicode(crubadan_code) + '-3grams.txt' import os.path  if not os.path.isfile(ngram_file): raise CrubadanError(""Could not find language n-gram file for ["" + lang + ""]."")  counts = FreqDist()  f = open(ngram_file, 'rU')",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
allow evaluate in compound,"def _get_newpspace(self, evaluate=False):",def _get_newpspace(self):,KEEP ADD REP,Add Parameter
added the tagger API to wrap around corenlp,"def tag(self, sentence, tagtype='pos'): return self.tag_sents([sentence], tagtype)","def tag(self, sentence): return self.tag_sents([sentence])",KEEP KEEP ADD REP KEEP ADD REP,Add Parameter
#2 factored out word normalization: from dictionary to sources,"def doc2bow(self, document, allowUpdate = False):","def doc2bow(self, document, normalizeWord, allowUpdate = False):",KEEP KEEP KEEP DEL KEEP KEEP KEEP,Remove Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def tagged_paras(self, fileids=None, categories=None, simplify_tags=False):","def tagged_paras(self, files=None, categories=None, simplify_tags=False):",KEEP KEEP REP KEEP KEEP,Rename Parameter
nltk/corpus/reader/util.py,"def tagged_sents(self, documents=None): return self._pos_reader.tagged_sents(documents) def tagged_paras(self, documents=None): return self._pos_reader.tagged_paras(documents) def chunked_words(self, documents=None): return self._pos_reader.chunked_words(documents) def chunked_sents(self, documents=None): return self._pos_reader.chunked_sents(documents) def chunked_paras(self, documents=None): return self._pos_reader.chunked_paras(documents) def parsed_sents(self, documents=None): return self._mrg_reader.parsed_sents(documents)","def tagged_sents(self, items=None): return self._pos_reader.tagged_sents(items) def tagged_paras(self, items=None): return self._pos_reader.tagged_paras(items) def chunked_words(self, items=None): return self._pos_reader.chunked_words(items) def chunked_sents(self, items=None): return self._pos_reader.chunked_sents(items) def chunked_paras(self, items=None): return self._pos_reader.chunked_paras(items) def parsed_sents(self, items=None): return self._mrg_reader.parsed_sents(items)",KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP,Rename Parameter
Merge develop into i9e (#1012),def test_add_rows_works_when_new_name(self): ,def test_add_rows_fails_when_wrong_name(self):  all_methods = ( self._get_unnamed_data_methods() + self._get_named_data_methods()),KEEP REP DEL DEL DEL DEL DEL DEL DEL,Rename Method
Rename PrefetchData -> MultiProcessRunner,"def __init__(self, ds, buffer_size, num_reuse=1, shuffle_interval=None, nr_reuse=None):","def __init__(self, ds, buffer_size, nr_reuse=1, shuffle_interval=None):",KEEP KEEP KEEP KEEP ADD REP REP,Add Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def attachments(self, fileids): return concat([StreamBackedCorpusView(fileid, self._read_obj_block,","def attachments(self, files): return concat([StreamBackedCorpusView(filename, self._read_obj_block,",KEEP KEEP REP KEEP REP KEEP,Rename Parameter
setup.py: implement logging,def _install_conda_packages(self) -> None:,def install_conda_packages(self):,KEEP ADD ADD REP,Rename Method
Expand log terms into prime factors.,"def _eval_expand_log(self, deep=True, factor=False, **hints): from sympy import unpolarify, expand_log, factorint","def _eval_expand_log(self, deep=True, **hints): from sympy import unpolarify, expand_log",KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Fix penalized loss for multiscale decoders,"def PenalizedLoss(mask, loss_func, mask_prop=1.0, mask_scaling=1.0):  ","def PenalizedLoss(mask, loss_func, mask_prop=1.0):  ",KEEP KEEP KEEP ADD REP,Add Parameter
add internal study to decouple assessment and task,"def _display_plot(self, task, algorithm_exp_trials):","def _display_plot(self, algorithm_exp_trials):",KEEP KEEP ADD KEEP,Add Parameter
remove some deprecation in trainers,"def __init__(self, config):","def __init__(self, config, input_queue=None, average_cost=False):",KEEP KEEP REP DEL DEL,Remove Parameter
Better answer scoring,def process_questions(questions):,"def process_questions(questions, include_blacklisted = True):",KEEP REP DEL DEL DEL,Remove Parameter
Refactoring to (nearly) restore pressure dependence functionality in RMG.,"def update(self, reactionModel, database):","def update(self, reactionModel):",KEEP KEEP ADD REP,Add Parameter
Make testing/databaseTest.py unit tests PEP-8 compliant,"def general_check_siblings_for_parents(self, group_name, group):","def general_checkSiblingsForParents(self, group_name, group):",KEEP REP KEEP KEEP,Rename Method
param setter object attr,"def __init__(self, param, file_name):","def __init__(self, var_name, file_name):",KEEP KEEP REP KEEP,Rename Parameter
visual pipeline prototype closes #47,"def fit_transform_poof(self, X, y=None, outpath=None, **kwargs):","def fit_transform_poof(self, X, y=None, **kwargs):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_strip_tags(self):,def testStripTags(self):,KEEP REP,Rename Method
"ZeroProxy working, but janky and very incomplete.","def __init__(self, enqueue, id=None):","def __init__(self, queue, id=None):",KEEP KEEP REP KEEP,Rename Parameter
GUI Updates (#940),"def _set_context_handletype(self, command, action, variable): """""" Sets the correct handle type  based on context.  Parameters ---------- command: str The command that is being executed. Used to look up the context actions action: str The action that is being performed. Used to look up the correct file dialog variable: :class:`tkinter.StringVar` The variable associated with this file dialog """""" if self._contexts[command].get(variable, None) is not None: handletype = self._contexts[command][variable][action]","def set_context_handletype(self, command, action, variable):  if self.contexts[command].get(variable, None) is not None: handletype = self.contexts[command][variable][action]",KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP,Rename Method
user-specified starting values for HMMs,"def hmsm(dtrajs, nstate, lag=1, conv=0.01, maxiter=None, timeshift=None, TCinit = None, chiInit = None):","def hmsm(dtrajs, nstate, lag=1, conv=0.01, maxiter=None, timeshift=None):",KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD REP,Add Parameter
changed name,"def _inv_block(M, iszerofunc=_iszero):","def _inv_BLOCK(M, iszerofunc=_iszero):",KEEP REP KEEP,Rename Method
"鏂板gpu棰勬祴銆?""def __init__(self"," macbert_model_dir=config.macbert_model_dir):""","def __init__(self, macbert_model_dir=config.macbert_model_dir, device=-1):",REP DEL DEL DEL,Remove Parameter
write some more comments in dataflow,def _open_lmdb(self):,def open_lmdb(self):,KEEP REP,Rename Method
bugfixes,"def __init__(self, arguments, available_masks, samples, display, lock, trigger, config_tools, tk_vars): logger.debug(""Initializing %s: (arguments: '%s', available_masks: %s, samples: %s, "" ""display: %s, lock: %s, trigger: %s, config_tools: %s, tk_vars %s)"", self.__class__.__name__, arguments, available_masks, samples, display, lock, trigger, config_tools, tk_vars)","def __init__(self, arguments, samples, display, lock, trigger, config_tools, tk_vars): logger.debug(""Initializing %s: (arguments: '%s', samples: %s: display: %s, lock: %s,"" "" trigger: %s, config_tools: %s, tk_vars %s)"", self.__class__.__name__, arguments, samples, display, lock, trigger, config_tools, tk_vars)",KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD KEEP ADD REP REP KEEP KEEP REP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
use init term instead of create for methods,"def init_ultrasonic_sensor(self, port):","def assign_ultrasonic_sensor(self, port):",KEEP REP KEEP,Rename Method
update corrector with super.,def check_detector_initialized(self): if not self.initialized_detector: self.initialize_detector(),def check_initialized(self): if not self.initialized: self.initialize()  def initialize(self):,KEEP REP KEEP KEEP REP REP DEL DEL DEL,Rename Method
Add datastore tests,def get_tub_list(self): folders = next(os.walk(self.path))[1],"def get_tub_list(self,path): folders = next(os.walk(path))[1]",KEEP REP KEEP KEEP REP,Remove Parameter
misc clean-ups,"def _build_graph(self, inputs):","def _build_graph(self, input_vars):",KEEP KEEP REP,Rename Parameter
[#74] add confidence to mention level,"def form_predicted_annotations(self, class_id, aggregator_function=utils.qmath.mean):","def form_predicted_annotations(self, class_id):",KEEP KEEP ADD REP,Add Parameter
Make rmgpy/qm/* unit tests PEP-8 compliant,def test_load_thermo_data(self):,def testLoadThermoData(self):,KEEP REP,Rename Method
Make rmgpy/thermo/* unit tests PEP-8 compliant,def test_convert_nasa_to_wilhoit(self):,def test_convert_NASA_to_Wilhoit(self):,KEEP REP,Rename Method
Move meta-data fetches to resolve_config,"@pytest.mark.usefixtures(""clean_db"", ""null_db_instances"", ""with_user_tsirif"") def test_build_view_from(config_file, create_db_instance, exp_config, random_dt):","@pytest.mark.usefixtures(""clean_db"") @pytest.mark.usefixtures(""null_db_instances"") @pytest.mark.usefixtures(""with_user_tsirif"") def test_build_view_from(config_file, create_db_instance, exp_config):",REP REP REP KEEP KEEP KEEP ADD REP,Add Parameter
example dqn_cartpole added.,"def observe(self, observ, action, reward, terminal, next_observ, train_policy=True, feed_dict=None):","def observe(self, reward, terminal, train_policy=True, feed_dict=None):",KEEP KEEP ADD ADD KEEP KEEP ADD KEEP KEEP,Add Parameter
API Introduce a subset_size parameter (#69),"def _process_data(df, sort_by, sort_categories_by, subset_size, sum_over): df, agg = _aggregate_data(df, subset_size, sum_over)","def _process_data(df, sort_by, sort_categories_by, sum_over):",KEEP KEEP KEEP KEEP ADD KEEP ADD ADD ADD ADD ADD ADD,Add Parameter
[readers] re-named _create_iterator -> _create_iterator_impl,"def _create_iterator_impl(self, skip=0, chunk=0, stride=1, return_trajindex=True, cols=None):","def _create_iterator(self, skip=0, chunk=0, stride=1, return_trajindex=True, cols=None):",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Method
Speed improvements (#522) (#523),"def check_missing_dep():  global MISSING_PACKAGES, INSTALLED_PACKAGES, ENABLE_CUDA, IS_MACOS if ENABLE_CUDA and IS_MACOS: REQUIRED_PACKAGES.extend(MACOS_REQUIRED_PACKAGES) MISSING_PACKAGES = [] for pkg in REQUIRED_PACKAGES:","def Check_Missing_Dep(): global Missing_Packages, Installed_Packages, ENABLE_CUDA, Is_MacOS if ENABLE_CUDA and Is_MacOS: Required_Packages.extend(MacOS_Required_Packages) Missing_Packages = [] for pkg in Required_Packages:",KEEP ADD REP KEEP REP REP KEEP REP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP KEEP KEEP REP,Rename Method
[FasterRCNN] coco load instance mask as well,"def load(self, add_gt=True, add_mask=False):","def load(self, add_gt=True):",KEEP KEEP ADD REP,Add Parameter
tweak uniquifier,"def __call__(self, item, string=False):","def __call__(self, item):",KEEP KEEP ADD REP,Add Parameter
Add acquire_algorithm_lock to Experiment,"@pytest.mark.parametrize(""method"", read_only_methods) def test_read_only_methods(self, space, algorithm, method):","def test_read_only_methods(self, space, algorithm):",ADD ADD KEEP KEEP KEEP ADD REP,Add Parameter
fixed lidar parts,"def __init__(self, min_dist_rec_mm = 100.):","def __init__(self, min_dist_rec = 10.):",KEEP KEEP REP KEEP REP,Rename Parameter
"Update PDepReaction to add label, remove thirdBody attributes.","def __init__(self, index=-1, label='', reactants=None, products=None, network=None, kinetics=None, reversible=True, transitionState=None, duplicate=False, degeneracy=1, pairs=None): rmgpy.reaction.Reaction.__init__(self, index, label, reactants, products, kinetics, reversible, transitionState, duplicate, degeneracy, pairs)","def __init__(self, index=-1, reactants=None, products=None, network=None, kinetics=None, reversible=True, transitionState=None, thirdBody=False, duplicate=False, degeneracy=1, pairs=None): rmgpy.reaction.Reaction.__init__(self, index, reactants, products, kinetics, reversible, transitionState, thirdBody, duplicate, degeneracy, pairs)",KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP DEL KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP DEL KEEP KEEP KEEP,Rename Parameter
update imgaug,"def __init__(self, all_channel=True): self.all_channel = all_channel",def __init__(self):,KEEP ADD ADD ADD ADD REP,Add Parameter
Refactor Log.get_symmetry_properties,def get_symmetry_properties(self):,def get_optical_isomers_and_symmetry_number(self):,KEEP REP,Rename Method
ENH Save directly in bzip2 format,"def unpickle(fname, use_bzip2=False):",def unpickle(fname):,KEEP ADD REP,Add Parameter
Update to Machine Learning Package,"def __init__(self,m=[],remote=True,bfgs=True,explicit=True): if m==[]: self.m = GEKKO(remote=remote) else: self.m = m","def __init__(self,remote=True,bfgs=True,explicit=True): self.m = GEKKO(remote=remote)",KEEP ADD ADD REP KEEP KEEP KEEP ADD ADD ADD ADD,Add Parameter
[Angelica] Refactor scope of neuralnets classes and methods.,def _init_neural_net_model(self):,def init_neural_net_model(self):,KEEP REP,Rename Method
Lowest Common Hypernyms Change & Tests,"def lowest_common_hypernyms(self, other, simulate_root=False, use_min_depth=False): """""" Get a list of absolute lowest synset(s) that both synsets have as a hypernym. This method is an implementation of Ted Pedersen's ""Lowest Common Subsumer"" method from the Perl Wordnet module. It can return either ""self"" or ""other"" if they are a hypernym of the other.","def lowest_common_hypernyms(self, other, simulate_root=False, use_max_depth=False): """"""Get a list of absolute lowest synset(s) that both synsets have as a hypernym.  By default this is calculated by finding the shortest paths for all synsets that are hypernyms of both words, and returning that with the longest path.",KEEP KEEP KEEP KEEP ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD REP REP REP REP REP REP REP REP KEEP ADD REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP KEEP REP DEL,Rename Parameter
Started refactoring project.,def get_output(self):,"def get_output(self, train=False):",KEEP REP DEL,Remove Parameter
change to neural network based card recognition,"def get_table_cards_nn(self, h):","def get_table_cards(self, h):",KEEP REP KEEP,Rename Method
Rename parameter as to imitate sklearn.,def test_k_prototypes_sample_weight_all_but_one_zero(self):,def test_k_prototypes_sample_weights_all_but_one_zero(self):,KEEP REP,Rename Method
FIX from_memberships now returns Series when data is series-like (#55),"@pytest.mark.parametrize('data,ndim', [ ([1, 2, 3, 4], 1), (np.array([1, 2, 3, 4]), 1), (pd.Series([1, 2, 3, 4], name='foo'), 1), ([[1, 'a'], [2, 'b'], [3, 'c'], [4, 'd']], 2), (pd.DataFrame([[1, 'a'], [2, 'b'], [3, 'c'], [4, 'd']], columns=['foo', 'bar'], index=['q', 'r', 's', 't']), 2),","@pytest.mark.parametrize('data', [ [1, 2, 3, 4], np.array([1, 2, 3, 4]), pd.Series([1, 2, 3, 4], name='foo'), [[1, 'a'], [2, 'b'], [3, 'c'], [4, 'd']], pd.DataFrame([[1, 'a'], [2, 'b'], [3, 'c'], [4, 'd']], columns=['foo', 'bar'], index=['q', 'r', 's', 't']),",REP KEEP REP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD,Add Parameter
pattern.server: better error handling,"def __init__(self, status="""", message="""", traceback=""""):","def __init__(self, code, status="""", message="""", traceback=""""):",KEEP KEEP DEL KEEP KEEP KEEP,Remove Parameter
-,"def test_create_experiment_debug_mode( self, monkeypatch, tmp_path, benchmark_config_py ):","def test_create_experiment_debug_mode(self, tmp_path, benchmark_config_py):",KEEP ADD ADD REP KEEP ADD REP,Add Parameter
Added ability to change input channel size,"def vgg_pspnet(n_classes,  input_height=384, input_width=576, channels=3):","def vgg_pspnet(n_classes,  input_height=384, input_width=576):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_path_line_sentences(self):,def testPathLineSentences(self):,KEEP REP,Rename Method
Docs and refactoring (#126),"def _prepare_new_batch(self, batch_index): """"""ELFI calls this method before submitting a new batch with an increasing index `batch_index`. This is an optional method to override. Use this if you have a need do do preparations, e.g. in Bayesian optimization algorithm, the next acquisition points would be acquired here.  If you need provide values for certain nodes, you can do so by instantiating a pool for them in `__init__`. See e.g. BayesianOptimization for an example.  Parameters ---------- batch_index : int next batch_index to be submitted  Returns ------- None  """""" pass ","def prepare_new_batch(self, batch_index):",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
pass parameters to eigs.construct_inverse,"def construct_inverse(self, mode, circuit, inreg, outreg): """""" Construct the inverse eigenvalue estimation quantum circuit. Args: mode (str): 'vector' or 'circuit' circuit (QuantumCircuit): the quantum circuit to invert inreg (QuantumRegister): the input quantum register outreg (QuantumRegister): the output quantum register Returns: the QuantumCircuit object for the inverse eigenvalue estimation circuit. """"""","def construct_inverse(self, mode): ",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Remove custom support template for `orion info`,def format_refers(experiment): ,"def format_refers(experiment, templates=None): """"""Render a string for refers section  Parameters ---------- experiment: `orion.core.worker.experiment.Experiment` templates: dict templates for the title and `refers`. See `format_title` for more info.  """""" if templates is None: templates = dict()  refers_template = templates.get('refers', REFERS_TEMPLATE) ",KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
Can now specify ground-state energy explicitly in input file.,"def loadSpecies(label, geomLog, statesLog, extSymmetry, freqScaleFactor, linear, rotors, atoms, bonds, E0=None):","def loadSpecies(label, geomLog, statesLog, extSymmetry, freqScaleFactor, linear, rotors, atoms, bonds):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Added several more functions needed for unirxn module. Also many bugfixes.,"def applyApproximateMethod(self, T, P, Elist, method):","def applyApproximateMethod(self, T, P, method):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
update N-controlled rotation gates for Terra v0.7,"def apply_cnu3(self, theta, phi, lam, ctls, tgt, circuit):","def apply_cnu3(self, theta, phi, lam, ctls, tgt):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
fixing ipa bug (reported by Yang Ji) and updating dictionary code,"def __init__(self,lang,config,dir_dicts=None):","def __init__(self,lang,config):",KEEP REP,Add Parameter
stats.frv.py done,"def __new__(cls, dist, size, seed=None): return cls._sample_pymc3(dist, size, seed)","def __new__(cls, dist, size): return cls._sample_pymc3(dist, size)",KEEP KEEP KEEP ADD REP KEEP KEEP ADD REP,Add Parameter
Made sure that Proxy._proxy_connection_is_registered(...) was called *inside* Proxy.replace_connection_and_queue(...) since the former was a precondition of the latter.,"def _proxy_connection_is_registered(self, connection):","def proxy_connection_is_registered(self, connection):",KEEP REP KEEP,Rename Method
add temperature to convs2s.,"def infer_interactive(model_path, vocab_dir, arch, max_len, temperature): return infer(model_path, vocab_dir, arch, '-', max_len, temperature)","def infer_interactive(model_path, vocab_dir, arch, max_len): return infer(model_path, vocab_dir, arch, '-', max_len)",KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
"Reenables top-level function integration tests, adjust top-level functions to new setup.","def build_vocabulary(*texts, **vocab_kwargs):","def build_vocabulary(cutoff, *texts):",KEEP REP REP,Remove Parameter
Adapt codebase to new name Orion (#61),"def test_ordered_index(self, orion_db):","def test_ordered_index(self, moptdb):",KEEP KEEP REP,Rename Parameter
[#38] graph,"def __init__(self, csvfile, graphfile, init_counter=15):","def __init__(self, csvfile, graphfile):",KEEP KEEP KEEP ADD REP,Add Parameter
feat: add chunk-dim parameter,"def __init__(self, Fm, Gm=None, adapter=None, implementation_fwd=-1, implementation_bwd=-1, chunk_dim=1):","def __init__(self, Fm, Gm=None, adapter=None, implementation_fwd=-1, implementation_bwd=-1):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
- Renamed Classifier.probdist() -> Classifier.prob_classify(),"def prob_classify(self, featureset):","def probdist(self, featureset):",KEEP REP KEEP,Rename Method
transformed camelCase to snake_case test names (#3033),def test_no_training_c_format(self):,def testNoTrainingCFormat(self):,KEEP REP,Rename Method
Fixed a bug when analysing data from multiple species with missing genes (issues #28 & #29),"def readDataFromFiles(datafiles, delimiter='\t| |, |; |,|;', dtype=float, skiprows=1, data_na_filter=True, skipcolumns=1, returnSkipped=True, comm='","def readDataFromFiles(datafiles, delimiter='\t| |, |; |,|;', dtype=float, skiprows=1, skipcolumns=1, returnSkipped=True, comm='",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP,Add Parameter
rename for consistency,"def format_row(self, strictnesses=None):","def format(self, strictnesses=None):",KEEP REP KEEP,Rename Method
Interim commit before rewriting the INI simulator.,"def __init__(self, nb_filter, nb_row, nb_col, filter_flip=True, **kwargs):","def __init__(self, nb_filter, nb_row, nb_col, weights=None, border_mode='valid', subsample=(1, 1), filter_flip=True, **kwargs):",KEEP KEEP KEEP KEEP KEEP DEL DEL DEL DEL KEEP KEEP,Remove Parameter
almost done with the code,"def _post_process(self, nhops=10, style='entropy', minmax='min'):","def _post_process(self, nhops=10, style='entropy', minmax='min', callback=False):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
Base optimizer (#136),"def i_double_uparrow(d, inputs, output, niter=None, bound_u=None):","def i_double_uparrow(d, inputs, output, nhops=None, bound_u=None):",KEEP KEEP KEEP KEEP REP KEEP,Rename Parameter
Isolate properly DB in branching tests,def test_full_x_half_y(init_full_x_half_y):,"def test_full_x_half_y(init_full_x_half_y, create_db_instance):",KEEP REP DEL,Remove Parameter
[coordinates.datasource(s)] all readers support column selection in iterator creation,"def __init__(self, data_source, skip=0, chunk=0, stride=1, return_trajindex=False, cols=False):","def __init__(self, data_source, skip=0, chunk=0, stride=1, return_trajindex=False):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
"Make `exp_name` be non optional, if not in moptconfig",def default_options():,"def default_options(user, starttime):",KEEP REP DEL,Remove Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_experiment_wout_success_wout_ac(single_without_success, capsys):","def test_experiment_wout_success_wout_ac(clean_db, single_without_success, capsys):",KEEP REP DEL KEEP,Remove Parameter
parallelize benchmark experiment,"def __init__(self, name, algorithms, targets, storage=None):","def __init__(self, name, algorithms, targets):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Upgrade gym,def reset(self):,def _reset(self):,KEEP REP,Rename Method
delegate add_graph to pytorch (#595),"def add_graph_deprecated(self, model, input_to_model=None, verbose=False, profile_with_cuda=False, **kwargs):","def add_graph(self, model, input_to_model=None, verbose=False, profile_with_cuda=False, **kwargs):",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Method
[#42] config files,"def main(root_folder=""../../"", html_path='resources/IDP4_plain_html/pool', ann_path='resources/IDP4_members_json/pool/abojchevski'):",def main():,KEEP ADD ADD REP,Add Parameter
wip,"def write_to_hdf5(self, filename, group='/', data_set_prefix='', overwrite=False, stride=1, chunksize=None, h5_opt=None):","def write_to_hdf5(self, filename, group='/', data_set_prefix='', stride=1, chunksize=None, h5_opt=None):",KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP,Add Parameter
BOLFI + NUTS (#135),def test_Result():,def test_result_obj():,KEEP REP,Rename Method
Merged release-1-2-newtoken branch back into HEAD.,"def __init__(self, grammar, token, trace=0): self._token = token self._parser = SteppingRecursiveDescentParser(grammar, trace, LEAF='TEXT')","def __init__(self, grammar, text, trace=0): self._text = text self._parser = SteppingRecursiveDescentParser(grammar, trace)",KEEP KEEP KEEP REP KEEP REP KEEP REP KEEP KEEP KEEP ADD REP,Rename Parameter
"Implemented architectures that branch right after input layer (fixes Issue #10). Fixed bug in counting the number of operations of SNN. Operations are now reported as ""synaptic operations"" and ""neuron operations"" separately. Adapted plotting functions to properly handle data_format=='channels_last'. Fixed bug in SpikingMaxPool layer in case the data_format==""channels_last"". Updated documentation.","def plot_layer_summaries(plot_vars, config, path=None, data_format=None):","def plot_layer_summaries(plot_vars, config, path=None):",KEEP KEEP KEEP ADD REP,Add Parameter
Update OLED part to use non-deprecated library and add rotation (#871),"def __init__(self, rotation, auto_record_on_throttle=False): self.rotation = rotation self.oled = OLEDDisplay(self.rotation)","def __init__(self, bus_number, auto_record_on_throttle=False): self.bus_number = bus_number self.oled = OLEDDisplay(self.bus_number)",KEEP KEEP REP KEEP REP KEEP REP KEEP KEEP REP,Rename Parameter
add conv seq2seq pytorch model.,"def evaluate_seq2seq_model(model, data, device, loss_fn):","def evaluate_model(model, data, device, loss_fn):",KEEP REP KEEP KEEP KEEP,Rename Method
Rework Load Datasets Api (#501),def load_concrete(data_path=FIXTURES):,"def load_concrete(path='data', extract=True):",KEEP REP DEL,Remove Parameter
Rename set_uniform_distortion_probabilities to set_uniform_probabilities,def test_set_uniform_vacancy_probabilities_of_non_domain_values(self):,def test_set_uniform_distortion_probabilities_of_non_domain_values(self):,KEEP REP,Rename Method
fix lint,"def _one_body(edge_list, p_i, q_i, h1_pq):","def _one_body(edge_list, p, q, h1_pq):",KEEP KEEP REP REP KEEP,Rename Parameter
Singleton: `ttl` and `max_entries` support (#5821),"def __init__( self, key: str, max_entries: float, ttl_seconds: float, display_name: str, allow_widgets: bool = False, ):","def __init__(self, key: str, display_name: str, allow_widgets: bool = False):",KEEP ADD REP KEEP KEEP ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Rename PrefetchData -> MultiProcessRunner,"def __init__(self, ds, num_thread=None, map_func=None, buffer_size=200, strict=False, nr_thread=None):","def __init__(self, ds, nr_thread, map_func, buffer_size=200, strict=False):",KEEP KEEP KEEP REP REP KEEP ADD REP,Add Parameter
initial average result assessment,"def display(self, notebook=False):",def display(self):,KEEP ADD REP,Add Parameter
updated beam-search-decode; adding model templates,def _build_embedders(self):,def _get_embedders(self):,KEEP REP,Rename Method
Refactor data_utils,"def visualize_segmentation_dataset(images_path, segs_path, n_classes, do_augment=False, ignore_non_matching=False, no_show=False): try:  img_seg_pairs = get_pairs_from_paths(images_path, segs_path, ignore_non_matching=ignore_non_matching)   colors = class_colors  print(""Please press any key to display the next image"") for im_fn, seg_fn in img_seg_pairs: img = cv2.imread(im_fn) seg = cv2.imread(seg_fn) print(""Found the following classes in the segmentation image:"", np.unique(seg)) seg_img = _get_colored_segmentation_image(img, seg, colors, n_classes, do_augment=do_augment) print(""Please press any key to display the next image"") cv2.imshow(""img"", img) cv2.imshow(""seg_img"", seg_img) cv2.waitKey() except DataLoaderError as e: print(""Found error during data loading\n{0}"".format(str(e))) return False","def visualize_segmentation_dataset(images_path, segs_path, n_classes, do_augment=False):  img_seg_pairs = get_pairs_from_paths(images_path, segs_path)  colors = class_colors  print(""Press any key to navigate. "") for im_fn, seg_fn in img_seg_pairs:  img = cv2.imread(im_fn) seg = cv2.imread(seg_fn) print(""Found the following classes"", np.unique(seg))",KEEP KEEP KEEP KEEP ADD ADD ADD REP KEEP KEEP KEEP KEEP ADD REP KEEP ADD KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Add Parameter
improve flexibility for tokenizers,"def parse_tweets_set(filename, word_tokenizer, sent_tokenizer=None): ''' Parse training file and output train and test sets in (text, label) format. :param tokenizer: the tokenizer method that will be used to tokenize the text E.g. WordPunctTokenizer.tokenize BlanklineTokenizer.tokenize  N.B.: word_tokenize is actually a shortcut that combines PunktSentenceTokenizer and TreebankWordTokenizer().tokenize '''",def parse_tweets_set(filename='labeled_tweets.csv'): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
changed nltk.data.paths back to nltk.data.path as it's documented and a common environment variable name,"def __init__(self, _path):","def __init__(self, path):",KEEP KEEP REP,Rename Parameter
[Angelica] Add method to extract features from images in csv file,"def get_time_series_image_feature_array_from_directory(self, root_directory, vector=True):","def get_time_series_image_feature_array(self, root_directory, vector=True):",KEEP REP KEEP KEEP,Rename Method
[coor/api] deprecate chunk_size (now called chunksize).,"def pca(data=None, dim=-1, var_cutoff=0.95, stride=1, mean=None, skip=0, chunksize=None, **kwargs):","def pca(data=None, dim=-1, var_cutoff=0.95, stride=1, mean=None, skip=0, chunk_size=None):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Rename Parameter
"Change from qiskit._util to qiskit.util, remove remaining Aer from unit tests",def todo_test_set_packing_vqe(self):,def test_set_packing_vqe(self):,KEEP REP,Rename Method
Speed improvements (#522) (#523),"def __init__(self, image=None, x=None, w=None, y=None, h=None, landmarksXY=None):","def __init__(self, image=None, r=0, x=None, w=None, y=None, h=None, landmarksXY=None):",KEEP KEEP KEEP DEL KEEP KEEP KEEP KEEP KEEP,Remove Parameter
updated utils strip_* to allow list of tokens,"def strip_eos(str_, eos_token='<EOS>', is_token_list=False, compat=True):","def strip_eos(str_, eos_token='<EOS>', compat=True):",KEEP KEEP KEEP ADD KEEP,Add Parameter
Add support for span tokenization.,"def span_tokenize(self, s):","def span_tokenize(self, s, relative=False):",KEEP KEEP REP DEL,Remove Parameter
lmdb shouldn't reload keys,"def _set_keys(self, keys=None):","def open_lmdb(self, keys=None):",KEEP REP KEEP,Rename Method
store the trained results and reuse them for testing and prediction.,"def test(self, test_input, class_labels):","def test(self, theta_best, test_input, class_labels):",KEEP KEEP DEL KEEP KEEP,Remove Parameter
minor change to rpn and proposal layer on ANCHOR_RATIO,"def __init__(self, feat_stride, scales, ratios):","def __init__(self, feat_stride, scales):",KEEP KEEP KEEP ADD REP,Add Parameter
rename some variables in inferencerunner.,"def __init__(self, ds, infs, input_tensor_names=None):","def __init__(self, ds, infs, input_tensors=None):",KEEP KEEP KEEP KEEP REP,Rename Parameter
nltk/corpus/reader/util.py,"def entries(self, documents=None):","def entries(self, items=None):",KEEP KEEP REP,Rename Parameter
lib.alignments: improve re-extraction speed by 500%,def _check_folder(self): ,"def check_folder(self): """""" Check that the faces folder doesn't pre-exist and create """"""",KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
Improved landmark differentiability by heatmaps.,"def run_projection(self, input_images, masks, heatmaps, id_features, iterations=None):","def run_projection(self, input_images, masks, landmarks, id_features, iterations=None):",KEEP KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
Model augmenter (#171),"def prepare_new_batch(self, batch_index):","def _prepare_new_batch(self, batch_index):",KEEP REP KEEP,Rename Method
change underscore to  camel_case style in reduction package,def retrieveReactions():,def retrieve_reactions():,KEEP REP,Rename Method
[GSoC 2018] Multistream API for vocabulary building in *2vec (#2078),"def __init__(self, sentences=None, input_streams=None, sg=0, hs=0, size=100, alpha=0.025, window=5, min_count=5,","def __init__(self, sentences=None, sg=0, hs=0, size=100, alpha=0.025, window=5, min_count=5,",KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
Refactor.,"def initialize(self): for document in self.corpus: frequencies = {} for word in document: if word not in frequencies: frequencies[word] = 0 frequencies[word] += 1 self.f.append(frequencies)  for word, freq in iteritems(frequencies): if word not in self.df: self.df[word] = 0 self.df[word] += 1  for word, freq in iteritems(self.df): self.idf[word] = math.log(self.corpus_size-freq+0.5) - math.log(freq+0.5)  def get_score(self, document, index, average_idf):","def init(self): for doc in self.docs: tmp = {} for word in doc: if not word in tmp: tmp[word] = 0 tmp[word] += 1 self.f.append(tmp) for k, v in tmp.items(): if k not in self.df: self.df[k] = 0 self.df[k] += 1 for k, v in self.df.items(): self.idf[k] = math.log(self.D-v+0.5)-math.log(v+0.5)  def sim(self, doc, index, average_idf): EPSILON = 0.05 * average_idf",KEEP REP KEEP REP KEEP REP REP KEEP KEEP KEEP KEEP KEEP REP KEEP ADD KEEP DEL KEEP REP REP KEEP KEEP REP KEEP KEEP ADD REP KEEP REP REP KEEP REP KEEP REP KEEP KEEP KEEP REP KEEP KEEP REP KEEP KEEP ADD KEEP REP REP KEEP REP REP KEEP ADD ADD REP KEEP KEEP REP REP KEEP KEEP DEL DEL DEL DEL DEL,Rename Method
Optimize Data Augmentation (#881),"def _validate_samples(self, data): """""" Ensures that the total number of images within :attr:`images` is greater or equal to the selected :attr:`batchsize`. Raises an exception if this is not the case. """"""","def validate_samples(self, data): """""" Check the total number of images against batchsize and return the total number of images """"""",KEEP REP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD REP REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD REP REP REP REP KEEP,Rename Method
Support internal_update in BN,"def update_bn_ema(xn, batch_mean, batch_var, moving_mean, moving_var, decay, internal_update):","def update_bn_ema(xn, batch_mean, batch_var, moving_mean, moving_var, decay):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
fix docstring,"def two_body(edge_list, p, q, r, s, h2_pqrs):","def two_body(edge_matrix_indices, p, q, r, s, h2_pqrs):",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Parameter
feat: add chunk-dim parameter,"def __init__(self, Fm, Gm=None, implementation_fwd=-1, implementation_bwd=-1, chunk_dim=1):","def __init__(self, Fm, Gm=None, implementation_fwd=-1, implementation_bwd=-1):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Add CLI options for Executor backend,"def on_error(client, trial, error, worker_broken_trials):","def on_error(experiment_client, trial, error, worker_broken_trials):",KEEP REP KEEP KEEP KEEP,Rename Parameter
GUI Updates (#940),"def _add_command(name, func):","def add_command(name, func):",KEEP REP KEEP,Rename Method
bug fixes,"def create_new_strategy(self,strategy): result = self.mongodb.strategies.insert_one(strategy)  def modify_strategy(self, elementName, change): self.selected_strategy[elementName] = str(round(float(self.selected_strategy[elementName]) + change, 2)) self.modified = True  ","def save_strategy(self, strategy): result = self.mongodb.strategies.insert_one(strategy)",KEEP REP DEL KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
"Simplify tests suite, remove spy_phase and related functions (#886)","def suggest(self, num: int) -> list[Trial]:","def suggest(self, num: int) -> list[Trial] | None:",KEEP KEEP KEEP KEEP KEEP REP DEL DEL,Change Return Type
Added linear option to IsingToQuadraticProgram converter (#956),def test_ising_to_quadraticprogram_linear(self): ,def test_ising_to_quadraticprogram(self): ,KEEP REP,Rename Method
minor,def _convert_to_dependency_graph(sentence):,def convert_to_dependency_graph(sentence):,KEEP REP,Rename Method
Inferencer API renamed,def get_fetches(self):,def get_output_tensors(self):,KEEP REP,Rename Method
Made the methods more compatible among each other (same method signature),"def show_scatterplot(self, array, name, file_format="".png"", *args, **kwargs):","def show_scatterplot(self, x, y, name, file_format="".png"", *args, **kwargs):",KEEP KEEP REP DEL KEEP KEEP KEEP KEEP,Remove Parameter
Make Arkane unit tests PEP-8 compliant,def test_temperature_count(self):,def testTcount(self):,KEEP REP,Rename Method
addes skip to api,"def load(trajfiles, features=None, top=None, stride=1, chunk_size=None, skip=0, **kw):","def load(trajfiles, features=None, top=None, stride=1, chunk_size=None, **kw):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
[coor/featurizer] add periodic argument to angle derived features.,"def add_angles(self, indexes, deg=False, cossin=False, periodic=True):","def add_angles(self, indexes, deg=False, cossin=False):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Adding in test to check for writing and savaing the metal database,"def save_entry(self, path, entry):","def save_entry(self, f, entry):",KEEP KEEP REP KEEP,Rename Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def raw(self, fileids=None):","def raw(self, files=None):",KEEP KEEP REP,Rename Parameter
BugFix: Revert function renaming in Arkane output.py,"def visit_Str(self, node):","def visit_str(self, node):",KEEP REP KEEP,Rename Method
Smart Masks to Convert (#957),"def _set_actions(self): """""" Compile the requested actions to be performed into a list  Returns ------- list The list of :class:`PostProcessAction` to be performed """""" postprocess_items = self._get_items()",def set_actions(self):  postprocess_items = self.get_items(),KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP REP,Rename Method
Add expression support to Conflict object,"def __init__(self, status, dimension, expression):","def __init__(self, status, dimension):",KEEP KEEP KEEP ADD REP,Add Parameter
Adding minimum length validation.,"def summarize(text, ratio=0.2, word_count=None, split=False):","def summarize(text, ratio=0.2, words=None, split=False):",KEEP KEEP KEEP REP KEEP,Rename Parameter
Improve docstrings in `poly.numberfields.modules`.,"def __mod__(self, m):","def __mod__(self, a):",KEEP KEEP REP,Rename Parameter
Make rmgpy/thermo/* unit tests PEP-8 compliant,def test_fit_to_data(self):,def test_fitToData(self):,KEEP REP,Rename Method
gensim models show_topic/print_topic parameter num_words changed to topn to match other topic models. Backwards compatible (#1200),"def show_topic(self, topicid, topn=10, num_words=None): if num_words is not None:   logger.warning(""The parameter num_words for show_topic() would be deprecated in the updated version."") logger.warning(""Please use topn instead."") topn = num_words ","def show_topic(self, topicid, num_words=10):",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
make dataflow idiomatic python container objects (fix #869) (#872),def __len__(self): return self.ds.__len__(),def size(self): return self.ds.size(),KEEP REP KEEP REP,Rename Method
Align _match_potential_end_contexts with NLTK 3.6.5 sent_tokenize results,"def sentences_from_tokens( self, tokens: Iterator[PunktToken] ) -> Iterator[PunktToken]:","def sentences_from_tokens(self, tokens):",KEEP ADD ADD ADD ADD ADD REP REP,Change Return Type
Added opts for all display functions,"def __show_image(self, image, name=None, title=None, caption=None, env_appendix="""", opts={}, **kwargs):","def __show_image(self, image, name=None, title=None, caption=None, env_appendix="""", **kwargs):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Add comprehensive error message for branching err,"def test_init_w_version_from_parent_w_children(clean_db, monkeypatch, capsys):","def test_init_w_version_from_parent_w_children(clean_db, monkeypatch):",KEEP KEEP ADD REP,Add Parameter
w.i.p,"def do_test(self, dim, rank, test_partial_fit=False):","def do_test(self, dim, rank):",KEEP KEEP KEEP ADD REP,Add Parameter
make InputSource subclass methods private,def _setup_staging_areas(self):,def setup_staging_areas(self):,KEEP REP,Rename Method
added unittest for UciCorpus,"def test_save(self, corpus=[[(1, 1.0)], [], [(0, 0.5), (2, 1.0)], []]):","def test_save(self): corpus = [[(1, 1.0)], [], [(0, 0.5), (2, 1.0)], []] ",KEEP REP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP REP,Add Parameter
Handle race conditions during version increment,"def test_old_experiment_w_version(self, parent_version_config,","def test_old_experiment_w_version(self, create_db_instance, parent_version_config,",KEEP KEEP DEL KEEP,Remove Parameter
- Changed tree drawing algorithm to draw nodes centered over their,"def print_tree(tree, filename, textsize=None):","def print_tree(tree, filename):",KEEP KEEP ADD REP,Add Parameter
Feature/memory metrics (#4016),"def __init__( self,","def __init__( self, key: str, persist: Optional[str], max_entries: float, ttl: float",KEEP KEEP KEEP DEL DEL DEL DEL DEL DEL DEL DEL,Add Parameter
[0px] Make SHIFT-E work.,"def _enqueue_script_state_changed_message(self, new_script_state):","def _enqueue_script_state_changed_messages(self, new_script_state):",KEEP REP KEEP,Rename Method
[Angelica] Update README. Move tests from final open-source library to experiments.,"def _extract_training_images_from_path(self, csv_data_path, raw_dimensions, csv_image_col, csv_label_col):","def _extract_training_images_from_path(self, csv_data_path):",KEEP KEEP ADD ADD ADD REP,Add Parameter
Smart Training Implementation (#914),"@property def _image_size(self): """""" int: The training image size. Reads the first image in the training folder and returns the size. """""" image = read_image(self._images[""a""][0], raise_error=True) size = image.shape[0] logger.debug(""Training image size: %s"", size) return size  @property def _alignments_paths(self): """""" dict: The alignments paths for each of the source and destination faces. Key is the side, value is the path to the alignments file """""" alignments_paths = dict() for side in (""a"", ""b""): alignments_path = getattr(self._args, ""alignments_path_{}"".format(side)) if not alignments_path: image_path = getattr(self._args, ""input_{}"".format(side)) alignments_path = os.path.join(image_path, ""alignments.fsa"") alignments_paths[side] = alignments_path logger.debug(""Alignments paths: %s"", alignments_paths) return alignments_paths  def _set_timelapse(self): """""" Set time-lapse paths if requested.  Returns ------- dict The time-lapse keyword arguments for passing to the trainer  """""" if (not self._args.timelapse_input_a and not self._args.timelapse_input_b and not self._args.timelapse_output):","@property def image_size(self):  image = read_image(self.images[""a""][0], raise_error=True) size = image.shape[0] logger.debug(""Training image size: %s"", size) return size",KEEP KEEP ADD ADD ADD REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
Rename get_parser to add_subparser,def fetch_config(args):,def fetch_args(args):,KEEP REP,Rename Method
fixing few GDM issues. Not fully fixed yet though.,"def mseclustersfuzzy(X, B, donormalise=True, GDM=None):","def mseclustersfuzzy(X, B, donormalise=True):",KEEP KEEP KEEP ADD REP,Add Parameter
nltk/corpus/reader/util.py,"def tagged_words(self, documents=None, categories=None):","def tagged_words(self, items=None):",KEEP KEEP ADD REP,Add Parameter
Add option to allow zero-based node numbers in input (for zpar),"def __init__(self, tree_str=None, zero_based=False):","def __init__(self, tree_str=None):",KEEP KEEP ADD REP,Add Parameter
Fix unit tests,def todo_test_vqe_callback(self):,def test_vqe_callback(self):,KEEP REP,Rename Method
code style fixes,"def align(self, align_sent):","def align(self, alignSent):",KEEP KEEP REP,Rename Parameter
Removed camelcase on function and attribute names,"def documents(self, name=None): """"""","def Documents(self, name=None): '''",KEEP REP KEEP REP,Rename Method
setup.py: implement logging,"def __init__(self, environment: Environment, is_gui: bool = False) -> None:","def __init__(self, environment: Environment):",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD REP,Add Parameter
udpate docs,def _build_placeholder(self):,def build_placeholder(self):,KEEP REP,Rename Method
Make QGAN run primarily on circuits (#1341),"def get_output(self, quantum_instance, params=None, shots=None):","def get_output(self, quantum_instance, qc_state_in=None, params=None, shots=None):",KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
add eval with cn spell.,"def correct(sentence, verbose=False): sentence = uniform(sentence)",def correct(sentence): sentence = preprocess(sentence),KEEP ADD REP KEEP KEEP REP,Add Parameter
Switch all testing to pytest.,"@pytest.mark.parametrize('i', range(2, 10)) def test_J5(i):",def test_J5():,ADD ADD ADD KEEP REP,Add Parameter
Core Updates (#1015),"def _initialize(self, log=False): """""" Initialize the library that will be returning stats for the system's GPU(s). For Nvidia (on Linux and Windows) the library is `pynvml`. For Nvidia (on macOS) the library is `pynvx`. For AMD `plaidML` is used.  Parameters ---------- log: bool, optional Whether the class should output information to the logger. There may be occasions where the logger has not yet been set up when this class is queried. Attempting to log in these instances will raise an error. If GPU stats are being queried prior to the logger being available then this parameter should be set to ``False``. Otherwise set to ``True``. Default: ``False`` """""" if not self._initialized: if get_backend() == ""amd"": self._log(""debug"", ""AMD Detected. Using plaidMLStats"") loglevel = ""INFO"" if self._logger is None else self._logger.getEffectiveLevel() self._plaid = plaidlib(loglevel=loglevel, log=log)","def initialize(self, log=False):  if not self.initialized: if K.backend() == ""plaidml.keras.backend"": loglevel = ""INFO"" if self.logger: self.logger.debug(""plaidML Detected. Using plaidMLStats"") loglevel = self.logger.getEffectiveLevel() self.plaid = plaidlib(loglevel=loglevel, log=log)",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP REP REP KEEP ADD ADD ADD ADD ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD REP REP KEEP KEEP KEEP,Rename Method
Bug fixes,"def npr_op(distribution, size, input_dict):","def npr_op(distribution, size, input):",KEEP KEEP KEEP REP,Rename Parameter
feat(assumptions) : apply assumptions to rel query,"def is_neq(lhs, rhs):","def is_neq(lhs, rhs, getter=lambda x, key: getattr(x, 'is_%s' % key)):",KEEP KEEP REP DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
Allow setting target shape and scale,"def flow(self, dictionary, classes, target_shape=None, scale=None, ox=None, oy=None): return DictionaryIterator(dictionary, classes, target_shape, scale, ox, oy, self)","def flow(self, dictionary, classes): return DictionaryIterator(dictionary, classes, self)",KEEP KEEP KEEP ADD ADD ADD ADD REP KEEP KEEP KEEP ADD ADD ADD ADD KEEP,Add Parameter
Accept pre-tokenized references & hypothesis for METEOR calculation (#2822),"def _enum_wordnetsyn_match( enum_hypothesis_list: List[Tuple[int, str]], enum_reference_list: List[Tuple[int, str]], wordnet: WordNetCorpusReader = wordnet, ) -> Tuple[List[Tuple[int, int]], List[Tuple[int, str]], List[Tuple[int, str]]]:","def _enum_wordnetsyn_match(enum_hypothesis_list, enum_reference_list, wordnet=wordnet):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP,Change Return Type
Cache escape hatch (#616),"def _read_from_mem_cache(key, allow_output_mutation, hash_funcs):","def _read_from_mem_cache(key, allow_output_mutation):",KEEP KEEP ADD REP,Add Parameter
Clean setup.py (#468),"def check_installation(): if sys.version_info < MINIMUM_PYTHON_VERSION: version = ""."".join(str(i) for i in MINIMUM_PYTHON_VERSION)",def check_installation(rv): if sys.version_info < rv:,KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD REP,Remove Parameter
Added ability to change input channel size,"def fcn_8_mobilenet(n_classes,  input_height=416, input_width=608, channels=3):","def fcn_8_mobilenet(n_classes,  input_height=416, input_width=608):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Changed the node naming ui (#124),"def __init__(self, value, **kwargs):","def __init__(self, name, value, **kwargs):",KEEP KEEP DEL KEEP KEEP,Remove Parameter
[thermo] dtram API function passes use_wham flag to DTRAM class,"def dtram( ttrajs, dtrajs, bias, lag, maxiter=10000, maxerr=1.0E-15, err_out=0, lll_out=0, dt_traj='1 step', use_wham=False):","def dtram(ttrajs, dtrajs, bias, lag, maxiter=10000, maxerr=1.0E-15, err_out=0, lll_out=0, dt_traj='1 step'):",KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
better docstrings and slight reorganization,"def transform(self, terms, transformations, groupby=None, *args, **kwargs): ''' Apply one or more data transformations to one or more Terms. Args: terms (str, list): The label(s) of one or more Terms to transform. transformations (callable, str, list): The transformations to apply to the Terms. Can be a str (the name of a predefined method found in the transformations module, e.g., 'scale'), a callable that accepts an array as its first argument and returns another array, or a list of strings or callables. groupby (list): A list of variables to group the transformation(s) by. For example, passing transformations='scale', groupby=['subject'] would apply the scaling transformation separately to each subject. args, kwargs: Optional positional and keyword arguments passed to the transformation method. ''' for term in listify(terms): for trans in listify(transformations): self.X[term].transform(trans, groupby, *args, **kwargs)","def transform(self, terms, operations, groupby=None, *args, **kwargs): for t in listify(terms): for op in listify(operations): self.X[t].transform(op, groupby, *args, **kwargs)   def transformer(func): def wrapper(self, *args, **kwargs): self.transform(func.__name__, *args, **kwargs) return wrapper",KEEP KEEP KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP KEEP KEEP DEL DEL,Rename Parameter
More general resnet blocks.,"def preact_basicblock(l, ch_out, stride, preact):","def preresnet_basicblock(l, ch_out, stride, preact):",KEEP REP KEEP KEEP KEEP,Rename Method
use molfile in class fields as much as possible,"def __init__(self, molfile, qmtp, environ = os.environ.get(""RMG_workingDirectory"")): QMParser.__init__(self, molfile, qmtp, environ)","def __init__(self, name, directory, molecule, qmtp, environ = os.environ.get(""RMG_workingDirectory"")): QMParser.__init__(self, name, directory, molecule, qmtp, environ)",KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP,Remove Parameter
IBMQ v2 support,"def _enable_ibmq_account(url, token, proxies, hub, group, project):","def enable_ibmq_account(url, token, proxies, hub, group, project):",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Method
Made the methods more compatible among each other (same method signature),"def show_barplot(self, array, name, show=True, *args, **kwargs):","def show_barplot(self, data, name, show=True, *args, **kwargs):",KEEP KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
added command line interface,"def classify(self, instances): instances.classify(self.bestDecisionStump)  def verify(self, path): self.goldInstances = OneRGoldInstances(path) self.classify(self.goldInstances) return self.goldInstances.confusionMatrix() ","def classify(self, testInstances): testInstances.classify(self.bestDecisionStump)  ",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Rename Parameter
Make saveChemkingFile() able to handle core and edge of the model,"def saveChemkinFile(self, path, verbose_path, dictionaryPath=None, transportPath=None, saveEdgeSpecies=False):","def saveChemkinFile(self, path, verbose_path, dictionaryPath=None, transportPath=None):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Experiment browser flask app umstyling,def experiment_remove(base_dir):,def experiment_remove():,KEEP REP,Add Parameter
dictionary can be initialized with existing data.,"def __init__(self, documents=None, word2id=None, id2word=None): self.token2id = {}   self.id2token = {}   self.docFreq = {}   self.numDocs = 0   self.numPos = 0    if word2id and id2word: self.token2id = word2id self.id2token = id2word elif documents:","def __init__(self, documents = None): self.token2id = {}  self.docFreq = {}  self.numDocs = 0  self.numPos = 0   if documents:",KEEP KEEP REP REP REP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP,Add Parameter
Align Eyes Horizontally After Umeyama + Blur Detection (#242),"def extract(self, image, face, size, align_eyes): alignment = get_align_mat(face, size, align_eyes) extracted = self.transform(image, alignment, size, 48) return extracted, alignment","def extract(self, image, face, size): alignment = get_align_mat( face ) return self.transform( image, alignment, size, 48 )",KEEP KEEP KEEP KEEP ADD REP KEEP KEEP REP REP REP REP REP REP KEEP KEEP ADD ADD REP REP,Add Parameter
[coordinates] add skip parameters to Estimators to allow to skip inital n_frames.,"def __init__(self, dim=-1, var_cutoff=0.95, mean=None, stride=1, skip=0):","def __init__(self, dim=-1, var_cutoff=0.95, mean=None, stride=1):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Force CONFIGURATION static prop for pluggable classes,def __init__(self): super().__init__(self.CONFIGURATION.copy()),"def __init__(self, configuration=None): super().__init__(configuration or self.SPSA_CONFIGURATION.copy())",KEEP REP REP DEL DEL DEL,Remove Parameter
Install latest version of nbconvert to fix Jinja issue. (#1141),def test_nbconvert_to_notebook(self):,def test_nbconvert(self):,KEEP REP,Rename Method
Implements quartic approx. to log-likelihood and cubic approx. to b = f(r),"def _scale_intercept(self, term, sd_corr):","def _scale_intercept(self, term, value):",KEEP KEEP KEEP REP,Rename Parameter
nltk/corpus/reader/util.py,"def words(self, documents=None):","def words(self, items=None):",KEEP KEEP REP,Rename Parameter
Smart Extract code review,"def load_aligned(self, image, size=256, dtype=None):","def load_aligned(self, image, size=256, coverage_ratio=1.0, dtype=None):",KEEP KEEP KEEP KEEP DEL KEEP,Remove Parameter
Huge round of changes!,"def __hardparse(self,meterPos,pos_i=None,slot_i=None,num_slots=None,all_positions=None):","def __hardparse(self,meterPos):",KEEP REP,Add Parameter
added gym RL examples,def _append_output_layer(self):,"def _append_output_layer(self, action_space):",KEEP REP DEL,Remove Parameter
Continuing to finalise the parse->read name change,"def read_pcfg(input, encoding=None):","def parse_pcfg(input, encoding=None):",KEEP REP KEEP,Rename Method
"[cmsm] cleanup, fix tests, update authors",def test_indices_remapping_sample_by_dist(self):,def test_indices_remapping(self):,KEEP REP,Rename Method
"wip, works for classical algorithms","def __init__(self, training_dataset, test_dataset=None, datapoints=None, gamma=None, multiclass_extension=None): super().__init__()","def init_args(self, training_dataset, test_dataset, datapoints, gamma, multiclass_extension=None): ",KEEP REP KEEP REP REP REP KEEP ADD,Rename Method
Make OptimizationResult read-only (all parameters of the constructor become mandatory) (#1131),"@property def variable_names(self) -> List[str]: """"""Returns the list of variable names of the optimization problem.  Returns: The list of variable names of the optimization problem. """""" return self._variable_names","@property def variable_names(self) -> Optional[List[str]]: """"""Returns the list of variable names under optimization.",KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Change Return Type
Bugfix: Gif Writer,def _load_extractor(self) -> Optional[Extractor]:,def _load_extractor(self):,KEEP ADD ADD REP,Change Return Type
rename params,"def ccx_v_chain(self, control_qubits, target_qubit, ancillary_qubits):","def ccx_v_chain(self, q_controls, q_ancilla, q_target):",KEEP KEEP REP REP REP,Rename Parameter
flake8 bootstrap/lib,"def __new__(cls, source=None, arguments_callback=None, lock=False, run_parser=True):","def __new__(self, source=None, arguments_callback=None, lock=False, run_parser=True):",KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
Fix serving tests,"def test_trials_by_from_specific_version_by_status_with_ancestors(self, client, ephemeral_storage):","def test_trials_by_from_specific_version_by_status_with_ancestors(self, client):",KEEP KEEP ADD REP,Add Parameter
Update arlstem.py,"def fem2masc(self, token): """""" transform the word from the feminine form to the masculine form """""" if(token.endswith('\u0629') and len(token)>3): token = token[:-1] return token  def plur2sing(self, token): """""" transform the word from the plural form to the singular form """""" if(len(token) > 4): for ps2 in self.pl_si2: if(token.endswith(ps2)): token = token[:-2] return token if(len(token) > 5): for ps3 in self.pl_si3: if(token.endswith(ps3)): token = token[:-3] return token if(len(token)>3 and token.endswith('\u0627\u062A')): token = token[:-2] return token if(len(token)>3 and token.startswith('\u0627') and token[2]=='\u0627'): token = token[0:2] + token[3:] return token if(len(token)>4 and token.startswith('\u0627') and token[-2]=='\u0627'): token = token[1:] token = token[:-2] + token[-1] return token  def verb(self, token): """""" stem the verb prefixes and suffixes or both """""" vb = self.verb_t1(token) if vb == None: vb = self.verb_t2(token) if vb == None: vb = self.verb_t3(token) if vb == None: vb = self.verb_t4(token) if vb == None: vb = self.verb_t5(token) if vb != None: token = vb return token else: return token else: token = vb return token else: token = vb return token else: token = vb return token else: token = vb return token  def verb_t1(self, token): """""" stem the present prefixes and suffixes """""" if(len(token)>5 and token.startswith('\u062A')):  for s2 in self.pl_si2: if(token.endswith(s2)): token = token[1:] token = token[:-2] return token if(len(token)>5 and token.startswith('\u064A')):  for s2 in self.verb_su2: if(token.endswith(s2)): token = token[1:] token = token[:-2] return token if(len(token)>4 and token.startswith('\u0627')):   if(len(token)>5 and token.endswith('\u0648\u0627')): token = token[1:] token = token[:-2] return token  if(token.endswith('\u064A')): token = token[1:] token = token[:-1] return token  if(token.endswith('\u0627')): token = token[1:] token = token[:-1] return token  if(token.endswith('\u0646')): token = token[1:] token = token[:-1] return token  if( len(token)>4 and token.startswith('\u064A') and token.endswith('\u0646') ): token = token[1:] token = token[:-1] return token  if( len(token)>4 and token.startswith('\u062A') and token.endswith('\u0646') ): token = token[1:] token = token[:-1] return token  def verb_t2(self, token): """""" stem the future prefixes and suffixes """""" if(len(token) > 6): for s2 in self.pl_si2:  if( token.startswith(self.verb_pr2[0]) and token.endswith(s2) ): token = token[2:] token = token[:-2] return token  if( token.startswith(self.verb_pr2[1]) and token.endswith(self.pl_si2[0]) ): token = token[2:] token = token[:-2] return token  if( token.startswith(self.verb_pr2[1]) and token.endswith(self.pl_si2[2]) ): token = token[2:] token = token[:-2] return token  if( len(token)>5 and token.startswith(self.verb_pr2[0]) and token.endswith('\u0646') ): token = token[2:] token = token[:-1] return token  if( len(token)>5 and token.startswith(self.verb_pr2[1]) and token.endswith('\u0646') ): token = token[2:] token = token[:-1] return token  def verb_t3(self, token): """""" stem the present suffixes """""" if(len(token) > 5): for su3 in self.verb_suf3: if(token.endswith(su3)): token = token[:-3] return token if(len(token) > 4): for su2 in self.verb_suf2: if(token.endswith(su2)): token = token[:-2] return token if(len(token) > 3): for su1 in self.verb_suf1: if(token.endswith(su1)): token = token[:-1] return token","def __fem2masc(self, token): """""" transform the word from the feminine form to the masculine form """""" if(token.endswith('\u0629') and len(token) > 3):  token = token[:-1] return token  def __plur2sing(self, token): """""" transform the word from the plural form to the singular form """""" if(len(token) > 4): for ps2 in self.pl_si2: if(token.endswith(ps2)): token = token[:-2] return token if(len(token) > 5): for ps3 in self.pl_si3: if(token.endswith(ps3)): token = token[:-3] return token if(len(token) > 3 and token.endswith('\u0627\u062A')): token = token[:-2] return token if(len(token) > 3 and token.startswith('\u0627') and token[2]=='\u0627'): token = token[0:2] + token[3:] return token if(len(token) > 4 and token.startswith('\u0627') and token[-2]=='\u0627'): token = token[1:] token = token[:-2] + token[-1] return token  def __verb(self, token): """""" stem the verb prefixes and suffixes or both """""" vb = self.__verb_t1(token) if vb == None: vb = self.__verb_t2(token) if vb == None: vb = self.__verb_t3(token) if vb == None: vb = self.__verb_t4(token) if vb == None: vb = self.__verb_t5(token) if vb != None: token = vb return token else: return token else: token = vb return token else: token = vb return token else: token = vb return token else: token = vb return token  def __verb_t1(self, token): """""" stem the present prefixes and suffixes """""" if(len(token) > 5 and token.startswith('\u062A')):  for s2 in self.pl_si2: if(token.endswith(s2)): token = token[1:] token = token[:-2] return token if(len(token) > 5 and token.startswith('\u064A')):  for s2 in self.verb_su2: if(token.endswith(s2)): token = token[1:] token = token[:-2] return token if(len(token) > 4 and token.startswith('\u0627')):  if(len(token) > 5 and token.endswith('\u0648\u0627')):  token = token[1:] token = token[:-2] return token if(token.endswith('\u064A')):  token = token[1:] token = token[:-1] return token if(token.endswith('\u0627')):  token = token[1:] token = token[:-1] return token if(token.endswith('\u0646')):  token = token[1:] token = token[:-1] return token if(len(token) > 4 and token.startswith('\u064A') and token.endswith('\u0646')):  token = token[1:] token = token[:-1] return token if(len(token) > 4 and token.startswith('\u062A') and token.endswith('\u0646')):  token = token[1:] token = token[:-1] return token  def __verb_t2(self, token): """""" stem the future prefixes and suffixes """""" if(len(token) > 6): for s2 in self.pl_si2: if(token.startswith(self.verb_pr2[0]) and token.endswith(s2)):  token = token[2:] token = token[:-2] return token if(token.startswith(self.verb_pr2[1]) and token.endswith(self.pl_si2[0])):  token = token[2:] token = token[:-2] return token if(token.startswith(self.verb_pr2[1]) and token.endswith(self.pl_si2[2])):  token = token[2:] token = token[:-2] return token if(len(token) > 5 and token.startswith(self.verb_pr2[0]) and token.endswith('\u0646')):  token = token[2:] token = token[:-1] return token if(len(token) > 5 and token.startswith(self.verb_pr2[1]) and token.endswith('\u0646')):  token = token[2:] token = token[:-1] return token  def __verb_t3(self, token): """""" stem the present suffixes """""" if(len(token) > 5): for su3 in self.verb_suf3: if(token.endswith(su3)): token = token[:-3] return token if(len(token) > 4): for su2 in self.verb_suf2: if(token.endswith(su2)): token = token[:-2] return token if(len(token) > 3): for su1 in self.verb_suf1: if(token.endswith(su1)): token = token[:-1] return token",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP REP REP DEL KEEP KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
Add `MIMOFeedback` class.,"def _eval_rewrite_as_TransferFunction(self, num, den, ftype, **kwargs):","def _eval_rewrite_as_TransferFunction(self, num, den, **kwargs):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Rename and refactor `Report` machinery (#4141),def get_module_paths(module: types.ModuleType) -> Set[str]:,def get_module_paths(module: types.ModuleType) -> t.Set[str]:,KEEP KEEP KEEP KEEP REP,Change Return Type
allow user-defined normalization in TfidfModel,"def __getitem__(self, bow, eps=1e-12):","def __getitem__(self, bow):",KEEP KEEP ADD REP,Add Parameter
update seq2seq_attention model for class.,"def padding(x, char2id):",def padding(x):,KEEP ADD REP,Add Parameter
bug fix and update the test value with Terra 0.7,"def train(self, data, labels, quantum_device=None): """"""Train the models, and save results. ","def train(self, data, labels): """"""Train the models, and save results",KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP REP,Add Parameter
restructure and clean,"def classify(self, instancesfile):","def tag(self, instancesfile):",KEEP REP KEEP,Rename Method
Modified  so that the ignore argument is explicitly mentioned in the arguments. Also added a bit more documentation to make it clear how the parameter should be used.,"def save(self, fname, ignore=['state', 'dispatcher'], *args, **kwargs):","def save(self, fname, *args, **kwargs):",KEEP KEEP KEEP ADD ADD KEEP KEEP,Add Parameter
Modifications to PrecisionRecall Curve Visualizer (#686),"def precision_recall_curve(model, X, y, X_test=None, y_test=None, ax=None, train_size=0.8,","def precision_recall_curve(model, X, y, ax=None, train_size=0.8,",KEEP KEEP KEEP KEEP ADD ADD KEEP KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_too_short_binary_word2vec_format(self):,def testTooShortBinaryWord2VecFormat(self):,KEEP REP,Rename Method
Updates model selection tutorial with new datasets module (#818),"def visualize_model(X, y, estimator, path, **kwargs):","def visual_model_selection(X, y, estimator, path):",KEEP REP KEEP KEEP ADD REP,Rename Method
"Edits to the docstrings, examples, variable names, and pep8.","def _alignment_rotation(self, parent, child):","def _align_axis(self, parent, child):",KEEP REP KEEP KEEP,Rename Method
Remove unittest dependency and test fixtures (#904),"def test_get_alphas_param(self, model):",def test_get_alphas_param(self):,KEEP ADD REP,Add Parameter
Added 4 probability distributions:,def __repr__(self):,def __str__(self):,KEEP REP,Rename Method
Adapt codebase to new name Orion (#61),"def test_insert_many(self, database, orion_db):","def test_insert_many(self, database, moptdb):",KEEP KEEP KEEP REP,Rename Parameter
Fix failing unit tests by switching to Aer,def test_real_eval(self):,def todo_test_real_eval(self):,KEEP REP,Rename Method
- Added proper unicode support to call corpus readers.  Corpus reader,"def __init__(self, delimiter=' ', encoding=None):","def __init__(self, delimiter=' '):",KEEP KEEP KEEP ADD REP,Add Parameter
Allow chemkin parser to read non-RMG generated chemkin files.,"def readReactionComments(reaction, comments, read = True):","def readReactionComments(reaction, comments):",KEEP KEEP ADD ADD ADD REP,Add Parameter
Pass default index into cell extractors,"def extract_4_cells(cells, index):",def extract_4_cells(cells):,KEEP ADD REP,Add Parameter
change underscore to  camel_case style in reduction package,"def computeObservables(targets, reactionModel, reactionSystem, atol, rtol):","def compute_observables(targets, reactionModel, reactionSystem, atol, rtol):",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
allow the user to not include the rel type in the string map if desired,"def map(self, entity_map_fun, prefix_with_rel_type=True):","def map(self, entity_map_fun):",KEEP KEEP ADD REP,Add Parameter
make all loss layers training phase dependent,"def call(self, inputs, training=None, **kwargs): output, target, labels_target = inputs","def call(self, inputs, **kwargs): output, target = inputs",KEEP KEEP KEEP ADD KEEP KEEP ADD REP KEEP KEEP,Add Parameter
Interim commit after rewriting the INI simulator.,@property def class_name(self):,def get_name(self):,ADD KEEP REP,Rename Method
gamma_init in InstanceNorm & LayerNorm,"def layer_func(*args, **kwargs):","def f(*args, **kwargs):",KEEP REP KEEP,Rename Method
Smart Masks to Convert (#957),"def _load(self, *args):   """""" Load frames from disk.  In a background thread: * Loads frames from disk. * Discards or passes through cli selected skipped frames * Pairs the frame with its :class:`~lib.faces_detect.DetectedFace` objects * Performs any pre-processing actions * Puts the frame and detected faces to the load queue """"""","def load(self, *args):   ",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
reorganization of transformer,"def _prepare_tokens_to_embeds(self, tokens):","def prepare_tokens_to_embeds(self, tokens):",KEEP REP KEEP,Rename Method
Smart Masks to Convert (#957),"def _get_face_hashes(self): """""" Check for the existence of an aligned directory for identifying which faces in the target frames should be swapped.  Returns ------- list A list of face hashes that exist in the given input aligned directory. """"""","def get_face_hashes(self): """""" Check for the existence of an aligned directory for identifying which faces in the target frames should be swapped. If it exists, obtain the hashes of the faces in the folder """"""",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP REP REP REP KEEP ADD ADD REP REP KEEP KEEP ADD ADD ADD REP KEEP,Rename Method
rename use_simulator_operator_mode,"def evaluation_instruction(self, statevector_mode, use_simulator_snapshot_mode=False):","def evaluation_instruction(self, statevector_mode, use_simulator_operator_mode=False):",KEEP KEEP KEEP REP,Rename Parameter
"integrate spsa optimzer, and add an entry to manually set spsa parameters; update requirement; using basis gates; format to PEP8","def init_args(self, max_trials=1000, parameters=None):","def init_args(self, max_trials=1000):",KEEP KEEP ADD REP,Add Parameter
No explicit IOLoop (#5014),def stop(self) -> None:,"def stop(self, from_signal=False) -> None:",KEEP REP DEL KEEP KEEP,Remove Parameter
update gpu infer.,"def __init__(self, save_vocab_path='', attn_model_path='', maxlen=400, gpu_id=0):","def __init__(self, save_vocab_path='', attn_model_path='', maxlen=400):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Add support for sparse matrix notation in APM lti object,"def state_space(self,A,B,C,D=None,discrete=False,dense=False):","def state_space(self,A,B,C,D=None,discrete=False):",KEEP REP,Add Parameter
update corrector with short text.,def build_eval_corpus(output_eval_path=eval_data_path):,def build_eval_corpus():,KEEP REP,Add Parameter
Run mypy on python 3.7 (#1521),"def _update(self, params: np.ndarray, gradient: np.ndarray, mprev: np.ndarray, step_size: float, momentum_coeff: float) -> Tuple[np.ndarray, List[float]]:","def _update(self, params: np.array, gradient: np.array, mprev: np.array, step_size: float, momentum_coeff: float) -> Tuple[List[float], List[float]]:",KEEP KEEP KEEP REP KEEP REP KEEP REP KEEP KEEP KEEP KEEP KEEP REP KEEP,Change Return Type
Faceswap 2.0 (#1045),"def _set_root_logger(loglevel=logging.INFO): """""" Setup the root logger.  Parameters ---------- loglevel: int, optional The log level to set the root logger to. Default :attr:`logging.INFO`  Returns ------- :class:`logging.Logger` The root logger for Faceswap """"""",def set_root_logger(loglevel=logging.INFO): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
typing: lib.gui.analysis.stats,"def get_timestamps(self, session_id: Optional[int]) -> Union[Dict[int, np.ndarray], np.ndarray]:","def get_timestamps(self, session_id: Optional[int]) -> Union[dict, np.ndarray]:",KEEP KEEP KEEP KEEP KEEP ADD REP KEEP,Change Return Type
Alignments Manual (#503),"def initialize(self, mtcnn_kwargs, dlib_buffer):","def initialize(self, detector, mtcnn_kwargs, dlib_buffer):",KEEP KEEP DEL KEEP KEEP,Remove Parameter
Made most methods in pytorch file logger static.,"def load_model_from_dir(model, dir, name, n_iter=None, prefix=False, iter_format=""%05d"", exclude_layers=None):","def load_model_from_dir(self, model, dir, name, n_iter=None, prefix=False, iter_format=""%05d"", exclude_layers=None):",KEEP REP DEL KEEP KEEP KEEP KEEP KEEP KEEP,Remove Parameter
added command line interface,"def classify(self, instances):","def classify(self, testInstances):",KEEP KEEP REP,Rename Parameter
#1342: Optimize word occurrence accumulation and fix a bug with repeated counting of tokens that occur more than once in a window.,"def analyze_text(self, text, doc_num=None):","def analyze_text(self, text):",KEEP KEEP ADD REP,Add Parameter
more documentation and bug fixes,def _check_ts(X): Nvars = np.array([np.row_stack(X[i]).shape[1] for i in range(len(X))]) assert len(np.unique(Nvars)) == 1,def _check_ts_input(X): Nvars = [len(X[i]) for i in range(len(X))] assert np.unique(Nvars) == 1  ,KEEP REP KEEP KEEP REP KEEP KEEP KEEP REP KEEP REP KEEP KEEP,Rename Method
use assign term instead of create for methods,"def assign_sound_sensor(self, port):","def create_sound_sensor(self, port):",KEEP REP KEEP,Rename Method
Make Arkane unit tests PEP-8 compliant,def test_number_of_atoms_from_qchem_log(self):,def testNumberOfAtomsFromQChemLog(self):,KEEP REP,Rename Method
"Adding dot product layer, rollback downsample","def __init__(self, name, stride=1, downscale_factor=1):","def __init__(self, name, stride=1):",KEEP KEEP KEEP ADD REP,Add Parameter
Elfi model docs and refactoring (#128),"def nx_constant_topological_sort(G, nbunch=None, reverse=False): """"""Return a list of nodes in a constant topological sort order. This implementations is adapted from `networkx.topological_sort`.","def nx_alphabetical_topological_sort(G, nbunch=None, reverse=False): """"""Return a list of nodes in topological sort order.",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD,Rename Method
added StickingCoeff to `get_rate_coefficient` reaction method,"def get_rate_coefficient(self, T, P=0, surface_site_density=0):","def get_rate_coefficient(self, T, P=0):",KEEP KEEP KEEP ADD REP,Add Parameter
"Extract: Expose ""allow_growth"" option","def __init__(self, name, model_path, model_kwargs=None, allow_growth=False): logger.trace(""Initializing: %s (name: %s, model_path: %s, model_kwargs: %s, "" ""allow_growth: %s)"", self.__class__.__name__, name, model_path, model_kwargs, allow_growth)","def __init__(self, name, model_path, model_kwargs=None): logger.trace(""Initializing: %s (name: %s, model_path: %s, model_kwargs: %s)"", self.__class__.__name__, name, model_path, model_kwargs)",KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Switch all testing to pytest.,"@pytest.mark.parametrize('i', range(3, 10)) def test_J8(i):",def test_J8():,ADD ADD ADD KEEP REP,Add Parameter
bugfixes:,"def __init__(self, show_min: bool = True, show_mean: bool = True, show_max: bool = True) -> None:",def __init__(self):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Make rmgpy/thermo/* unit tests PEP-8 compliant,def test_cp0(self):,def test_Cp0(self):,KEEP REP,Rename Method
Mock pandas with status,"def assert_lpi_plot(plot, dims):","def assert_lpi_plot(plot, dims, known_best=True):",KEEP KEEP REP DEL,Remove Parameter
"Revert ""Issues/141""","def shift(shape, stride):","def shift(anchors, shape, stride):",KEEP REP DEL KEEP,Remove Parameter
ENH Save directly in bzip2 format,"def save_as_text(self, fname, use_bzip2=False):","def save_as_text(self, fname):",KEEP KEEP ADD REP,Add Parameter
"Add I_preceq, I_triangle, I_GH, and I_MES (#176)","def s_i(d, source, target, target_value):","def s_i(d, input_, output, output_value):",KEEP KEEP REP REP REP,Rename Parameter
"wip, grover works, bug fix in sat","def __init__(self, oracle, incremental=False, num_iterations=1): super().__init__() if QuantumAlgorithm.is_statevector_backend(self.backend): raise ValueError('Selected backend  ""{}"" does not support measurements.'.format(QuantumAlgorithm.backend_name(self.backend))) self._oracle = oracle self._max_num_iterations = 2 ** (len(self._oracle.variable_register()) / 2) self._incremental = incremental self._num_iterations = num_iterations if incremental: logger.debug('Incremental mode specified, ignoring ""num_iterations"".') else: if num_iterations > self._max_num_iterations: logger.warning('The specified value {} for ""num_iterations"" might be too high.'.format(num_iterations))","def init_args(self, oracle, incremental=False, num_iterations=1): if QuantumAlgorithm.is_statevector_backend(self.backend): raise ValueError('Selected backend  ""{}"" does not support measurements.'.format(QuantumAlgorithm.backend_name(self.backend))) self._oracle = oracle self._max_num_iterations = 2 ** (len(self._oracle.variable_register()) / 2) self._incremental = incremental self._num_iterations = num_iterations if incremental: logger.debug('Incremental mode specified, ignoring ""num_iterations"".') else: if num_iterations > self._max_num_iterations: logger.warning('The specified value {} for ""num_iterations"" might be too high.'.format(num_iterations))",KEEP REP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
introduced unsupervised equal widthdiscretiser,"def has_value(self, to_test): return self.values.__contains__(to_test)","def has_value(self, toTest): return self.values.__contains__(toTest)",KEEP KEEP REP KEEP REP,Rename Parameter
minor refactoring,def total_counts(dictionary_of_klass_freq):,def total_counts(dictionary_of_klass_counts):,KEEP REP,Rename Parameter
"Added tests for loading, parsing and testing.","def run(self, x_test=None, y_test=None, dataflow=None, s=None, **kwargs):","def run(self, x_test=None, y_test=None, dataflow=None):",KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
add types to net_util.py (#4916),"def _make_blocking_http_get(url: str, timeout: float = 5) -> Optional[str]:","def _make_blocking_http_get(url, timeout=5):",KEEP ADD ADD ADD ADD ADD ADD REP REP,Change Return Type
DirectML Support (#1291),"def get_dpi() -> Optional[float]: """""" Gets the DPI (dots per inch) of the display screen.","def get_dpi() -> float: """""" Obtain the DPI of the running screen.",KEEP KEEP KEEP REP KEEP REP KEEP KEEP ADD ADD ADD KEEP KEEP REP KEEP,Change Return Type
Improvements to type util types (#4856),"def _is_probably_plotly_dict(obj: object) -> TypeGuard[dict[str, Any]]:",def _is_probably_plotly_dict(obj: Any) -> bool:,KEEP KEEP REP KEEP ADD REP,Change Return Type
make K() allow for conditioning,"def common_information(dist, rvs=None, crvs=None, rv_names=None):","def common_information(dist, rvs=None, rv_names=None):",KEEP KEEP KEEP ADD KEEP,Add Parameter
fix signature,"def _create_iterator(self, skip=0, chunk=0, stride=1, return_trajindex=True): return FeatureReaderIterator(self, skip=skip, chunk=chunk, stride=stride, return_trajindex=return_trajindex)","def _create_iterator(self, skip=0, chunk=0, stride=1, return_trajindex=True, mapping_fct=None): return FeatureReaderIterator(self, skip=skip, chunk=chunk, stride=stride, return_trajindex=return_trajindex, mapping_fct=mapping_fct)",KEEP KEEP KEEP KEEP KEEP REP DEL KEEP KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
update docs,"def feed(self, count, total=1):","def feed(self, cnt, tot=1):",KEEP KEEP REP REP,Rename Parameter
Change 'event' to 'outcome'.,"def _init(self, pmf, outcomes, alphabet, base):","def _init(self, pmf, events, alphabet, base):",KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
BSL methods implementation (#392),"def plot_marginals(self, selector=None, bins=20, axes=None, reference_value=None, **kwargs):","def plot_marginals(self, selector=None, bins=20, axes=None, **kwargs):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Add experimental and beta namespaces (#1240),"def _show(*args): """"""Write arguments and *argument names* to your app for debugging purposes.","def show(*args): """"""Write arguments to your app for debugging purposes.",KEEP REP KEEP KEEP ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
cascade -> series,"def series(self, other): """""" Returns the series interconnection of the system and another system","def cascade(self, other): """""" Returns the cascade interconnection of the system and another system",KEEP REP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
BOLFI is functional,"def __init__(self, seed=None, batch_size=None, observed=None, output_supply=None):","def __init__(self, seed=None, batch_size=None, observed=None, override_outputs=None):",KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
automatically infer weakly-informative priors from data; closes #6,"def add_y(self, variable, *args, **kwargs): if 'prior' not in kwargs or kwargs['prior'] is None: kwargs['prior'] = deepcopy(default_priors['sigma']) kwargs['prior']['args']['beta'] *= self.data[variable].std() self.add_term(variable, *args, **kwargs)","def add_y(self, *args, **kwargs): self.add_term(*args, **kwargs)",KEEP KEEP ADD KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP,Add Parameter
refactor normalization and fix test,def reduce_lengthening(text):,def _reduce_length(text):,KEEP REP,Rename Method
[coordinates/iterable] refactoring 3,"def trajectory_length(self, itraj, stride=1, skip=None):","def trajectory_length(self, itraj, stride=1):",KEEP KEEP KEEP ADD REP,Add Parameter
Faceswap 2.0 (#1045),"""particularly bad for this)."" ""\n2) Lower the batchsize (the amount of images fed into the model each "" ""iteration)."" ""\n3) Try enabling 'Mixed Precision' training."" ""\n4) Use a more lightweight model, or select the model's 'LowMem' option "" ""(in config) if it has one."") raise FaceswapError(msg) from err","write_grads=True) tf_version = [int(ver) for ver in tf.__version__.split(""."") if ver.isdigit()] logger.debug(""Tensorflow version: %s"", tf_version) if tf_version[0] > 1 or (tf_version[0] == 1 and tf_version[1] > 12): kwargs[""update_freq""] = ""batch"" if tf_version[0] > 1 or (tf_version[0] == 1 and tf_version[1] > 13): kwargs[""profile_batch""] = 0 logger.debug(kwargs) return kwargs  def __print_loss(self, loss): """""" Outputs the loss for the current iteration to the console.  Parameters ---------- loss: dict The loss for each side. The dictionary should contain 2 keys (""a"" and ""b"") with the values being a list of loss values for the current iteration corresponding to each side. """""" logger.trace(loss) output = [""Loss {}: {:.5f}"".format(side.capitalize(), loss[side][0]) for side in sorted(loss.keys())] output = "", "".join(output) output = ""[{}] [ print(""\r{}"".format(output), end="""") ",REP REP DEL DEL KEEP REP REP REP REP REP REP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP REP REP REP REP REP REP REP REP REP REP DEL DEL DEL DEL KEEP REP REP REP REP REP KEEP REP REP REP REP REP REP REP REP REP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
add se2seq demo.,"def train_seq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=20):","def train_seq2seq_model(model, train_data, device, loss_fn, optimizer, model_path, epochs=20):",KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP,Rename Parameter
Add new CNN model. Add sample static image directory for examples.,"def __init__(self, from_csv=None, target_labels=None, datapath=None, image_dimensions=None, csv_label_col=None, csv_image_col=None, avep=False):","def __init__(self, from_csv=None, target_labels=None, datapath=None, image_dimensions=None, csv_label_col=None, csv_image_col=None):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Allow trimolecular reactions in RMG simulations,"def reactAll(coreSpcList, numOldCoreSpecies, unimolecularReact, bimolecularReact, trimolecularReact=None):","def reactAll(coreSpcList, numOldCoreSpecies, unimolecularReact, bimolecularReact):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
added binary flag for nltk.ne_chunk(),"def batch_ne_chunk(tagged_sentences, binary=False):",def batch_ne_chunk(tagged_sentences):,KEEP ADD REP,Add Parameter
Fix serving tests,"def test_specific_version(self, client, ephemeral_storage):","def test_specific_version(self, client):",KEEP KEEP ADD REP,Add Parameter
Refactore ImageDataGenerator to accept rotation_angle,"def get_random_transform_matrix(self, sample, seed=None):","def get_random_transform_matrix(self, x, seed=None):",KEEP KEEP REP KEEP,Rename Parameter
Merge SampleArray functionality into MCMCResults,def _convert_to_results(self):,def _convert_to_samplearray(self):,KEEP REP,Rename Method
nltk/corpus/reader/util.py,"def __init__(self, root, documents, extension='.xml'):","def __init__(self, root, items, extension='.xml'):",KEEP KEEP KEEP REP KEEP,Rename Parameter
fix augment images so validation is done on non-augmented images,"def add_rectangle(arr, probability=.2, top=10, bottom=30, left=10, right=150, min_width=10, max_width=30): if probability > random.random(): tl, br = gen_random_rectangle_coords(top, bottom, left, right, min_width, max_width) color = tuple(random.choice(range(0, 200)) for i in range(3)) arr = cv2.rectangle(arr, tl, br, color, -1)","def add_rectangle(arr, top=10, bottom=30, left=10, right=150, min_width=20, max_width=20): tl, br = gen_random_rectangle_coords(top, bottom, left, right, min_width, max_width) color = tuple(random.choice(range(0, 100)) for i in range(3)) arr = cv2.rectangle(arr, tl, br, color, -1)",KEEP KEEP ADD KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
Allow Cantherm networks to be drawn in multiple formats.,"def draw(self, outputDirectory, format='pdf'):","def draw(self, outputDirectory):",KEEP KEEP ADD REP,Add Parameter
"updated module interfaces, put  in  rather than as an argument to __init__","def __init__(self, hparams=None):","def __init__(self, name, hparams=None): self.name = name self._template = tf.make_template(name, self._build, create_scope_now_=True)",KEEP KEEP DEL KEEP DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
refactor inferencer and improve hed,def get_tensors_by_names(names):,def get_vars_by_names(names):,KEEP REP,Rename Method
Simple backend unit tests (#1020),def _diff_xy(img): ,def diff_xy(img):,KEEP REP,Rename Method
More documentation,"def show_image_grid(self, images, name=None, caption=None, env_appendix="""", opts=None,","def show_image_grid(self, images, name=None, title=None, caption=None, env_appendix="""", opts=None,",KEEP KEEP KEEP KEEP DEL KEEP KEEP KEEP,Remove Parameter
- Remove random access as a general option and only enable it for data-in-memory and feature reader for selected file formats.,"def __init__(self, source, max_slice_dimension=-1):","def __init__(self, source):",KEEP KEEP ADD REP,Add Parameter
code clean-up in predict/,"def __init__(self, model, session_creator=None, session_init=None, session_config=None,","def __init__(self, model, session_init=None, session_config=get_default_sess_config(0.4),",KEEP KEEP KEEP ADD KEEP REP,Add Parameter
Remove outdate multidispatch,def test_multipledispatch():,def test_multipledispatch(benchmark):,KEEP REP,Remove Parameter
[coordinates.api] renamed cluster_assign_centers to assign_to_centers (it's not the centers that are assigned),"def assign_to_centers(data=None, centers=None, stride=1): r""""""Assigns data to the nearest cluster centers, thus creating a Voronoi partition.","def cluster_assign_centers(data=None, centers=None, stride=1): r""""""Assigns data to (precalculated) cluster centers.",KEEP REP KEEP KEEP KEEP KEEP KEEP ADD REP KEEP ADD ADD ADD ADD ADD REP,Rename Method
Pytorch 0.4 and PIP compatible,"def __init__(self, engine=None, cuda_tf=transforms.ToCuda,","def __init__(self, engine=None, cuda_tf=transforms.ToCuda, variable_tf=transforms.ToVariable,",KEEP KEEP KEEP KEEP DEL,Remove Parameter
Fix pluggable dependency update,"def _update_dependencies(self, section_name, pluggable_dependencies):","def _update_dependencies(self, section_name, sections_to_be_deleted, pluggable_dependencies):  if section_name in sections_to_be_deleted: sections_to_be_deleted.remove(section_name)",KEEP KEEP KEEP DEL KEEP DEL DEL DEL DEL DEL DEL,Remove Parameter
update dropout.,"def load_model(word_dict, label_dict, embedding_dim, rnn_hidden_dim, dropout, save_model_path):","def load_model(word_dict, label_dict, embedding_dim, rnn_hidden_dim, save_model_path):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
"Simplify tests suite, remove spy_phase and related functions (#886)",def test_n_observed(self):,"@phase def test_n_observed(self, mocker, num, attr):",DEL KEEP REP DEL DEL DEL,Remove Parameter
Better logging of outs,"def __init__(self, t, h, p, l): self.logger = logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG)","def __init__(self, t, h, p, logger, l):",KEEP KEEP KEEP KEEP KEEP ADD ADD ADD REP REP,Remove Parameter
Add base=None to a few of the random distribution generators.,"def uniform(outcomes, base=None):",def uniform(outcomes):,KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_doc2author_missing(self):,def testDoc2authorMissing(self):,KEEP REP,Rename Method
Refactor Arkane kinetics output,"def draw(self, output_directory, format='pdf'):","def draw(self, outputDirectory, format='pdf'):",KEEP KEEP REP KEEP,Rename Parameter
Make testing/databaseTest.py unit tests PEP-8 compliant,"def kinetics_check_child_parent_relationships(self, family_name):","def kinetics_checkChildParentRelationships(self, family_name):",KEEP REP KEEP,Rename Method
Make fertility_of_i a derived attribute of the number of elements in a cept's tablet,"def __init__(self, alignment, src_sentence, trg_sentence, cepts):","def __init__(self, alignment, src_sentence, trg_sentence, fertility_of_i):",KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
"Add Registry, rework how Space is passed to algorithms (#833)","def compute_fidelities( n_branching: int, low: numpy.ndarray | float, high: numpy.ndarray | float, base: float, ) -> list[float]:","def compute_fidelities(n_branching, low, high, base):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP,Change Return Type
test on coco dataset,"def __init__(self, classes, pretrained=False):","def __init__(self, classes):",KEEP KEEP ADD REP,Add Parameter
update preprocess.,"def _save_data(data_list, data_path):","def save_data(data_list, data_path):",KEEP REP KEEP,Rename Method
Add integration tests for Snowpark (#5543),def test_unevaluated_snowpark_table_mock(self): ,def test_unevaluated_snowpark_table(self): ,KEEP REP,Rename Method
"Global caching works with Aqua 0.4, but for some reason execution is slower. Will convert caching to instance variable of QuantumInstance next.","def __init__(self, num_qubits, depth=2, entangler_map=None, entanglement='full', paulis=['Z', 'ZZ'], data_map_func=self_product): """"""Constructor.","def init_args(self, num_qubits, depth, entangler_map=None, entanglement='full', paulis=['Z', 'ZZ'], data_map_func=self_product): """"""Initializer.",KEEP REP KEEP REP KEEP KEEP KEEP KEEP KEEP REP,Rename Method
misc clean-ups,"def _build_graph(self, inputs): image_pos, y = inputs","def _build_graph(self, input_vars): image_pos, y = input_vars",KEEP KEEP REP KEEP KEEP KEEP REP,Rename Parameter
argscope,"def BNReLU(x, name=None): x = BatchNorm('bn', x, is_training)","def f(x, name=None): with tf.variable_scope('bn'): x = BatchNorm.f(x, is_training)",KEEP REP KEEP DEL DEL KEEP KEEP ADD REP KEEP,Rename Method
"Removed hard-coded file path in `GlueDict`, and used `nltk.data.load` for reading the glue file instead.","def __init__(self, filename, encoding=None):","def __init__(self, filename):",KEEP KEEP ADD REP,Add Parameter
adding optimizations,"def get_helper(helper_type,     inputs=None, sequence_length=None, embedding=None, start_tokens=None, end_token=None, **kwargs):","def make_helper(helper_type,     inputs=None, sequence_length=None, embedding=None, start_tokens=None, end_token=None, **kwargs):",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
Added approximate means for ILT method with Arrhenius kinetics such that n < 0.,"def calculateMicrocanonicalRateCoefficient(reaction, Elist, reacDensStates, prodDensStates=None, T=None):","def calculateMicrocanonicalRateCoefficient(reaction, Elist, reacDensStates, prodDensStates=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
get_global_step -> get_global_step_value to avoid confusion with tf.train.get_global_step,def get_global_step_value():,def get_global_step():,KEEP REP,Rename Method
Faceswap 2.0 (#1045),"def __init__(self, tk_globals, exclude_gpus): logger.debug(""Initializing: %s (tk_globals: %s, exclude_gpus: %s)"", self.__class__.__name__, tk_globals, exclude_gpus)","def __init__(self, tk_globals): logger.debug(""Initializing: %s (tk_globals: %s)"", self.__class__.__name__, tk_globals)",KEEP KEEP ADD REP KEEP KEEP KEEP ADD ADD KEEP KEEP ADD REP,Add Parameter
Merge ForwardMsg caching into develop  (#178),"def _enqueue_report_finished_message(self, status): """"""Enqueues a report_finished ForwardMsg.  Parameters ---------- status : ReportFinishedStatus  """"""",def _enqueue_report_finished_message(self):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
"Update ES code to optionally use auth, ssl, hosts","def __init__(self, es_hosts=None, es_port=None, es_ssl=False, es_auth=None, verbose=False, country_threshold=0.6, threads=True, progress=True, mod_date=""2018-06-05"", **kwargs):","def __init__(self, es_ip=""localhost"", es_port=""9200"", verbose=False, country_threshold=0.6, threads=True, progress=True, mod_date=""2018-06-05"", **kwargs):",KEEP KEEP ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
model fixes,def _extract_regions(classes):,def _detections(classes):,KEEP REP,Rename Method
[vamp] pass scaling to vampmodel and added test,def _diagonalize(self):,"def _diagonalize(self, scaling=None):",KEEP REP DEL,Remove Parameter
changed name from general to polynomial,"def polynomial_congruence(expr, m):","def general_congruence(expr, m):",KEEP REP KEEP,Rename Method
-,"def test_cli_change(self, parent_config, changed_cli_config, storage):","def test_cli_change(self, parent_config, changed_cli_config):",KEEP KEEP KEEP ADD REP,Add Parameter
Annotate types for strategy module,"def minimize( *rules: Callable[[_S], _T], objective=_identity ) -> Callable[[_S], _T]:","def minimize(*rules, objective=identity):",KEEP ADD ADD ADD ADD ADD ADD ADD REP REP,Change Return Type
"renamed non-grouping to non-capturing (for regexp parentheses), cf https://github.com/nltk/nltk/pull/567","def compile_regexp_to_noncapturing(pattern, flags=0):","def compile_regexp_to_nongrouping(pattern, flags=0):",KEEP REP KEEP,Rename Method
Test different type of categorical dims,"def sample(self, num=1, attempts=10):","def sample(self, num=1):",KEEP KEEP ADD REP,Add Parameter
revert var name qubits -> register,"def construct_circuit(self, mode='circuit', register=None):","def construct_circuit(self, mode='circuit', qubits=None):",KEEP KEEP KEEP REP,Rename Parameter
Add recursive lookup for pluggable dependencies,"def _update_pluggable_schema(self, pluggable_type, pluggable_name, default_name):","def _update_pluggable_input_schema(self, pluggable_type, pluggable_name, default_name):",KEEP REP KEEP KEEP KEEP,Rename Method
make dataflow idiomatic python container objects (fix #869) (#872),def __iter__(self): idxs = list(range(self.__len__())),def get_data(self): idxs = list(range(self.size())),KEEP REP KEEP KEEP REP,Rename Method
Save changes,"def save_image_grid_static(image_dir, tensor, name, n_iter=None, prefix=False, iter_format=""{:05d}"", nrow=8,","def store_image_grid_static(image_dir, tensor, name, n_iter=None, prefix=False, iter_format=""{:05d}"", nrow=8,",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
[coor/api] deprecate chunk_size (now called chunksize).,"def source(inp, features=None, top=None, chunksize=None, **kw):","def source(inp, features=None, top=None, chunk_size=None, **kw):",KEEP KEEP KEEP KEEP REP KEEP,Rename Parameter
Significant progress on numpy version of montecarlo equity calculator,"def get_flush(self, iterations, player_amount): self.suitCounts = (self.suits[:, :, :, None] == np.arange(1, 5)).sum(1)   self.maxsuit = np.argmax(self.suitCounts, axis=2) + 1 self.flush = self.suitCounts[np.arange(iterations)[:, None], np.arange(player_amount), self.maxsuit - 1] >= 5","def get_flush(self):   self.suitCounts = (self.suits[:, :, None] == np.arange(1, 5)).sum(1)   self.maxsuit = np.argmax(self.suitCounts, axis=1) + 1 self.flush = np.choose(self.maxsuit - 1, self.suitCounts.T) >= 5",KEEP REP REP REP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP ADD ADD ADD REP KEEP REP DEL KEEP KEEP,Add Parameter
Remove deprecated VQ tests (#987),"@data( ('QUBIT_OP_SIMPLE', 'qasm_simulator', 1, 5), ('QUBIT_OP_ZZ', 'statevector_simulator', 1, 1), ('QUBIT_OP_H2_WITH_2_QUBIT_REDUCTION', 'statevector_simulator', 1, 6), )","@idata([ ['QUBIT_OP_SIMPLE', 'qasm_simulator', 1, 5, False], ['QUBIT_OP_SIMPLE', 'qasm_simulator', 1, 5, True], ['QUBIT_OP_ZZ', 'statevector_simulator', 1, 1, False], ['QUBIT_OP_ZZ', 'statevector_simulator', 1, 1, True], ['QUBIT_OP_H2_WITH_2_QUBIT_REDUCTION', 'statevector_simulator', 1, 6, False], ['QUBIT_OP_H2_WITH_2_QUBIT_REDUCTION', 'statevector_simulator', 1, 6, True], ])",REP REP KEEP KEEP REP REP DEL DEL DEL DEL DEL DEL KEEP KEEP REP REP DEL KEEP KEEP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
"- Make reload_module optional in testsuite(), so it plays nice with nltk.test.",def testsuite(reload_module=False):,def testsuite():,KEEP REP,Add Parameter
ordering upd. #2,"def predict(self, *args):  ","def predict(self, x, *args):  ",KEEP KEEP DEL KEEP,Remove Parameter
Normalized pcoords and pcoords improvements (#259),"def parallel_coordinates(X, y, ax=None, features=None, classes=None, normalize=None, sample=1.0, color=None, colormap=None, vlines=True, vlines_kwds=None, **kwargs):","def parallel_coordinates(X, y=None, ax=None, features=None, classes=None, color=None, colormap=None, vlines=True, vlines_kwds=None, **kwargs):",KEEP KEEP REP KEEP KEEP KEEP ADD ADD KEEP KEEP KEEP KEEP KEEP,Add Parameter
"add docstrings, rename ci -> confint throughout","def _fisher_confint(self, alpha, observed=False): """""" Compute the confidence interval for the MLE of the previous run based on the Fisher information.  Args: alpha (float): specify the (1 - alpha) confidence level (0 < alpha < 1) observed (bool): if true, the observed Fisher information is used to construct the confidence interval, otherwise the expected Fisher information  Returns: list[float]: the confidence interval """"""","def _fisher_ci(self, alpha, observed=False):",KEEP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
Remove MongoDB dependencies from tests/unittests/core/worker/test_producer.py,"def test_exceed_max_idle_time_because_of_optout(producer, random_dt, monkeypatch):","def test_exceed_max_idle_time_because_of_optout( producer, database, random_dt, monkeypatch ):",KEEP REP DEL DEL KEEP REP DEL,Remove Parameter
Added partial support for mapping of tagsets.,"def _get_chunked_words(self, grid, chunk_types, tagset=None):","def _get_chunked_words(self, grid, chunk_types, simplify_tags=False):",KEEP KEEP KEEP KEEP REP,Rename Parameter
configurable anchor size,"def shift(shape, stride, base_size=16, ratios=None, scales=None):","def shift(shape, stride):",KEEP KEEP ADD ADD ADD REP,Add Parameter
"Allowing 1-hot encoding for DAs, overhaul of NN functions","def __init__(self, name, keep_dims=1):","def __init__(self, name, num_dims=-1):",KEEP KEEP KEEP REP,Rename Parameter
adding properties `auto_hermitian` and `auto_resize` to LinearSystemInput,"def __init__(self, matrix=None, vector=None, auto_hermitian=False, auto_resize=False):","def __init__(self, matrix=None, vector=None):",KEEP KEEP KEEP ADD ADD REP,Add Parameter
update infer.,"def plot_attention(attention, sentence, predicted_sentence, img_path):","def plot_attention(attention, sentence, predicted_sentence, attn_img_path=''):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Adapt docstrings for google style,"def show_image(self, image_path):","def _show_image(self, image_path):",KEEP REP KEEP,Rename Method
Push arguments down into objects...,"def get_marked_arguments(self, conflicts, cli_change_type=None, **branching_kwargs):","def get_marked_arguments(self, conflicts):",KEEP KEEP ADD ADD REP,Add Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_two_related_w_a_wout_c(family_with_trials, capsys):","def test_two_related_w_a_wout_c(clean_db, family_with_trials, capsys):",KEEP REP DEL KEEP,Remove Parameter
Minor changes to methods in data.kinetics.common,def independent_ids():,def independentIDs():,KEEP REP,Rename Method
Remove type hints and move into docs,"def sequence_partitions(l, n):","def sequence_partitions(l: Sequence[_T], n: int) -> Iterator[List[Sequence[_T]]]:",KEEP REP REP DEL DEL DEL DEL,Change Return Type
Add include_empty_subsets (#203),"def _process_data(df, *, sort_by, sort_categories_by, subset_size,","def _process_data(df, sort_by, sort_categories_by, subset_size,",KEEP KEEP ADD KEEP KEEP KEEP,Remove Parameter
fix how TF session is passed in client object,"def __init__(self, facebook_token, distance, model_dir, likes_left=100, tfsess=None):","def __init__(self, facebook_token, distance, model_dir, likes_left=100):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_nlargest(self):,def testNlargest(self):,KEEP REP,Rename Method
allow cell arguments in encoders/decoders,"def __init__(self, vocab_size, cell=None, hparams=None, name=""basic_rnn_decoder""): RNNDecoderBase.__init__(self, cell, hparams, name)","def __init__(self, vocab_size, name=""basic_rnn_decoder"", hparams=None): RNNDecoderBase.__init__(self, name, hparams)",KEEP KEEP KEEP ADD REP REP KEEP ADD REP REP,Add Parameter
s/name/item/g,"def read_lexicon(item='en'): filename = find_corpus_file('words', item)","def read_lexicon(name='en'): filename = find_corpus_file('words', name)",KEEP REP KEEP KEEP KEEP REP,Rename Parameter
Solvent viscosity can now be calculated at any temperature.,"def enable(self, solventData, solvationDatabase, comment=''):  logging.info(""Enabling diffusion-limited kinetics..."")","def enable(self, viscosity, solvationDatabase, comment=''): logging.info(""Enabling diffusion-limited kinetics with solvent viscosity {0!r}"".format(viscosity))",KEEP KEEP REP KEEP KEEP ADD KEEP KEEP REP DEL DEL DEL DEL,Rename Parameter
"Added duplicate, degeneracy, and pairs parameters to PDepReaction.__init__().","def __init__(self, index=-1, reactants=None, products=None, network=None, kinetics=None, reversible=True, transitionState=None, thirdBody=False, duplicate=False, degeneracy=1, pairs=None): rmgpy.reaction.Reaction.__init__(self, index, reactants, products, kinetics, reversible, transitionState, thirdBody, duplicate, degeneracy, pairs)","def __init__(self, index=-1, reactants=None, products=None, network=None, kinetics=None, reversible=True, transitionState=None, thirdBody=False): rmgpy.reaction.Reaction.__init__(self, index, reactants, products, kinetics, reversible, transitionState, thirdBody)",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD REP,Add Parameter
Fix ADAM resuseability (#1016),"def minimize(self, objective_function: Callable[[np.ndarray], float], initial_point: np.ndarray, gradient_function: Callable[[np.ndarray], float]) -> Tuple[np.ndarray, float, int]: """"""Run the minimization.  Args: objective_function: A function handle to the objective function. initial_point: The initial iteration point. gradient_function: A function handle to the gradient of the objective function.  Returns: A tuple of (optimal parameters, optimal value, number of iterations). """"""","def minimize(self, objective_function, initial_point, gradient_function): ",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP,Change Return Type
model_refactor (#571) (#572),"def __init__(self, parent): logger.debug(""Initializing %s: (parent: %s)"", self.__class__.__name__, parent) scaling_factor = get_config().scaling_factor","def __init__(self, parent, cli_options, tk_vars, scaling_factor): logger.debug(""Initializing %s: (parent: %s, cli_options: %s, tk_vars: %s, "" ""scaling_factor: %s"", self.__class__.__name__, parent, cli_options, tk_vars, scaling_factor)",KEEP KEEP REP DEL DEL DEL KEEP KEEP KEEP REP DEL DEL DEL DEL DEL DEL DEL KEEP REP REP REP REP,Remove Parameter
More Tests (#200),"def get_data(train_or_test, fake=False): if fake: return FakeData([[64, 224, 224, 3], [64]], 1000, random=False, dtype='uint8')",def get_data(train_or_test): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Handle benchmark race condition and conflict configure,"def test_create_benchmark(self, benchmark_config, benchmark_config_py):","def test_create_benchmark(self, benchmark_algorithms, benchmark_config):",KEEP KEEP REP REP,Rename Parameter
Make rmgpy/tools/* unit tests PEP-8 compliant,def test_species_conversion(self):,def testSpeciesConversion(self):,KEEP REP,Rename Method
Fixed ranges,"def __init__(self,gui_signals,logger):",def __init__(self):,KEEP REP,Add Parameter
Donkeycar 4.x release.  (#644),"def __init__(self, num_behavior_inputs=2, input_shape=(120, 160, 3)): super(KerasBehavioral, self).__init__() self.model = default_bhv(num_bvh_inputs=num_behavior_inputs, input_shape=input_shape)","def __init__(self, model=None, num_outputs=2, num_behavior_inputs=2, input_shape=(120, 160, 3), *args, **kwargs): super(KerasBehavioral, self).__init__(*args, **kwargs) self.model = default_bhv(num_outputs = num_outputs, num_bvh_inputs = num_behavior_inputs, input_shape=input_shape)",KEEP KEEP DEL DEL KEEP KEEP KEEP REP DEL DEL KEEP REP DEL KEEP KEEP REP DEL DEL DEL DEL DEL KEEP,Remove Parameter
Add CBOW,"def __init__(self, sentences=None, sg=1, size=100, alpha=0.025, window=5, min_count=5, seed=1, workers=1, min_alpha=0.0001):","def __init__(self, sentences=None, size=100, alpha=0.025, window=5, min_count=5, seed=1, workers=1, min_alpha=0.0001):",KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
refactor: perfom linting for punkt.py (#2830),def _pair_iter(iterator):,def _pair_iter(it):,KEEP REP,Rename Parameter
documentation and bugfixes,"def ts_stats(Xt, y, fs = 1.0, class_labels = None): ''' Generates some helpful statistics about the data X  Parameters ---------- X : array-like, shape [n_series, ...] Time series data and (optionally) static data created as per ``make_ts_data`` y : array-like, shape [n_series] target data fs : float sampling frequency class_labels : list of strings, default None List of target class names   Returns ------- results : dict | Dictionary of relevant statistics for the time series data | results['total'] has stats for the whole data set | results['by_class'] has stats segragated by target class  ''' check_ts_data(Xt) Xt, Xs = get_ts_data_parts(Xt)  if Xs is not None: S = len(np.atleast_1d(Xs[0]))","def ts_stats(X, y, fs = 1.0, class_labels = None): check_ts_data(X) try: dnames = X.dtype.names except: X = np.array(X) dnames = None H = 0  if dnames is not None: X = X['ts'] H = len([h for h in X.dtype.names if h != 'ts'])",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP REP REP REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP KEEP ADD ADD REP REP REP KEEP REP REP REP REP REP REP REP REP REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP KEEP ADD ADD ADD ADD REP REP REP,Rename Parameter
Resolve some EVC failures,"def test_adapter_add_changed(self, parent_config, cl_config, storage):","def test_adapter_add_changed(self, parent_config, cl_config):",KEEP KEEP KEEP ADD REP,Add Parameter
Adapt Primary Algo to use trials instead of points,"def test_shouldsuspend(self, palgo, fixed_suggestion):","def test_shouldsuspend(self, palgo):",KEEP KEEP ADD REP,Add Parameter
Switch all testing to pytest.,"@pytest.mark.parametrize('i', range(2, 10)) def test_H5(i):",def test_H5():,ADD ADD ADD KEEP REP,Add Parameter
New input file format for specifying hindered rotors.,"def loadSpecies(label, geomLog, statesLog, extSymmetry, freqScaleFactor, linear, rotors, atoms, bonds):","def loadSpecies(label, geomLog, statesLog, extSymmetry, freqScaleFactor, linear, rotorPivots, rotorTops, rotorScans, rotorSymmetry, atoms, bonds):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL DEL KEEP KEEP,Remove Parameter
Normalizing decoder outputs properly,"def __init__(self, dec_inputs=[], dec_states=[], logprob=0.0):","def __init__(self, dec_inputs=[], dec_outputs=[], dec_states=[], logprob=0.0):",KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
ZMQInput can run.,"def send_dataflow_zmq(df, addr, hwm=50, print_interval=100, format='msgpack'):","def send_dataflow_zmq(df, addr, hwm=50, print_interval=100):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Fix overwriting elements in the sidebar (#181),"@parameterized.expand( [ (BlockPath.MAIN,), (BlockPath.SIDEBAR,), ] ) def test_enqueue_new_element_delta(self, container): dg = self.new_delta_generator(container=container)",def test_enqueue_new_element_delta(self): dg = self.new_delta_generator(),ADD ADD ADD ADD ADD ADD KEEP ADD REP KEEP KEEP REP,Add Parameter
[vamp] delegate estimator params (ctor input) to model (#1257),"def __init__(self, test_model, test_estimator, observables, statistics, observables_mean_free, statistics_mean_free,","def __init__(self, model, estimator, observables, statistics, observables_mean_free, statistics_mean_free,",KEEP KEEP REP REP KEEP KEEP KEEP KEEP,Rename Parameter
Alignments Import from DeepFaceLab (#487),def load(self):,def load_alignments(self):,KEEP REP,Rename Method
"* Dispatch between augmentations which change the training data and transformations, like multiply and crop which manipulate the images in training, validation and inferencing (driving).","def __init__(self, cfg, key): aug_list = getattr(cfg, key, [])","def __init__(self, cfg): aug_list = getattr(cfg, 'AUGMENTATIONS', [])",KEEP KEEP ADD REP KEEP KEEP KEEP REP KEEP,Add Parameter
fix bugs and improve the approach making frames (#900),"def draw_steering_distribution(self, img, img_drawon):","def draw_steering_distribution(self, img):",KEEP KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_scoring_default(self):,def testScoringDefault(self):,KEEP REP,Rename Method
rename entire_... -> complete_...,def get_subsystems_counts(complete_system_counts): mixed_measurements = list(complete_system_counts),def get_subsystems_counts(entire_system_counts): mixed_measurements = list(entire_system_counts),KEEP REP KEEP KEEP REP,Rename Parameter
Misc fixes (#185),"def plot(self, logpdf=False): """"""Plot the posterior pdf.  Currently only supports 1 and 2 dimensional cases.  Parameters ---------- logpdf : bool Whether to plot logpdf instead of pdf. """""" if logpdf: fun = self.logpdf","def plot(self): if len(self.model.bounds) == 1: mn = self.model.bounds[0][0] mx = self.model.bounds[0][1] dx = (mx - mn) / 200.0 x = np.arange(mn, mx, dx) pd = np.zeros(len(x)) for i in range(len(x)): pd[i] = self.pdf([x[i]]) plt.figure() plt.plot(x, pd) plt.xlim(mn, mx) plt.ylim(0.0, max(pd)*1.05) plt.show()  elif len(self.model.bounds) == 2: x, y = np.meshgrid(np.linspace(*self.model.bounds[0]), np.linspace(*self.model.bounds[1])) z = (np.vectorize(lambda a,b: self.pdf(np.array([a, b]))))(x, y) plt.contour(x, y, z) plt.show() ",KEEP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Add Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_two_related_w_trials_wout_ac(family_with_trials, capsys):","def test_two_related_w_trials_wout_ac(clean_db, family_with_trials, capsys):",KEEP REP DEL KEEP,Remove Parameter
Flip Develop Into Master  / DexterOS 1.2 (#137),"def __init__(self, port=""I2C"", gpg=None, use_mutex=False):","def __init__(self, port=""I2C"", gpg=None):",KEEP KEEP KEEP ADD REP,Add Parameter
Fix qsvm unit tests,def test_qsvm_variational_via_run_algorithm(self):,def todo_test_qsvm_variational_via_run_algorithm(self):,KEEP REP,Rename Method
transformed camelCase to snake_case test names (#3033),def test_update_new_data_old_author(self):,def testUpdateNewDataOldAuthor(self):,KEEP REP,Rename Method
Stats optimization (#1067),"def _smooth_amount_callback(self, *args):","def smooth_amount_callback(self, *args):",KEEP REP KEEP,Rename Method
-,"def test_demo_four_workers(tmp_path, storage, monkeypatch):","def test_demo_four_workers(storage, monkeypatch):",KEEP ADD REP KEEP,Add Parameter
Completed integration of QM Thermo with RMG.,def generateThermoDataFromQM(self):,"def generateThermoDataFromQM(self, thermoClass=MultiNASA):",KEEP REP DEL,Remove Parameter
"fix roi for rnn,3d,imu models","def default_imu(num_outputs, num_imu_inputs, input_shape, roi_crop=(0, 0)):","def default_imu(num_outputs, num_imu_inputs, input_shape):",KEEP KEEP KEEP ADD ADD REP,Add Parameter
fix augment images so validation is done on non-augmented images,def val_record_transform(record): ,def rt(record):,KEEP REP,Rename Method
File writing method for Twitter class.,"def search(self, keywords, count=100, lang='en'):","def search(self, query, count=100, lang='en'):",KEEP KEEP REP KEEP KEEP,Rename Parameter
refine repo structure,out = mx.symbol.Group(out_list) return out ,"out_list = [embedding, all_label] out = mx.symbol.Group(out_list) return out",DEL DEL DEL DEL KEEP KEEP KEEP KEEP KEEP,Add Parameter
various refactors on qpe,"def _compute_energy(self, compute_eigenstate=False):",def _compute_energy(self):,KEEP ADD REP,Add Parameter
Adjust Transformers space to using Trials,"def reverse(self, transformed_trial):","def reverse(self, transformed_point):",KEEP KEEP REP,Rename Parameter
Adds summary_description and display_name for add_scalar() call (#570),"def add_scalar(self, tag, scalar_value, global_step=None, walltime=None, display_name="""", summary_description=""""):","def add_scalar(self, tag, scalar_value, global_step=None, walltime=None):",KEEP KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
Added custom augmenttion data generation test,def test_image_segmentation_generator_preprocessing(self): pass ,"def test_image_segmentation_generator(self): """""" Stub test TODO(divamgupta): Fill with actual test """""" pass",KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP,Rename Method
Remove MongoDB dependencies from tests/functional/commands,"def test_python_api(with_experiment_using_python_api, capsys):","def test_python_api(clean_db, with_experiment_using_python_api, capsys):",KEEP REP DEL KEEP,Remove Parameter
Fixed bug in setConnectivityValues() created during switch to integer lists.,def sortAndLabelVertices(self):,def sort_and_label_vertices(self):,KEEP REP,Rename Method
"Adds new parameters ""Colorbar"" and ""Heatmap"" to PCA visualizer (PR #884)","def pca_decomposition( X, y=None, ax=None, features=None, scale=True, proj_dim=2, proj_features=False, color=None, colormap=palettes.DEFAULT_SEQUENCE, alpha=0.75, random_state=None, colorbar=False, heatmap=False, **kwargs ): """""" Produce a two or three dimensional principal component plot of the data array ``X`` projected onto it's largest sequential principal components. It is common practice to scale the data array ``X`` before applying a PC decomposition. Variable scaling can be controlled using the ``scale`` argument.","def pca_decomposition(X, y=None, ax=None, features=None, scale=True, proj_dim=2, proj_features=False, color=None, colormap=palettes.DEFAULT_SEQUENCE, alpha=0.75, random_state=None, **kwargs): """"""Produce a two or three dimensional principal component plot of the data array ``X`` projected onto it's largest sequential principal components. It is common practice to scale the data array ``X`` before applying a PC decomposition. Variable scaling can be controlled using the ``scale`` argument.",KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
Change 'event' to 'outcome'.,"def _make_distribution(pmf, outcomes=None, alphabet=None, base=None, sparse=True):","def _make_distribution(pmf, events=None, alphabet=None, base=None, sparse=True):",KEEP KEEP REP KEEP KEEP KEEP,Rename Parameter
update ConstantVIdealGasReactor construct to new Reactor constructor,"def __init__(self, core_phase_system, edge_phase_system, initial_conditions, terminations, constant_species=[]): super().__init__(core_phase_system, edge_phase_system, initial_conditions, terminations, constant_species=[])","def __init__(self, core_phase_system, edge_phase_system, initial_conditions, terminations): super().__init__(core_phase_system, edge_phase_system, initial_conditions, terminations)",KEEP KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP ADD REP,Add Parameter
added weighted lsh index,"def __init__(self, hashvalues, seed):","def __init__(self, hashes, seed):",KEEP KEEP REP KEEP,Rename Parameter
- Switched from unittest-style testing to doctest-style testing.,"def test(verbosity=2, reload_module=False): runner = unittest.TextTestRunner(verbosity=verbosity) runner.run(testsuite(reload_module))",def test(): import unittest runner = unittest.TextTestRunner() runner.run(testsuite()),KEEP REP REP DEL KEEP KEEP REP REP,Add Parameter
Got the mnist example rewritten in the new API.,"def __init__(self, x_test):","def __init__(self, x_test, print):",KEEP KEEP REP DEL,Remove Parameter
change context.is_train to context.global_mode,"def get_rnn_cell(hparams=None, mode=None):",def get_rnn_cell(hparams=None):,KEEP ADD REP,Add Parameter
"changed ""utterances"" to ""turns"" [google code issue 147]","def _tagged_turns_block_reader(self, stream):","def _tagged_utterances_block_reader(self, stream):",KEEP REP KEEP,Rename Method
Fix test to current core,def test_echo_2d_array_args(self):,def test_echo_1d_array_args(self):,KEEP REP,Rename Method
Only require email (not invite code),"def test__verify_code(self):  ret = _verify_code('user@domain.com', 'ARzVsqhSB5i')","def test_verify_code(self):  ret = verify_code('user@domain.com', 'ARzVsqhSB5i')",KEEP REP KEEP KEEP KEEP REP KEEP,Rename Method
GUI v0.2.1b (#352),"def __init__(self, utils, notebook, command): self.utils = utils","def __init__(self, gui, notebook, command): self.gui = gui",KEEP KEEP REP KEEP KEEP REP KEEP REP,Rename Parameter
[coor/save_trajs] added stride parameter.,"def frames_from_file(file_name, pdbfile, frames, chunksize=100, verbose=False, stride=1, **kwargs):","def frames_from_file(file_name, pdbfile, frames, chunksize=int(1e5), verbose=False):",KEEP KEEP KEEP KEEP ADD ADD REP REP,Add Parameter
Keep counter name parameter consistent across all loggers,"def show_value(self, value, name=None, counter=None, tag=None, show_legend=True, env_appendix="""", opts=None,","def show_value(self, value, name=None, count=None, tag=None, show_legend=True, env_appendix="""", opts=None,",KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
Align eyes deprecation (#851),"def align_face(self, faces, size, filename):","def align_face(self, faces, align_eyes, size, filename):",KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
use lambdify,"def _pdf(self, x): return handmade_pdf(x)","def _pdf(self, z): return handmade_pdf(z)",KEEP KEEP REP KEEP REP,Rename Parameter
Added key version,def get_key_id(key):,def get_key_name(key):,KEEP REP,Rename Method
[notebook-pbar] fix setting of description.,"def print_status(s='', close=False, bar_style=None, desc=None):","def print_status(s='', close=False, bar_style=None):",KEEP KEEP KEEP ADD REP,Add Parameter
Making properties py25 compatible,"def _set_alignment(self, alignment):","@alignment.setter def alignment(self, alignment):",DEL KEEP REP KEEP,Rename Method
-,"def test_config_change(self, parent_config, changed_userconfig_config, storage):","def test_config_change(self, parent_config, changed_userconfig_config):",KEEP KEEP KEEP ADD REP,Add Parameter
fix validation loss,"def sample_rois(self, all_rois, gt_boxes, gt_labels, training=None):","def sample_rois(self, all_rois, gt_boxes, gt_labels):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
use feature map in qsvm kernel,def test_svm_qkernel_multiclass_all_pairs(self):,def test_classical_multiclass_all_pairs(self):,KEEP REP,Rename Method
Improve Streamlit CLI and clean up __main__.py to use Click properly.,"@click.group() @click.option('--log_level', show_default=True, type=click.Choice(LOG_LEVELS)) @click.version_option(prog_name='Streamlit') @click.pass_context def main(ctx, log_level='info'):   if log_level: import streamlit.logger streamlit.logger.set_log_level(log_level.upper())   @main.command('help') @click.pass_context def help(ctx):","@click.command() @click.pass_context @click.argument('mode', default='usage', type=click.Choice(COMMANDS)) @click.argument('args', type=str, nargs=-1) @click.option('--log_level', show_default=True, type=click.Choice(LOG_LEVELS)) def main(ctx, mode, args, log_level):    if log_level: import streamlit.logger streamlit.logger.set_log_level(log_level)  if mode == 'usage': click.echo(ctx.get_help())  COMMAND_HANDLERS[mode](args)  ",REP DEL DEL DEL DEL DEL DEL DEL KEEP KEEP KEEP ADD ADD KEEP KEEP REP DEL DEL KEEP KEEP DEL KEEP KEEP KEEP KEEP REP KEEP REP REP REP REP REP DEL DEL,Remove Parameter
session_state docstrings (+ minor housekeeping) (#4403),"def get_widget_metadata_by_key(self, user_key: str) -> WidgetMetadata: ","def get_metadata_by_key(self, user_key: str) -> WidgetMetadata:",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
Smart Masks to Convert (#957),"def _predict(self): """""" Predict from the loaded frames.  With a threading lock (to prevent stacking), run the selected faces through the Faceswap model predict function and add the output to :attr:`predicted` """""" with self._lock: self._predicted_images = list() for frame in self._input_images: self._predictor.in_queue.put(frame)",def predict(self):  with self.lock: self.predicted_images = list() for frame in self.input_images: self.predictor.in_queue.put(frame),KEEP ADD ADD ADD ADD ADD ADD REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP REP REP KEEP KEEP KEEP KEEP KEEP REP REP,Rename Method
Minor redesign of the corpus readers.  Instead of using 'items' or,"def chunked_paras(self, files=None):","def chunked_paras(self, documents=None):",KEEP KEEP REP,Rename Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_three_related_wout_ac(three_family_with_trials, capsys):","def test_three_related_wout_ac(clean_db, three_family_with_trials, capsys):",KEEP REP DEL KEEP,Remove Parameter
Rankd Basic Tests (#332),def test_rankd2(self):,def test_rankd1(self):,KEEP REP,Rename Method
"support light sensor and sound sensor, buzzer and LED","def __init__(self, port=""AD1"",gpg=None): try: AnalogSensor.__init__(self, port, ""OUTPUT"",gpg) self.setPin(2) self.set_descriptor(""LED"") except Exception as e: print(e) raise ValueError","def __init__(self, port=""D11""): AnalogSensor.__init__(self, port, ""OUTPUT"") self.set_descriptor(""LED"")",KEEP KEEP ADD REP KEEP KEEP ADD REP KEEP ADD ADD ADD ADD ADD ADD ADD,Add Parameter
Updates,def _add_option_refresh(self):,def add_option_refresh(self):,KEEP REP,Rename Method
simplify output,"def format_header_complete(self, strictnesses=None):","def format_header(self, strictnesses=None):",KEEP REP KEEP,Rename Method
"Global caching works with Aqua 0.4, but for some reason execution is slower. Will convert caching to instance variable of QuantumInstance next.","def predict(self, data, quantum_instance=None):","def predict(self, data):",KEEP KEEP ADD REP,Add Parameter
Adding width and height parameter to st.dataframe (#33),"def _enqueue_new_element_delta(self, marshall_element, elementWidth=None, elementHeight=None):","def _enqueue_new_element_delta(self, marshall_element):",KEEP KEEP ADD ADD REP,Add Parameter
Make rmgpy/tools/* unit tests PEP-8 compliant,def test_remove_isotope_for_reactions(self):,def testRemoveIsotopeForReactions(self):,KEEP REP,Rename Method
With conflict with new_config fixture,"def test_add_new_default(self, parent_config, new_config_with_w):","def test_add_new_default(self, parent_config, new_config):",KEEP KEEP KEEP REP,Rename Parameter
[coordinates.api & coordinates.transform]: subspace selection by cumulative variance in pca and tica. Kinetic maps in tica.,"def pca(data=None, dim=2, var_cutoff=1.0, stride=1):","def pca(data=None, dim=2, stride=1):",KEEP KEEP KEEP ADD KEEP,Add Parameter
Final cleaning for mtree incorp,"def __init__(self,id=None,name=None,logic=None,weight=1,meter=None):","def __init__(self,id=None,name=None,logic=None,weight=1):",KEEP REP,Add Parameter
"Adjust tests to new (trial.id, experiment.id) index","def build_query(experiment, query):",def build_query(query):,KEEP ADD REP,Add Parameter
Rename ignore_hash to allow_output_mutation (#422),"def _read_from_cache(key, persisted, allow_output_mutation, func_or_code, message_opts):","def _read_from_cache(key, persisted, ignore_hash, func_or_code, message_opts):",KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
Switch all testing to pytest.,"@pytest.mark.parametrize('i', range(2, 6)) def test_ii1(i):",def test_ii1():,ADD ADD ADD KEEP REP,Add Parameter
TYP: Make `OptionSequence` fully generic (#5192),def as_index_list(v: object) -> List[int]: if _is_range_value(v):,"def as_index_list(v): is_range_value = isinstance(v, (list, tuple)) if is_range_value:",KEEP REP REP REP REP DEL DEL KEEP REP,Change Return Type
Can now explicitly turn on/off kinetics families in RMG input files.,"def loadKinetics(self, path, reactionLibraries=None, seedMechanisms=None, kineticsFamilies=None, kineticsDepositories=None):","def loadKinetics(self, path, reactionLibraries=None, seedMechanisms=None, kineticsDepositories=None):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
added variable input image dim,"def __init__(self, model=None, num_outputs=2, num_imu_inputs=6, input_shape=(120, 160, 3), *args, **kwargs):","def __init__(self, model=None, num_outputs=2, num_imu_inputs=6 , *args, **kwargs):",KEEP KEEP KEEP KEEP ADD ADD REP REP KEEP KEEP,Add Parameter
Plot model can now handle multiple inputs to the model,"def plot_model_structure(self, model, *input_size, name=None, use_cuda=True, delete_tmp_on_close=False, **kwargs):","def plot_model_structure(self, model, input_size, name=None, use_cuda=True, delete_tmp_on_close=False, **kwargs):",KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP,Remove Parameter
Rename variable new_report_msg -> initial_msg,"def _connect(self, uri, initial_msg, on_connect, on_cleanup):","def _connect(self, uri, new_report_msg, on_connect, on_cleanup):",KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
Make perturb_pmf sample from a ball region. Update tests.,"def perturb_support(pmf, eps=.1, shape='ball', prng=None):","def perturb_support(pmf, eps=.1, prng=None):",KEEP KEEP KEEP ADD KEEP,Add Parameter
Add backend object parameter to run_algorithm,"def run_algorithm(params, algo_input=None, json_output=False, backend=None):","def run_algorithm(params, algo_input=None, json_output=False):",KEEP KEEP KEEP ADD REP,Add Parameter
implement bisect optimizer,"def compute_deviation(original, reduced, targets):","def compute_deviation(original, reduced):",KEEP KEEP ADD REP,Add Parameter
Smart Training Implementation (#914),"def _end_thread(self, thread, err): """""" Output message and join thread back to main on termination.  Parameters ---------- thread: :class:`lib.multithreading.MultiThread` The background training thread err: bool Whether an error has been detected in :func:`_monitor` """"""","def end_thread(self, thread, err): ",KEEP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
-,"def __init__( self, name, algorithms, targets, storage=None, executor=None, storage_instance=None, ):","def __init__(self, name, algorithms, targets, storage=None, executor=None):",KEEP ADD REP KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
Significant progress on numpy version of montecarlo equity calculator,"def run_evaluation(self, card1, card2, tablecards, iterations, player_amount=2): self.start = time.time() self.distribute_cards(card1, card2, tablecards, iterations) self.get_counts() self.get_kickers() self.get_multiplecards() self.get_fullhouse() self.get_straight() self.get_flush(iterations, player_amount) self.get_straighflush() self.get_highcard() self.calc_score()  self.print_output()  print(""Time Elapsed: ""+str(time.time() - self.start)) ","def run_evaluation(self, card1, card2, tablecards, iterations): self.start = time.time() self.distribute_cards(card1, card2, tablecards, iterations) self.get_counts() self.get_kickers() self.get_multiplecards() self.get_fullhouse() self.get_straight() self.get_flush() self.get_straighflush() self.get_highcard() self.calc_score()  self.print_output() print(time.time() - self.start)  def sortddeck(self): sortval = self.decks[:, :, 0] * 4 + self.decks[:, :, 1] sortval *= -1   sortedIdx = np.argsort(sortval) self.decks = self.decks[np.arange(len(self.decks))[:, None], sortedIdx]  self.cards = self.decks[:, :, 0] self.suits = self.decks[:, :, 1]",KEEP KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP DEL DEL DEL KEEP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Add Parameter
finished architecture,def extractEntities(taggedSentence):,def extractEntities(taggedSentences):,KEEP REP,Rename Parameter
file_uploader: support for multiple files (#1183),"def remove_files(self, session_id, widget_id): """"""Remove the file list with the given ID, if it exists.","def remove_file(self, session_id, widget_id): """"""Remove the file with the given ID, if it exists.",KEEP REP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
Add support for saving / loading models,"def initialize_variables(self, save_file=None):",def initialize_variables(self):,KEEP ADD REP,Add Parameter
[cktest] expose n_jobs argument,"def cktest(self, mlags=10, conf=0.95, err_est=False, n_jobs=1, show_progress=True):","def cktest(self, mlags=10, conf=0.95, err_est=False, show_progress=True):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Switch to using memory-mapped files when reading. (#691),"def __init__(self, file, read_only=False, line_lengths=list()):","def __init__(self, file, method='a+', line_lengths=list()): self.method = method",KEEP KEEP KEEP REP KEEP DEL DEL DEL,Rename Parameter
Lint DeltaGenerator and data_frame_proto.py,def _index_len(index): ,def index_len(index): ,KEEP REP,Rename Method
Fixes,"def distribute_cards(self, card1, card2, tablecards, iterations):","def distribute_cards(self, card1, card2, iterations):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
"based on the results of code review, fix format issues","def convert(size, in_x, in_y):","def convert(size, X, Y):",KEEP KEEP REP REP,Rename Parameter
rename quantum_exp_config to quantum_instance,"def test(self, data, labels, quantum_instance=None):","def test(self, data, labels, quantum_device=None):",KEEP KEEP KEEP KEEP REP,Rename Parameter
[msm.ui.msm.MSM]: added trajectory_weights and methods to compute active state/count fractions,"def __init__(self, dtrajs, lag, reversible=True, sparse=False, connectivity='largest', compute=True, dt = '1 step', **kwargs):","def __init__(self, dtrajs, lag, reversible=True, sparse=False, connectivity='largest', compute=True, **kwargs):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD KEEP,Add Parameter
Add CLI options for Executor backend,"def __init__(self, n_workers, **kwargs): self.n_workers = n_workers","def __init__(self, n_jobs, **kwargs): self.n_jobs = n_jobs",KEEP KEEP REP KEEP REP KEEP REP,Rename Parameter
Tweak Plot test setup,def test_plot(self):,"def test_plot(self, client):",KEEP REP DEL,Remove Parameter
Fix mutex (#124),"def __init__(self, port, pinmode, gpg, use_mutex = False):","def __init__(self, port, pinmode, gpg):",KEEP KEEP KEEP KEEP ADD ADD ADD REP,Add Parameter
"[solvers] correct many mistaked in documentation, remove nonsensical optional parameters","def spd_inv(W, epsilon=1e-10, method='QR'):","def spd_inv(W, epsilon=1e-10, method='QR', canonical_signs=False):",KEEP KEEP KEEP REP DEL,Remove Parameter
Fix third-party dependency issues and support scikit-learn 0.24 and scipy 1.6 (#1147),"def __init__(self, estimator, ax=None, colors=None, is_fitted=""auto"", **kwargs):","def __init__(self, model, ax=None, colors=None, is_fitted=""auto"", **kwargs):",KEEP KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
Added AffineAdapter class with necessary changes and pytests,"def __init__(self, Fm, Gm=None, coupling='additive', keep_input=False, implementation_fwd=1, implementation_bwd=1, adapter=None):","def __init__(self, Fm, Gm=None, coupling='additive', keep_input=False, implementation_fwd=1, implementation_bwd=1):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
[#100] Add option to read only mutations,"def __init__(self, directory, read_just_mutations=False):","def __init__(self, directory):",KEEP KEEP ADD REP,Add Parameter
Faceswap 2.0 (#1045),"log_dir = os.path.join(str(self._model.model_dir), ""{}_logs"".format(self._model.name), ""session_{}"".format(self._model.state.session_id)) tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0,   write_graph=get_backend() != ""amd"", write_images=False, update_freq=""batch"", profile_batch=0, embeddings_freq=0, embeddings_metadata=None) tensorboard.set_model(self._model.model) tensorboard.on_train_begin(0)","return kwargs  def __print_loss(self, loss): """""" Outputs the loss for the current iteration to the console.  Parameters ---------- loss: dict The loss for each side. The dictionary should contain 2 keys (""a"" and ""b"") with the values being a list of loss values for the current iteration corresponding to each side. """""" logger.trace(loss) output = [""Loss {}: {:.5f}"".format(side.capitalize(), loss[side][0]) for side in sorted(loss.keys())] output = "", "".join(output) output = ""[{}] [ print(""\r{}"".format(output), end="""") ",REP REP REP REP REP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL KEEP REP REP REP REP REP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
- Now fully functional (some cleaning and tweaking still required). Outputs a file with two pickled dicts containing the frequency counts for synsets of all words sourced from the Brown corpus.,"def brown_information_content(output_filename, compounds_filename, \ stopwords_filename=None, smoothing=True):       noun_tags = [ 'nn',                'nns',           'np',              'nps',          'nr',           'nrs',         'nc',         ]  verb_tags = [ 'vb',               'vbd',         'vbg',          'vbn',          'vbz',         'vbc'         ]  outfile = open(output_filename, ""wb"")  compounds = read_word_list(compounds_filename)  if stopwords_filename: stopwords = read_word_list(stopword_filename) else: stopwords = []  noun_fd = FreqDist() verb_fd = FreqDist()  count = 0 increment = 10000  sys.stdout.write(""Building initial frequency distributions"")  for sentence in brown.tagged():               new_sentence = [] compound = sentence.pop(0)         while len(sentence) > 0:  (token, tag) = sentence.pop(0)   token = token.lower()    compound_token = compound[0] + ' ' + token         compound_tag = substr_binary_search(compound_token, compounds)  if compound_tag: compound = (compound_token, compound_tag)     ","def brown_information_content(compounds_filename, output_filename):  noun_tags = [ 'nn',		        'nns',		   'np',		      'nps',		  'nr',		   'nrs',		 'nc',		 ]  verb_tags = [ 'vb',		       'vbd',		 'vbg',		  'vbn',		  'vbz',		 'vbc'		 ]  compounds = read_compound_list(compounds_filename) outfile = open(output_filename, ""w"")  noun_freq_dist = FreqDist() verb_freq_dist = FreqDist()  count = 0 increment = 10000  sys.stdout.write('Building initial frequency distributions')  for sentence in islice(brown.tagged(), 1000):               new_sentence = [] compound = sentence.pop(0)         while len(sentence) > 0:  (token, tag) = sentence.pop(0) compound_token = compound[0] + ' ' + token         compound_tag = substr_binary_search(compound_token, compounds)  if compound_tag: compound = (compound_token, compound_tag)       else: new_sentence.append(compound) compound = (token, tag)     new_sentence.append(compound)  for (token, tag) in new_sentence:   ",KEEP ADD ADD ADD REP REP KEEP ADD ADD ADD ADD ADD KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP REP KEEP KEEP KEEP KEEP ADD KEEP REP KEEP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP REP KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP KEEP KEEP ADD ADD ADD ADD ADD KEEP KEEP ADD ADD ADD REP REP KEEP ADD ADD ADD REP REP KEEP REP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP REP KEEP KEEP KEEP KEEP REP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Add Parameter
"Revert ""Datasource add skip parameter""","def load(trajfiles, features=None, top=None, stride=1, chunk_size=None, **kw):","def load(trajfiles, features=None, top=None, stride=1, chunk_size=None, skip=0, **kw):",KEEP KEEP KEEP KEEP KEEP KEEP DEL KEEP,Remove Parameter
cleanup the use of preact,"def resnet_bottleneck(l, ch_out, stride, stride_first=False):","def resnet_bottleneck(l, ch_out, stride, preact, stride_first=False):",KEEP KEEP KEEP KEEP DEL KEEP,Remove Parameter
Make augmentors return a `Transform` instance. (#1290),"def get_transform(self, img):","def _get_augment_params(self, img):",KEEP REP KEEP,Rename Method
Some changes to API docs (#308),"def __init__(self, name, term, data, prior=None, constant=None):","def __init__(self, name, term_dict, data, prior=None, constant=None):",KEEP KEEP KEEP REP KEEP KEEP KEEP,Rename Parameter
added augmentation,"def multi_train(cfg, tub, model, transfer, model_type, continuous, aug):","def multi_train(cfg, tub, model, transfer, model_type, continuous):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Docs and refactoring (#126),"def _update(self, batch, batch_index):","def update(self, batch, batch_index):",KEEP REP KEEP KEEP,Rename Method
comments; sentence->document; ipynb tweaks,"def note_doctag(self, key, document_no, document_length):","def note_doctag(self, key, sentence_no, sentence_length):",KEEP KEEP KEEP REP REP,Rename Parameter
Refactored to new bhmm code,"def timescales_hmsm(dtrajs, nstates, lags=None, nits=None, reversible=True, stationary=False,","def timescales_hmsm(dtrajs, nstates, lags=None, nits=None, reversible=True,",KEEP KEEP KEEP KEEP KEEP KEEP ADD,Add Parameter
update copyt5 predict with batch.,"def batch_t5_correct(self, texts: List[str], max_length: int = 128, batch_size: int = 32):","def batch_t5_correct(self, texts: List[str], max_length: int = 128):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP,Add Parameter
Reorganize methods related parsing and generating InChI layers,def remove_inchi_prefix(string):,def ignore_prefix(string):,KEEP REP,Rename Method
BSL remove likelihood estimation node (#430),"def slice_gamma_mean(ssy, loglik, gamma, sample_mean, sample_cov, tau=0.5, w=1.0, max_iter=1000, random_state=None):","def slice_gamma_mean(ssx, ssy, loglik, gamma, std, sample_mean, sample_cov, tau=0.5, w=1.0, max_iter=1000):",KEEP REP DEL KEEP KEEP DEL KEEP KEEP KEEP KEEP ADD REP,Remove Parameter
Add L2 Regularization to Structural Losses,"def _set_loss_functions(self, output_names): """""" Set the loss functions and their associated weights.","def _get_loss_functions(self, output_names): """""" Set the loss functions.",KEEP REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP,Rename Method
Training Split Loss to it's own section,def _set_globals(self): ,"def set_globals(self): """""" Set the global options for training  Loss Documentation MAE https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine -learners-should-know-4fb140e9d4b0 MSE https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine -learners-should-know-4fb140e9d4b0 LogCosh https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine -learners-should-know-4fb140e9d4b0 Smooth L1 https://arxiv.org/pdf/1701.03077.pdf L_inf_norm https://medium.com/@montjoile/l0-norm-l1-norm-l2-norm-l-infinity -norm-7a7d18a4f40c SSIM http://www.cns.nyu.edu/pub/eero/wang03-reprint.pdf GMSD https://arxiv.org/ftp/arxiv/papers/1308/1308.3052.pdf """"""",KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
restore OLD naming convention,"def fitWithBreaks(self, breaks):","def fit_with_breaks(self, breaks):",KEEP REP KEEP,Rename Method
Alignments update:,"def get_faces_in_frame(self, frame_name: str) -> List[AlignmentFileDict]:","def get_faces_in_frame(self, frame_name):",KEEP KEEP ADD ADD ADD REP,Change Return Type
Save kinetics in RMG-Java kinetics library format.,"def writeKineticsEntry(reaction, speciesList, verbose = True, javaLibrary = False):","def writeKineticsEntry(reaction, speciesList, verbose = True):",KEEP KEEP KEEP KEEP KEEP ADD ADD ADD REP,Add Parameter
Save changes,"def load_last_checkpoint(dir, name=None, **kwargs):","def restore_lastest_checkpoint(dir, name=None, **kwargs):",KEEP REP KEEP KEEP,Rename Method
Finish rv_names -> rv_mode for dit.multivariate.,"def interaction_information(dist, rvs=None, crvs=None, rv_mode=None):","def interaction_information(dist, rvs=None, crvs=None, rv_names=None):",KEEP KEEP KEEP KEEP REP,Rename Parameter
"Fix imports, remove models.__init__ to models.all_models","def evaluate(model=None, inp_images=None, annotations=None,","def evaluate(model=None, inp_inmges=None, annotations=None,",KEEP KEEP REP KEEP,Rename Parameter
Add fixed_initial option to variable builder. Setting fixed_initial=False makes the initial condition of the variable a degree of freedom. The default behavior of APM is fixed_initial=True.,"def Var(self, value=None, lb=None, ub=None, integer=False, fixed_initial=True, name=None):","def Var(self, value=None, lb=None, ub=None, integer=False, name=None):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Fixes dataproxy connection object not returning api response. Makes b鈥?(#572),"def test_project_with_connected_account_default_credentials(self, mock_access_token, ApiUrlMock): self._setup_mocks(ApiUrlMock)",def test_project_with_connected_account_default_credentials(self):,KEEP ADD ADD ADD REP,Add Parameter
add evaluate and sighan corpus.,def known(words): return set(word for word in words if word in word_freq)   def candidates(word):,def known(phrases): return set(phrase for phrase in phrases if phrase in phrase_freq),KEEP REP KEEP REP KEEP REP KEEP REP KEEP REP KEEP ADD ADD ADD ADD REP,Rename Parameter
Remove deprecated VQ tests (#987),"def test_sample_generation(self):  self.qgan.set_generator(generator_circuit=self.generator_circuit) _, weights_statevector = self.qgan._generator.get_output(self.qi_statevector, shots=100)","@data('wrapped', 'circuit', 'library') def test_sample_generation(self, mode):  if mode == 'wrapped':   warnings.filterwarnings('ignore', category=DeprecationWarning) self.qgan.set_generator(generator_circuit=self.generator_circuits[mode]) warnings.filterwarnings('always', category=DeprecationWarning) else: self.qgan.set_generator(generator_circuit=self.generator_circuits[mode])  _, weights_statevector = \ self.qgan._generator.get_output(self.qi_statevector, shots=100)",DEL DEL DEL KEEP REP DEL KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
"Added contains, __or__, __and__, difference, __minus__, len, and",def len(self):,def __len__(self):,KEEP REP,Rename Method
Update tests to use new datasets module (PR #907),def test_numpy_integration(self):,def test_integration_class_prediction_error(self):,KEEP REP,Rename Method
"documentation, pep8, style, clarity Prep for Segmentation (#812)","def ms_ssim_calc(img1, img2, max_val=1.0, power_factors=(0.0517, 0.3295, 0.3462, 0.2726)):","def ms_ssim(img1, img2, max_val=1.0, power_factors=(0.0517, 0.3295, 0.3462, 0.2726)):",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
Bug Manual Fix a first time indexing bug when EEN > 1,"def _wait_for_threads(self, extractor, loader, valid_meta):","def _wait_for_threads(self, extractor, loader, video_meta_data):",KEEP KEEP KEEP KEEP REP,Rename Parameter
separate common from DQN,def _sample_one(self):,def sample_one(self):,KEEP REP,Rename Method
AppSession: handle script events on the main thread (#4467),def _create_file_change_message(self) -> ForwardMsg: ,"def _enqueue_file_change_message(self) -> None: LOGGER.debug(""Enqueuing script_changed message (id=%s)"", self.id)",KEEP REP KEEP REP DEL DEL DEL DEL DEL,Rename Method
Fix for classes with dynamic docstring,"def process_class(c_name, obj, c_skip, c_md, c_mdt, c_idt, c_has_doctest,","def process_class(c_name, obj, c_sk, c_md, c_mdt, c_idt, c_has_doctest,",KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
Major refactoring to make conversion completely independent of input model library and of the simulator to use. All methods that have to be extended when adding a new simulator or input lib are in one file now.,"def save_assembly(assembly, path, filename):",def save_assembly(assembly):,KEEP ADD ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_mmap_compressed(self):,def testMmapCompressed(self):,KEEP REP,Rename Method
working default prior specifications plus automatic intercept Term creation,"def __init__(self, data, intercept=True, backend='pymc3'):","def __init__(self, data, backend='pymc3'):",KEEP KEEP KEEP ADD KEEP,Add Parameter
Remove MongoDB dependencies from tests/unittests/core/worker/test_producer.py,"def test_naive_algo_trained_on_all_non_completed_trials(producer, random_dt):","def test_naive_algo_trained_on_all_non_completed_trials(producer, database, random_dt):",KEEP KEEP DEL KEEP,Remove Parameter
Make rmgpy/rmg/* unit tests PEP-8 compliant,def test_thermo_filter_down(self):,def testThermoFilterDown(self):,KEEP REP,Rename Method
Smart Masks to Convert (#957),"def _get_mask(self): """""" Create a mask to be used at the edges of the face box.  The box for every face will be identical, so the mask is set just once on initialization. As gaussian blur technically blurs both sides of the mask, the mask ratio is reduced by half to give a more expected box.  Returns ------- :class:`numpy.ndarray` The mask to be used at the edges of the box output from the Faceswap model """"""","def get_mask(self): """""" The box for every face will be identical, so set the mask just once As gaussian blur technically blurs both sides of the mask, reduce the mask ratio by half to give a more expected box """"""",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP DEL KEEP KEEP ADD ADD KEEP KEEP ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP DEL KEEP KEEP KEEP ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD KEEP,Rename Method
Add ExperimentClient for python API,"def test_info_cmdline_api(self):  out = execute('orion info --name hunt-cmdline') assert 'name: hunt-cmdline' in out  def test_info_python_api(self, fill_db):  version = fill_db if version < '0.1.8': pytest.skip(""Python API not supported by {}"".format(version))",def test_info(self):  out = execute('orion info --name hunt') assert 'name: hunt' in out,KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def words(self, fileids=None): return concat([IndianCorpusView(fileid, enc,","def words(self, files=None): return concat([IndianCorpusView(filename, enc,",KEEP KEEP REP KEEP REP KEEP,Rename Parameter
Enable atom map constant for Fragment get_aromatic_rings,"def is_aryl_radical(self, aromatic_rings=None, save_order=False):","def is_aryl_radical(self, aromatic_rings=None):",KEEP KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_corpus_transform(self):,def testCorpusTransform(self):,KEEP REP,Rename Method
add more tests for SKAR-related PIDs,"def necessary_intrinsic_mutual_information_directed(dist, X, Y, Z, rv_mode=None, nhops=None, bound_u=None, bound_v=None):","def necessary_intrinsic_mutual_information_directed(dist, X, Y, Z, rv_mode=None, bound_u=None, bound_v=None):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
Add generic [de]serialize_payload function in payload module.,def destringify_jpg(stringified_jpg):,def destringify_jpg(serialized_jpg):,KEEP REP,Rename Parameter
bug fix: supporting submitting more than 300 circuits.,"def test_addition_noninplace(self): """""" test addition """""" pauli_a = 'IXYZ' pauli_b = 'ZYIX' coeff_a = 0.5 coeff_b = 0.5 pauli_term_a = [coeff_a, label_to_pauli(pauli_a)] pauli_term_b = [coeff_b, label_to_pauli(pauli_b)] opA = Operator(paulis=[pauli_term_a]) opB = Operator(paulis=[pauli_term_b]) copy_opA = copy.deepcopy(opA)",def test_addition(self):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
BOLFI building,"def update(self, X, Y, optimize=True):","def update(self, X, Y):",KEEP KEEP KEEP ADD REP,Add Parameter
Widgets with identical IDs raise an Exception (#425),"def _get_widget_ui_value(widget_type, element, user_key=None):","def _get_widget_ui_value(widget_type, element):",KEEP KEEP ADD REP,Add Parameter
Push arguments down into objects...,"def get_marked_arguments(self, conflicts, code_change_type=None, **branching_kwargs):","def get_marked_arguments(self, conflicts):",KEEP KEEP ADD ADD REP,Add Parameter
"integrate spsa optimzer, and add an entry to manually set spsa parameters; update requirement; using basis gates; format to PEP8","def init_args(self, num_of_qubits=2, circuit_depth=3, print_info=False, optimizer=None): self.num_of_qubits = num_of_qubits","def init_args(self, num_of_qubits=2, circuit_depth=3, max_trials=250, print_info=False): self.num_of_qubits=num_of_qubits",KEEP KEEP KEEP KEEP ADD ADD REP REP REP,Rename Parameter
Attempt to fix reference,"def sequence_partitions(l: Sequence[_T], n: int) -> Iterator[List[Sequence[_T]]]:","def sequence_partitions(l: Sequence[T], n: int) -> Iterator[List[Sequence[T]]]:",KEEP KEEP REP KEEP KEEP KEEP REP,Change Return Type
Add distributional models (#607),"def posterior_predictive(self, model, posterior): raise NotImplementedError","def posterior_predictive(self, model, posterior, linear_predictor): return NotImplemented",KEEP KEEP KEEP REP REP REP DEL,Remove Parameter
refactoring,def get_max_value_key(dic):,def mode_from_dict(dic):,KEEP REP,Rename Method
Multiuser i9e (#875),def _on_server_start(server): _print_url(),"def _on_server_start(server, report): _print_url(report)",KEEP REP REP DEL,Remove Parameter
Reverting to bleu scores with normalized Fraction,"def brevity_penalty(closest_ref_len, hyp_len):","def _brevity_penalty(closest_ref_len, hyp_len):",KEEP REP KEEP,Rename Method
"delete unused parameters, cf #979","def tf(self, term, text):","def tf(self, term, text, method=None):",KEEP KEEP KEEP REP DEL,Remove Parameter
Native circuits (#905),"def get_optimal_vector(self) -> Union[List[float], Dict[str, int]]: ",def get_optimal_vector(self):,KEEP ADD ADD ADD ADD REP,Change Return Type
stats.frv.py done,"def sample(self, size=(), library='scipy', seed=None):","def sample(self, size=(), library='scipy'):",KEEP KEEP KEEP ADD REP,Add Parameter
Save changes,"def save_images_static(image_dir, tensors, n_iter=None, prefix=False, iter_format=""{:05d}"", normalize=True):","def store_images_static(image_dir, tensors, n_iter=None, prefix=False, iter_format=""{:05d}"", normalize=True):",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Method
remove deprecated function/method/class,"def evolve(self, state_in, evo_time=0, num_time_slices=0, expansion_mode='trotter', expansion_order=1):","def evolve(self, state_in, evo_time=0, evo_mode=None, num_time_slices=0, quantum_registers=None, expansion_mode='trotter', expansion_order=1):",KEEP KEEP KEEP KEEP DEL KEEP DEL KEEP KEEP,Remove Parameter
Faceswap 2.0 (#1045),"alignments_path = os.path.join(image_path, ""alignments.fsa"") if not os.path.exists(alignments_path): raise FaceswapError(""Alignments file does not exist: `{}`"".format(alignments_path)) retval[side] = alignments_path logger.debug(""Alignments paths: %s"", retval) return retval ","the keys being `input_a`, `input_b`, `output` """""" logger.debug(""Getting time-lapse samples: '%s'"", side) if not self._output_file: self._setup(**timelapse_kwargs) self._samples.images[side] = self._batchers[side].compile_timelapse_sample() logger.debug(""Got time-lapse samples: '%s' - %s"", side, len(self._samples.images[side])) ",REP REP REP REP REP REP REP REP REP REP REP DEL DEL KEEP REP REP REP KEEP REP REP REP REP REP REP REP DEL DEL,Rename Parameter
"make all mut_class_id a parameter of the mutation readers, which should be moved to nala anyway","def __init__(self, directory, mut_class_id):","def __init__(self, directory):",KEEP KEEP ADD REP,Add Parameter
TYP: Make `OptionSequence` fully generic (#5192),"def deserialize( self, ui_value: Optional[List[int]], widget_id: str = """", ) -> Union[T, Tuple[T, T]]:","def deserialize(self, ui_value, widget_id=""""):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP,Change Return Type
Add entry points drivers and operatos discovery,def _discover_preferences_drivers(self):,def discover_preferences_drivers(self):,KEEP REP,Rename Method
allow cantera output to use RMG names,"def toCantera(self, speciesList=None, useChemkinIdentifier = True):","def toCantera(self, speciesList=None):",KEEP KEEP ADD ADD ADD REP,Add Parameter
"feat: enables to store position, gyro, accel, vel of simulator car into tub files","def __init__(self, sim_path, host=""127.0.0.1"", port=9091, headless=0, env_name=""donkey-generated-track-v0"", sync=""asynchronous"", conf={}, record_location=False, record_gyroaccel=False, record_velocity=False, delay=0):","def __init__(self, sim_path, host=""127.0.0.1"", port=9091, headless=0, env_name=""donkey-generated-track-v0"", sync=""asynchronous"", conf={}, delay=0):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD KEEP,Add Parameter
changed to be in line with standard practice,"def test_issue_22757(): assert manualintegrate(sin(x), y) == y * sin(x) assert manualintegrate(cos(x), y) == y * cos(x) assert manualintegrate(tan(x), y) == y * tan(x) assert manualintegrate(cot(x), y) == y * cot(x) assert manualintegrate(sec(x), y) == y * sec(x) assert manualintegrate(csc(x), y) == y * csc(x)  assert manualintegrate(sin(x) * cos(x), y) == y * sin(x) * cos(x) assert manualintegrate(-sec(x) * tan(x), y) == y * -sec(x) * tan(x) assert manualintegrate(csc(x) * cot(x), y) == y * csc(x) * cot(x) assert manualintegrate(sec(x)**2, y) == y * sec(x)**2 assert manualintegrate(csc(x)**2, y) == y * csc(x)**2  assert manualintegrate(sin(x) + cos(x), y) == y * (sin(x) + cos(x)) ","def tests_manualintegrate_trigonometry_differential(): assert manualintegrate(sin(x), y) == y * sin(x) assert manualintegrate(cos(x), y) == y * cos(x) assert manualintegrate(tan(x), y) == y * tan(x) assert manualintegrate(cot(x), y) == y * cot(x) assert manualintegrate(sec(x), y) == y * sec(x) assert manualintegrate(csc(x), y) == y * csc(x)  assert manualintegrate(sin(x) * cos(x), y) == y * sin(x) * cos(x) assert manualintegrate(-sec(x) * tan(x), y) == y * -sec(x) * tan(x) assert manualintegrate(csc(x) * cot(x), y) == y * csc(x) * cot(x) assert manualintegrate(sec(x)**2, y) == y * sec(x)**2 assert manualintegrate(csc(x)**2, y) == y * csc(x)**2  assert manualintegrate(sin(x) + cos(x), y) == y * (sin(x) + cos(x))   ",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
draw/concordance.py:,def pos_concordance():,def demo():,KEEP REP,Rename Method
Improved preflop reverse,"def update_most_gui_items(self, preflop_state, p, m, t, d, h, gui_signals): try: sheet_name = t.preflop_sheet_name except: sheet_name = ''","def update_most_gui_items(self, p, m, t, d, h, gui_signals): try: sheet_name=t.preflop_sheet_name except: sheet_name=''",KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP KEEP ADD ADD REP,Add Parameter
[coordinates] added stridden access,"def parametrize(self, stride=1):",def parametrize(self):,KEEP ADD REP,Add Parameter
Add: add a windows_tol for the visual unittest suite (#864),"def __init__(self, stack, visualizer=None, ax=None, tol=0.01, windows_tol=0.01, ext="".png"",","def __init__(self, stack, visualizer=None, ax=None, tol=0.01, ext="".png"",",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Fixes (#148),"def __init__(self, name=None, source_net=None, computation_context=None, set_current=True): """"""Create a new ElfiModel instance  Parameters ---------- name : str, optional source_net : nx.DiGraph, optional computation_context : elfi.ComputationContext, optional set_current : bool, optional Sets this model as the current ELFI model """"""  super(ElfiModel, self).__init__(source_net)","def __init__(self, name=None, source_net=None, computation_context=None):",KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Prepare Distribution to be base class for JointDistribution.,"def _make_distribution(pmf, events=None, alphabet=None, base=None, sparse=True):","def _make_distribution(pmf, events=None, eventspace=None, base=None, sparse=True):",KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
refactor imgaug,"def _augment(self, img, _): img_shape = img.shape[:2]","def _augment(self, img): img_shape = img.arr.shape[:2]",KEEP KEEP ADD REP KEEP KEEP REP,Add Parameter
Changed methods of thermo and kinetics models to use scalars instead of numpy arrays.,"def getRateCoefficient(self, T, dHrxn):","def getRateCoefficient(self, Tlist, dHrxn):",KEEP KEEP REP KEEP,Rename Parameter
Wr/config (#137),"def drive(cfg, model_path=None):",def drive(model_path=None):,KEEP ADD REP,Add Parameter
Refactoring to (nearly) restore pressure dependence functionality in RMG.,"def exploreIsomer(self, isomer, reactionModel, database):","def exploreIsomer(self, isomer, reactionModel):",KEEP KEEP KEEP ADD REP,Add Parameter
Replace the InitialState components by circuits (#1374),"@data('initial_state', 'circuit') def test_eoh(self, mode):",def test_eoh(self):,ADD ADD KEEP ADD REP,Add Parameter
Cached widget replay (#5298),"def get_cache( self, key: str, display_name: str, allow_widgets: bool ) -> ""SingletonCache"":","def get_cache(self, key: str, display_name: str) -> ""SingletonCache"":",KEEP ADD REP KEEP KEEP KEEP ADD ADD ADD REP KEEP KEEP,Add Parameter
Test experiment.stats,"def test_experiment_stats_max_trials_none(space: Space):  NUM_COMPLETED = 3 statuses = ([""completed""] * NUM_COMPLETED) + ([""reserved""] * 2) with OrionState(trials=generate_trials(statuses)) as cfg: exp = Experiment(""supernaekei"", mode=""x"", space=space, storage=cfg.storage) exp._id = cfg.trials[0][""experiment""] exp.metadata = {""datetime"": datetime.datetime.utcnow()} stats = exp.stats assert stats.trials_completed == NUM_COMPLETED assert stats.best_trials_id == cfg.trials[2][""id""] assert stats.best_evaluation == 0 assert stats.start_time == exp.metadata[""datetime""] assert stats.finish_time == cfg.trials[3][""end_time""] assert stats.duration == datetime.timedelta(seconds=3) assert stats.whole_clock_time == datetime.timedelta(seconds=3) assert stats.nb_trials == NUM_COMPLETED + 2 assert stats.trial_status_count == {""completed"": NUM_COMPLETED, ""reserved"": 2}  assert stats.max_trials is None assert stats.progress is None assert stats.eta is None assert stats.eta_milliseconds is None   def test_experiment_stats_max_trials_inf(space: Space):  NUM_COMPLETED = 3 statuses = ([""completed""] * NUM_COMPLETED) + ([""reserved""] * 2) with OrionState(trials=generate_trials(statuses)) as cfg: exp = Experiment(""supernaekei"", mode=""x"", space=space, storage=cfg.storage) exp._id = cfg.trials[0][""experiment""] exp.metadata = {""datetime"": datetime.datetime.utcnow()} exp.max_trials = float(""inf"") stats = exp.stats assert stats.trials_completed == NUM_COMPLETED assert stats.best_trials_id == cfg.trials[2][""id""] assert stats.best_evaluation == 0 assert stats.start_time == exp.metadata[""datetime""] assert stats.finish_time == cfg.trials[3][""end_time""] assert stats.duration == datetime.timedelta(seconds=3) assert stats.whole_clock_time == datetime.timedelta(seconds=3) assert stats.nb_trials == NUM_COMPLETED + 2 assert stats.trial_status_count == {""completed"": NUM_COMPLETED, ""reserved"": 2}  assert stats.max_trials == ""infinite"" assert stats.progress is None assert stats.eta is None assert stats.eta_milliseconds is None   def test_experiment_stats_max_trials_zero(space: Space):  NUM_COMPLETED = 3 statuses = ([""completed""] * NUM_COMPLETED) + ([""reserved""] * 2) with OrionState(trials=generate_trials(statuses)) as cfg: exp = Experiment(""supernaekei"", mode=""x"", space=space, storage=cfg.storage) exp._id = cfg.trials[0][""experiment""] exp.metadata = {""datetime"": datetime.datetime.utcnow()} exp.max_trials = 0 stats = exp.stats assert stats.trials_completed == NUM_COMPLETED assert stats.best_trials_id == cfg.trials[2][""id""] assert stats.best_evaluation == 0 assert stats.start_time == exp.metadata[""datetime""] assert stats.finish_time == cfg.trials[3][""end_time""] assert stats.duration == datetime.timedelta(seconds=3) assert stats.whole_clock_time == datetime.timedelta(seconds=3) assert stats.nb_trials == NUM_COMPLETED + 2 assert stats.trial_status_count == {""completed"": NUM_COMPLETED, ""reserved"": 2}  assert stats.max_trials == 0 assert stats.progress == 0.6 assert stats.eta is None assert stats.eta_milliseconds is None   def test_experiment_stats_max_trials_lesser_than_nb_completed(space: Space):  NUM_COMPLETED = 3 statuses = ([""completed""] * NUM_COMPLETED) + ([""reserved""] * 2) with OrionState(trials=generate_trials(statuses)) as cfg: exp = Experiment(""supernaekei"", mode=""x"", space=space, storage=cfg.storage) exp._id = cfg.trials[0][""experiment""] exp.metadata = {""datetime"": datetime.datetime.utcnow()} exp.max_trials = 2 stats = exp.stats assert stats.trials_completed == NUM_COMPLETED assert stats.best_trials_id == cfg.trials[2][""id""] assert stats.best_evaluation == 0 assert stats.start_time == exp.metadata[""datetime""] assert stats.finish_time == cfg.trials[3][""end_time""] assert stats.duration == datetime.timedelta(seconds=3) assert stats.whole_clock_time == datetime.timedelta(seconds=3) assert stats.nb_trials == NUM_COMPLETED + 2 assert stats.trial_status_count == {""completed"": NUM_COMPLETED, ""reserved"": 2}  assert stats.max_trials == 2 assert stats.progress == 0.6 assert stats.eta == datetime.timedelta() assert stats.eta_milliseconds == 0   def test_experiment_stats_no_completed_trials(space: Space):  NUM_COMPLETED = 0 statuses = ([""completed""] * NUM_COMPLETED) + ([""reserved""] * 2) with OrionState(trials=generate_trials(statuses)) as cfg: exp = Experiment(""supernaekei"", mode=""x"", space=space, storage=cfg.storage) exp._id = cfg.trials[0][""experiment""] exp.metadata = {""datetime"": datetime.datetime.utcnow()} exp.max_trials = 2 stats = exp.stats assert stats.trials_completed == NUM_COMPLETED  assert stats.best_trials_id is None assert stats.best_evaluation is None assert stats.start_time == exp.metadata[""datetime""] assert stats.finish_time == exp.metadata[""datetime""] assert stats.duration == datetime.timedelta() assert stats.whole_clock_time == datetime.timedelta() assert stats.nb_trials == NUM_COMPLETED + 2 assert stats.trial_status_count == {""reserved"": 2}  assert stats.max_trials == 2 assert stats.progress == 0 assert stats.eta == ""infinite"" assert stats.eta_milliseconds is None   def test_experiment_stats_normal(space: Space): ",def test_experiment_stats(space: Space): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP,Rename Method
Use orion state for storage setups,"def test_interrupt_diff_code(monkeypatch, capsys):","def test_interrupt_diff_code(storage, monkeypatch, capsys):",KEEP REP DEL KEEP,Remove Parameter
Misc updates on master before GAN. Added multithreading + mmod face detector (#109),"def detect_faces(frame, model=""hog""): face_locations = face_recognition.face_locations(frame, model=model)",def detect_faces(frame): face_locations = face_recognition.face_locations(frame),KEEP ADD REP KEEP KEEP ADD REP,Add Parameter
updated with fully working Long division,"def construct_circuit(self, mode, inreg):","def construct_circuit(self, mode, inreg, precision):",KEEP KEEP KEEP REP DEL,Remove Parameter
Fixes,"def run_evaluation(self, card1, card2, tablecards, iterations):","def run_evaluation(self, card1, card2, iterations):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Split classes into files. Reformating with PEP,def open_help(self):,"def open_help(self, p, l):",KEEP REP DEL DEL,Remove Parameter
-,"def _create_benchmark(name, algorithms, targets, storage, executor, storage_instance):","def _create_benchmark(name, algorithms, targets, storage, executor):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
"Refactor lib/Serializer.py, and other improvements. (#394)",def get_serializer_from_ext(ext):,"def get_serializer_fromext(ext): if ext in ("".yaml"", "".yml""): return YAMLSerializer",KEEP REP DEL DEL DEL DEL DEL DEL DEL,Rename Method
fix perturbation fallbacks,"def __init__(self, job, output_directory, perturbation, max_iters=5):","def __init__(self, job, output_directory, perturbation):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
[versioneer] updated to v0.13,def git_get_keywords(versionfile_abs):,def get_expanded_variables(versionfile_abs):,KEEP REP,Rename Method
Bugfixes,"def _to_numpy(self, data: Dict[int, EventData], is_live: bool) -> Tuple[np.ndarray, np.ndarray]:","def _to_numpy(self, data, is_live):",KEEP KEEP ADD ADD ADD ADD ADD ADD REP REP,Change Return Type
[frames_from_file] topology argument more flexible,"def frames_from_file(file_name, topology, frames, chunksize = 100, stride = 1, verbose = False):","def frames_from_file(file_name, pdbfile, frames, chunksize = 100, stride = 1, verbose = False, **kwargs):",KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL,Rename Parameter
nltk/corpus/reader/util.py,"def tagged_sents(self, documents=None):","def tagged_sents(self, items=None):",KEEP KEEP REP,Rename Parameter
transformed camelCase to snake_case test names (#3033),def test_training(self):,def testTraining(self):,KEEP REP,Rename Method
Adding dict support to Options,"def __new__(self, source=None, arguments_callback=None, lock=False, run_parser=True):","def __new__(self, path_yaml=None, arguments_callback=None, lock=False, run_parser=True):",KEEP KEEP REP KEEP KEEP KEEP,Rename Parameter
Faceswap 2.0 (#1045),"def log_setup(loglevel, log_file, command, is_gui=False): """""" Set up logging for Faceswap.  Sets up the root logger, the formatting for the crash logger and the file logger, and sets up the crash, file and stream log handlers.  Parameters ---------- loglevel: str The requested log level that Faceswap should be run at. log_file: str The location of the log file to write Faceswap's log to command: str The Faceswap command that is being run. Used to dictate whether the log file should have ""_gui"" appended to the filename or not. is_gui: bool, optional Whether Faceswap is running in the GUI or not. Dictates where the stream handler should output messages to. Default: ``False`` """"""","def log_setup(loglevel, logfile, command, is_gui=False): ",KEEP KEEP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Parameter
Remove Server._singleton (#4966),def _set_up_signal_handler(server: Server) -> None:,def _set_up_signal_handler() -> None:,KEEP ADD REP KEEP KEEP,Add Parameter
Fix sidebar crosstalk between sessions (#1015),"def add_report_ctx(thread=None, ctx=None):",def add_report_ctx(thread):,KEEP ADD REP,Add Parameter
Refactored remaining toolbox modules.,"def plot_confusion_matrix(y_test, y_pred, path=None, class_labels=None): """"""  Parameters ----------  y_test : y_pred: Sequence path: Optional[str] Where to save the output. class_labels: Optional[list] List of class labels. """""" ","def plot_confusion_matrix(Y_test, Y_pred, path=None, class_labels=None):",KEEP REP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Parameter
BSL update semiparametric likelihood calculation (#436),def gaussian_rank_corr(x):,"def gaussian_rank_corr(x, vec=False):",KEEP REP DEL,Remove Parameter
refactoring,"def resnet50(k, **kwargs):",def resnet50(**kwargs):,KEEP ADD REP,Add Parameter
- Updated tests to use new CFGProduction constructor signature (no varargs),def testsuite(reload_module=False):,def testsuite():,KEEP REP,Add Parameter
Minor redesign of the corpus readers.  Instead of using 'items' or,"def paras(self, files=None):","def paras(self, documents=None):",KEEP KEEP REP,Rename Parameter
[thermo] moving umbrella_sampling_data API function to util.get_umbrella_sampling_data,def umbrella_sampling_estimation(,def umbrella_sampling_estimate(,KEEP REP,Rename Method
Rename fetch_db_config to fetch_config_from_db,"def fetch_config_from_db(self, cmdargs): """"""Get dictionary of options from experiment found in the database","def fetch_db_config(self, cmdargs): """"""Get dictionary of options from all local sources (not from db)",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP REP REP DEL,Rename Method
optional load_entries_to_save when saving database,"def save(self, path, reindex=True):","def save(self, path):",KEEP KEEP ADD REP,Add Parameter
Change QuadraticProgramConverter.interpret to convert `x` directly (#1196),@staticmethod def _find_strongest_correlation(correlations):,"def _find_strongest_correlation(self, correlations):",ADD KEEP REP DEL,Remove Parameter
Allow HtmlReader to read either a directory or a file,"def __init__(self, path): self.path = path   def __read_directory(self):","def __init__(self, directory): self.directory = directory ",KEEP KEEP REP REP KEEP ADD ADD ADD ADD REP,Rename Parameter
some naming and code migration,"def __init__(self, idx, config):","def __init__(self, idx, gpuid, config):",KEEP KEEP KEEP DEL KEEP,Remove Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_three_exp(capsys, three_experiments):","def test_three_exp(capsys, clean_db, three_experiments):",KEEP KEEP DEL KEEP,Remove Parameter
Improvements to type util types (#4856),def is_pydeck(obj: object) -> TypeGuard[Deck]:,def is_pydeck(obj: Any) -> bool:,KEEP KEEP REP KEEP REP,Change Return Type
Updating F1 measurements to work on tokens as well,"def common_substruct_stats(self): """"""Return common subtree/subphrase size statistics.","def common_subtree_stats(self): """"""Return common subtree size statistics.",KEEP REP KEEP KEEP REP KEEP KEEP,Rename Method
[coordinates / api / load|source] introduced optional chunksize parameter,"def source(inp, features=None, top=None, chunk_size=100): r"""""" Wraps input as data source for pipeline","def source(inp, features=None, top=None): r"""""" Wraps input as data source for pipeline.",KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP,Add Parameter
Added partial support for mapping of tagsets.,"def iob_words(self, fileids=None, tagset=None):","def iob_words(self, fileids=None, simplify_tags=False):",KEEP KEEP KEEP REP,Rename Parameter
Updates to Chemical Package,"def __init__(self,m): self.m = m  ","def __init__(self,m=[],remote=True): if m==[]: self.m = GEKKO(remote=remote) else: self.m = m ",KEEP REP DEL DEL DEL DEL DEL DEL KEEP KEEP KEEP,Remove Parameter
membership operator for lsh,def test_remove(self):,def test_delete(self):,KEEP REP,Rename Method
Add Mouth and Eye Priority to Loss options (#1054),"def __init__(self): logger.debug(""Initializing: %s"", self.__class__.__name__)","def __init__(self, loss_functions): logger.debug(""Initializing: %s: (loss_functions: %s)"", self.__class__.__name__, loss_functions)",KEEP REP DEL KEEP REP REP DEL DEL DEL,Remove Parameter
change underscore to  camel_case style in reduction package,"def findImportantReactions(rmg, tolerance):","def find_important_reactions(rmg, tolerance):",KEEP REP KEEP,Rename Method
Make rmgpy/statmech/* unit tests PEP-8 compliant,def test_get_partition_function_quantum(self):,def test_getPartitionFunction_quantum(self):,KEEP REP,Rename Method
Add Kendall-Tau metric to Rank2D (#645),def test_rank1d_orientation(self):,def test_rank1d_random(self):,KEEP REP,Rename Method
Generating :-),"def generate_tree(self, da, doc=None):","def generate_tree(self, doc=None):",KEEP KEEP ADD KEEP,Add Parameter
Adds frequency sort feature to PosTagVisualizer (#779),"def postag( X, ax=None, tagset=""penn_treebank"", colormap=None, colors=None, frequency=False, **kwargs ):","def postag(X, ax=None, tagset=""penn_treebank"", colormap=None, colors=None, **kwargs):",KEEP ADD REP KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
"[msm.ui.msm.EstimatedMSM]: Renamed compute to estimate. Propose to do the same for other estimators, to have a consistent interface.",def estimate(self):,def compute(self):,KEEP REP,Rename Method
added VarUttMonoTextData; Fixed VarUttTextDataDecoder,"def _process_dataset(self, dataset, hparams, data_spec): tran_fn, data_spec = self.MultiAlignedTextData._make_processor(","@staticmethod def _process_dataset(dataset, hparams, data_spec): tran_fn, data_spec = MultiAlignedTextData._make_processor(",REP REP REP KEEP KEEP KEEP KEEP KEEP REP,Add Parameter
removes DDM.scalarmul and corrects neg mistake,def test_DomainMatrix_truediv():,def test_DomainMatrix_scalardiv():,KEEP REP,Rename Method
Add walltime override to SummaryWriter methods (#207),"def add_figure(self, tag, figure, global_step=None, close=True, walltime=None):","def add_figure(self, tag, figure, global_step=None, close=True):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
"Add mypy types to server.py, bootstrap.py, server_util.py (#3729)","def get_compression_options(self) -> Optional[Dict[Any, Any]]:",def get_compression_options(self):,KEEP ADD ADD ADD REP,Change Return Type
"[show_config] Add 3 visibility modes: visible, hidden, obfuscated","def _create_option( key, description=None, default_val=None, visibility='visible'):","def _create_option(key, description=None, default_val=None, visible=True):",KEEP ADD REP KEEP KEEP REP,Rename Parameter
"Added fixed random_seed and better checks to test_is_invertible_module, also added more tests","def is_invertible_module(module_in, test_input_shape, test_input_dtype=torch.float32, atol=1e-6, random_seed=42):","def is_invertible_module(module_in, test_input_shape, test_input_dtype=torch.float32, atol=1e-6):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Model updates,"def _get_input_shape(self) -> Tuple[int, int, int]:",def _get_input_shape(self):,KEEP ADD ADD ADD ADD REP,Change Return Type
Port RawFeatureVector to a circuit (#1404),"@data('circuit', 'component') def test_raw_feature_vector_on_wine(self, mode):",def test_raw_feature_vector_on_wine(self):,ADD ADD KEEP ADD REP,Add Parameter
added MaltParser param for additional Java args to allow larger heap,"def __init__(self, tagger=None, mco=None, working_dir=None, additional_java_args=None):","def __init__(self, tagger=None, mco=None, working_dir=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
add model save.,"def vectorize_data(path, word_dict):","def data_reader(path, word_dict):",KEEP REP KEEP,Rename Method
Changed the node naming ui (#124),"def __init__(self, *parents, state=None, model=None, name=None):","def __init__(self, name, *parents, state=None, model=None):",KEEP KEEP DEL KEEP KEEP ADD REP,Remove Parameter
"[progress bars] slight changes to progress bars, allow floating point numbers + allow to deactivate eta info","def _progress_update(self, numerator_increment, stage=0, show_eta=True, **kw):","def _progress_update(self, numerator_increment, stage=0, **kw):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
autopep8 + manual pep8,def is_list_empty(inList):,def isListEmpty(inList):,KEEP REP,Rename Method
simplified decisions stumps,def test_create_n_validate_instance(self):,def testValidateAndCreateInstance(self):,KEEP REP,Rename Method
rename allargs() to allarg(),"def test_allargs(): assert allargs(x, Q.zero(x), x*y) == And(Q.zero(x), Q.zero(y)) assert allargs(x, Q.positive(x) | Q.negative(x), x*y) == And(Q.positive(x) | Q.negative(x), Q.positive(y) | Q.negative(y))","def test_allarg(): assert allarg(x, Q.zero(x), x*y) == And(Q.zero(x), Q.zero(y)) assert allarg(x, Q.positive(x) | Q.negative(x), x*y) == And(Q.positive(x) | Q.negative(x), Q.positive(y) | Q.negative(y))",KEEP REP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
transformed camelCase to snake_case test names (#3033),def test_strip_numeric(self):,def testStripNumeric(self):,KEEP REP,Rename Method
parse_text(),"def raw_parse_sents( self, sentences, verbose=False, tokenize_whitespace=False, sentence_split=False, ):","def raw_parse_sents(self, sentences, verbose=False, tokenize_whitespace=False):",KEEP ADD REP KEEP KEEP ADD ADD REP,Add Parameter
Initial parallel implementation of K-Modes and K-Prototypes.,"def init_huang(X, n_clusters, dissim, random_state):","def init_huang(X, n_clusters, dissim):",KEEP KEEP KEEP ADD REP,Add Parameter
Rename independent_distribution to product_distribution.,"def product_distribution(dist, rvs=None, rv_mode=None):","def independent_distribution(dist, rvs=None, rv_mode=None):",KEEP REP KEEP KEEP,Rename Method
Allow carbenes to participate in resonance,def is_atom_able_to_lose_lone_pair(atom):,def is_NOS_able_to_lose_lone_pair(atom):,KEEP REP,Rename Method
lib.add DPI detector,def camel_case_split(identifier: str) -> List[str]:,def camel_case_split(identifier):,KEEP ADD ADD ADD REP,Change Return Type
Replace the use of random and fixed effects terms (#279),def test_distribute_group_specific_effect_over(diabetes_data): ,def test_distribute_random_effect_over(diabetes_data): ,KEEP REP,Rename Method
Minor fixes,def set_option(**kwargs):,def set(**kwargs):,KEEP REP,Rename Method
"Improve experimental ""magic"" commands (#899)","def _get_st_write_from_expr(node, i, parent_type):","def _get_st_write_from_expr(node, i):",KEEP KEEP ADD REP,Add Parameter
"Global object, circuit cache default true, num.processes parameter","def mapping(self, map_type, threshold=0.00000001):","def mapping(self, map_type, threshold=0.00000001, num_workers=4):",KEEP KEEP KEEP REP DEL,Remove Parameter
File-based fast training for Any2Vec models (#2127),"def __init__(self, sentences=None, corpus_file=None, size=100, alpha=0.025, window=5, min_count=5,","def __init__(self, sentences=None, input_streams=None, size=100, alpha=0.025, window=5, min_count=5,",KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
Fixes dataproxy connection object not returning api response. Makes b鈥?(#572),"def test_project_with_connected_account(self, mock_access_token, ApiUrlMock): self._setup_mocks(ApiUrlMock)",def test_project_with_connected_account(self):,KEEP ADD ADD ADD REP,Add Parameter
Update Time Delay model architecture. Update image series sample directory structure.,"def __init__(self, from_csv=None, target_labels=None, datapath=None, image_dimensions=None, csv_label_col=None, csv_image_col=None, time_steps=None):","def __init__(self, from_csv=None, target_labels=None, datapath=None, image_dimensions=None, csv_label_col=None, csv_image_col=None, avep=False):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
use feature map in qsvm kernel,"def test_svm_qkernel_binary_directly(self): svm = get_algorithm_instance(""QSVM.Kernel"") svm.random_seed = self.random_seed svm.setup_quantum_backend(backend='local_qasm_simulator_py', shots=1024)  num_qubits = 2 feature_map = get_feature_map_instance('SecondOrderExpansion') feature_map.init_args(num_qubits=num_qubits, depth=2, entangler_map={0: [1]}) svm.init_args(self.training_data, self.testing_data, None, feature_map, None)  result = svm.run()","def test_svm_qkernel_directly(self): svm = get_algorithm_instance(""QSVM.Kernel"") svm.setup_quantum_backend(backend='local_qasm_simulator_py', shots=1024) svm.random_seed = self.random_seed  params = { 'problem': {'name': 'svm_classification', 'random_seed': self.random_seed}, 'algorithm': {'name': 'QSVM.Kernel'}, 'backend': {'name': 'local_qasm_simulator_py', 'shots': 1024}, 'multiclass_extension': {'name': 'AllPairs', 'estimator': 'QKernalSVM_Estimator'}, }  svm.init_params(params, self.svm_input) result = svm.run()  np.testing.assert_array_almost_equal( result['kernel_matrix_training'], self.ref_kernel_matrix_training, decimal=4) np.testing.assert_array_almost_equal( result['kernel_matrix_testing'], self.ref_kernel_matrix_testing, decimal=4)  self.assertEqual(len(result['svm']['support_vectors']), 4) np.testing.assert_array_almost_equal( result['svm']['support_vectors'], self.ref_support_vectors, decimal=4)  np.testing.assert_array_almost_equal(result['svm']['alphas'], self.ref_alpha, decimal=4) np.testing.assert_array_almost_equal(result['svm']['bias'], self.ref_bias, decimal=4)  ",KEEP REP KEEP KEEP KEEP DEL DEL KEEP KEEP KEEP ADD ADD KEEP REP KEEP REP REP REP REP REP REP REP REP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL KEEP DEL DEL KEEP KEEP KEEP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
Fix flake8 and pylint issues,"def _execute(cmdargs, cmdconfig): experiment, cmdargs = _infer_experiment(cmdargs, cmdconfig)","def execute(cmdargs, cmdconfig): experiment, cmdargs = infer_experiment(cmdargs, cmdconfig)",KEEP REP KEEP KEEP KEEP KEEP REP KEEP,Rename Method
[coordinates.datasource(s)] all readers support column selection in iterator creation,"def __init__(self, data_source, skip=0, chunk=0, stride=1, return_trajindex=False, cols=None): ","def __init__(self, data_source, skip=0, chunk=0, stride=1, return_trajindex=False):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Finished debugging the new INI simulator.,def binary_sigmoid_activation(self):,"def binary_sigmoid_activation(self, x):",KEEP REP DEL,Remove Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def chunked_paras(self, fileids=None):","def chunked_paras(self, files=None):",KEEP KEEP REP,Rename Parameter
Remove dlib.rectangles. Replace with BoundingBox class,def to_bounding_box(self): ,def to_dlib_rect(self): ,KEEP REP,Rename Method
Bug / incompatibility fixes,"def make_log_folder(self, path, folder_format=""run-%05d""):","def make_log_folder(self, path):",KEEP KEEP ADD REP,Add Parameter
Added documentation,"def show_histogram(self, array, name=None, bins=30, env_appendix=""""): """""" Displays the histogramm of an array.  :param array: The array the histogram is calculated of :param name: The name of the window :param bins: Number of bins (== bars) in the histogram :param env_appendix: appendix to the environment name, if used the new env is env+env_appendix """"""","def show_histogram(self, array, name=None, bins=30, env_app=""""):",KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Parameter
Update extracted faces to use PNG EXIF data (#1123),"def _move_faces(self, output_folder, items_output):","def move_faces(self, output_folder, items_output):",KEEP REP KEEP KEEP,Rename Method
"k-prototypes feature matrix is no longer a list of Xnum and Xcat, but a single matrix X; additional argument 'categorical' introduced that identifies the categorical columns","def k_prototypes(X, categorical, n_clusters, gamma, init, n_init, max_iter, verbose):","def k_prototypes(X, n_clusters, gamma, init, n_init, max_iter, verbose):",KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
Add preliminary Distribution.condition_on(),"def _init(self, outcomes, pmf, base):","def _init(self, outcomes, pmf, base, trim):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
Update _rpn.py,"def call(self, inputs, **kwargs):","def call(self, inputs, training=None, **kwargs):",KEEP KEEP KEEP DEL KEEP,Remove Parameter
Add entry points drivers and operatos discovery,"def _discover_local_chemistry_operators(directory=os.path.dirname(__file__), parentname=os.path.splitext(__name__)[0]):","def discover_local_chemistry_operators(directory=os.path.dirname(__file__), parentname=os.path.splitext(__name__)[0]):",KEEP REP KEEP,Rename Method
[coor/api] deprecate chunk_size (now called chunksize).,"def create_file_reader(input_files, topology, featurizer, chunksize=None, **kw):","def create_file_reader(input_files, topology, featurizer, chunk_size=1000, **kw):",KEEP KEEP KEEP KEEP REP KEEP,Rename Parameter
introduced unsupervised equal widthdiscretiser,def test_gold_insts_thrws_system_error_if_confusion_matrix_is_invoked_bfore_classification(self):,def testGoldInstancesThrowSystemExceptionIfConfusionMatrixIsAskedForBeforeClassification(self):,KEEP REP,Rename Method
#minor,"def import_json_to_db(documents, jsonlist):",def import_json_to_db():,KEEP ADD REP,Add Parameter
Add deleteion of non ann-complete docs,"def __init__(self, directory, read_just_mutations=True, delete_incomplete_docs=True):","def __init__(self, directory, read_just_mutations=False):",KEEP KEEP KEEP ADD REP,Add Parameter
closes #24,"def add_embedding(self, mat, metadata=None, label_img=None, global_step=None, tag='default'):","def add_embedding(self, mat, metadata=None, label_img=None, global_step=None):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Prefix legacy and arrow commands with _ (#3563),"def _legacy_add_rows(self, data=None, **kwargs):","def legacy_add_rows(self, data=None, **kwargs):",KEEP REP KEEP KEEP,Rename Method
Refactored remaining toolbox modules.,"def collect_plot_results(self, x_batch, idx=0):","def collect_plot_results(self, X_batch, idx=0):",KEEP KEEP REP KEEP,Rename Parameter
implemented homogenous formula,"def __new__(cls, a=0, b=0, c=0, d=0, real_field=True, norm=None):","def __new__(cls, a=0, b=0, c=0, d=0, real_field=True):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
[transformer] removed lag argument from ctor,"def __init__(self, chunksize=100):","def __init__(self, chunksize=100, lag=0):",KEEP KEEP REP DEL,Remove Parameter
add more tests to Options + fix bug for non string key,def test_initialize_not_locked():,def test_initialize_unlock():,KEEP REP,Rename Method
fix unittests,"def _finish_estimate(self): fh = None if isinstance(self._in_memory_chunks, np.memmap): fh = self._in_memory_chunks.filename del self._in_memory_chunks if fh: os.unlink(fh) if self.init_strategy == 'uniform': del self._centers_iter_list del self._init_centers_indices if self.init_strategy == 'kmeans++': self._progress_force_finish(0) self._progress_force_finish(1)  def _init_estimate(self, stride):  if stride is None: stride = 1  self._cluster_centers_iter = [] self._init_centers_indices = {} self._t_total = 0 traj_lengths = self.trajectory_lengths(stride=stride) total_length = sum(traj_lengths) if not self.n_clusters: self.n_clusters = min(int(math.sqrt(total_length)), 5000) self._logger.info(""The number of cluster centers was not specified, "" ""using min(sqrt(N), 5000)=%s as n_clusters."" % self.n_clusters) if self.init_strategy == 'kmeans++': it = self.data_producer.iterator(stride=stride)  self._progress_register(self.n_clusters, description=""initialize kmeans++ centers"", stage=0) self._progress_register(self.max_iter, description=""kmeans iterations"", stage=1) self._init_in_memory_chunks(total_length) if self.init_strategy == 'uniform':   with conditional(self.fixed_seed, random_seed(42)): for idx, traj_len in enumerate(traj_lengths): self._init_centers_indices[idx] = random.sample(list(range(0, traj_len)), int( math.ceil((traj_len / float(total_length)) * self.n_clusters)))  return stride ","def _param_finish(self): fh = None if isinstance(self._in_memory_chunks, np.memmap): fh = self._in_memory_chunks.filename del self._in_memory_chunks if fh: os.unlink(fh)  if self.init_strategy == 'uniform': del self._centers_iter_list del self._init_centers_indices if self.init_strategy == 'kmeans++': self._progress_force_finish(0) self._progress_force_finish(1) ",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
AppSession.handle_backmsg (#4982),def _handle_git_information_request(self) -> None:,def handle_git_information_request(self) -> None:,KEEP REP KEEP KEEP,Rename Method
add localizer,"def default_loc(num_locations, input_shape): drop = 0.2","def default_loc(num_outputs, num_locations, input_shape): ''' Notes: this model depends on concatenate which failed on keras < 2.0.8 '''  drop = 0.5",KEEP REP DEL KEEP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP KEEP REP,Remove Parameter
Fix lint errors for test/aqua,"def _ad_hoc_data(training_size, test_size, n, gap):","def ad_hoc_data(training_size, test_size, n, gap):",KEEP REP KEEP KEEP KEEP,Rename Method
add obstacle detection to drive_cm(),"def drive_inches(self, dist, dist_to_obstacle=0, blocking=True):","def drive_inches(self, dist, blocking=True):",KEEP KEEP KEEP ADD KEEP,Add Parameter
[Angelica] Extract target labels parameter as user input for neural net classes.,"def __init__(self, image_size, channels, target_labels, time_delay=2, verbose=False):","def __init__(self, image_size, channels, time_delay=2, verbose=False):",KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
Base optimizer (#136),"def i_dep(d, inputs, output, maxiter=None):","def i_dep(d, inputs, output, maxiters=1000):",KEEP KEEP KEEP KEEP REP,Rename Parameter
"Perceptron ranker initial, rankers moved to one source file","def get_features(self, node, context, feats=defaultdict(float)):","def get_features(self, node, feats=defaultdict(float)):",KEEP KEEP KEEP ADD KEEP,Add Parameter
Add job result accumulated time_taken to QuantumInstance (#1400),"def _maybe_split_qobj_by_gates(qobjs: List[QasmQobj], qobj: QasmQobj) -> List[QasmQobj]:","def _maybe_split_qobj_by_gates(qobjs, qobj):",KEEP ADD ADD ADD ADD REP REP,Change Return Type
Minor redesign of the corpus readers.  Instead of using 'items' or,"def sents(self, files=None):","def sents(self, documents=None, categories=None):",KEEP KEEP REP DEL,Remove Parameter
adaptations to bhmm changes,"def __init__(self, nstates=2, lag=1, stride=1, msm_init=None, reversible=True, connectivity='largest', mincount_connectivity=1e-6, observe_active=True, dt_traj='1 step', accuracy=1e-3, maxit=1000):","def __init__(self, nstates=2, lag=1, stride=1, msm_init=None, reversible=True, connectivity='largest', observe_active=True, dt_traj='1 step', accuracy=1e-3, maxit=1000):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP,Add Parameter
send anchor_ratios to AnchorTargetLayer,"def __init__(self, feat_stride, scales, ratios):","def __init__(self, feat_stride, scales):",KEEP KEEP KEEP ADD REP,Add Parameter
Smart Training Implementation (#914),"def _get_headers(self, side, width): """""" Set header row for the final preview frame  Parameters ---------- side: {""a"" or ""b""} The side that the headers should be generated for width: int The width of each column in the preview frame  Returns ------- :class:`numpy.ndarray` The column headings for the given side """"""","def get_headers(self, side, width): ",KEEP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
[base|coor|msm_estimators] Added progress reporter impl and use it in Transformers and Estimators.,"def _estimate_param_scan_worker(estimator, params, X, evaluate, evaluate_args, failfast, progress_reporter=None):","def _estimate_param_scan_worker(estimator, params, X, evaluate, evaluate_args, failfast):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_persistency(self):,def testPersistency(self):,KEEP REP,Rename Method
explicit categorical kwarg,"def fit(self, X, y=None, categorical=None):","def fit(self, X, y=None, **kwargs):",KEEP KEEP KEEP KEEP REP,Add Parameter
Manual tool. Use new ExtractMedia class,"def __init__(self, filename, image, detected_faces=None): logger.trace(""Initializing %s: (filename: '%s', image shape: %s, detected_faces: %s)"", self.__class__.__name__, filename, image.shape, detected_faces)","def __init__(self, filename, image): logger.trace(""Initializing %s: (filename: '%s', image shape: %s)"", self.__class__.__name__, filename, image.shape)",KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD KEEP KEEP KEEP ADD REP,Add Parameter
Remove MongoDB dependencies from tests/functional/branching,"def test_init_w_version_gt_max(setup_pickleddb_database, monkeypatch):","def test_init_w_version_gt_max(create_db_instance, monkeypatch):",KEEP REP KEEP,Rename Parameter
Plugin preset support,def _save_filename(self):,def _savefilename(self):,KEEP REP,Rename Method
_draw to draw,"def draw(self, **kwargs):","def _draw(self, **kwargs):",KEEP REP KEEP,Rename Method
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def tagged_posts(self, fileids=None, simplify_tags=False):","def tagged_posts(self, files=None, simplify_tags=False):",KEEP KEEP REP KEEP,Rename Parameter
Classifier audit (#936),"def __init__(self, model, ax=None, fig=None, classes=None, **kwargs):","def __init__(self, model, ax=None, classes=None, **kwargs):",KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
more on trainers,def summary_moving_average(tensors=None):,"def summary_moving_average(): """""" Create a MovingAverage op and summary for all variables in MOVING_SUMMARY_VARS_KEY. :returns: a op to maintain these average.",KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Add Parameter
Allow carbenes to participate in resonance,def is_atom_able_to_gain_lone_pair(atom):,def is_NOS_able_to_gain_lone_pair(atom):,KEEP REP,Rename Method
rename extra_fetch to before_run (#147),"def _after_run(self, _, vals):","def _after_run(self, ctx, vals):",KEEP KEEP REP KEEP,Rename Parameter
Capture logging message in test code,"def test_create_with_different_configure(self, benchmark_config_py, caplog):","def test_create_with_different_configure(self, benchmark_config_py):",KEEP KEEP ADD REP,Add Parameter
add Triggerable callback,def _trigger(self): val = self.trainer.sess.run(self._tensor),def _trigger_epoch(self): val = self.trainer.sess.run(self.var),KEEP REP KEEP KEEP REP,Rename Method
refactor modules to follow PEP-8 guidelines,"def _show_plot(x_values, y_values, x_labels=None, y_labels=None):","def _show_plot(x_values, y_values, x_labels=None, y_labels=None, y_min=-1.2, y_max=1.2):",KEEP KEEP KEEP KEEP REP DEL DEL,Remove Parameter
DeltaGeneratorTestCase: remove unused setup param (#5628),def setUp(self):,"def setUp(self, override_root=True):",KEEP REP DEL,Remove Parameter
feat(core): allow is_ge to take assumptions,"def is_gt(lhs, rhs, assumptions=None):","def is_gt(lhs, rhs):",KEEP KEEP ADD REP,Add Parameter
New version of documentation. Updated comments and example scripts. Added 'custom_activation' to user settings. Removed redundant evaluation set. Cleaned up package requirements. Changed way to configure toolbox: Console command expects text file now.,"def load_settings(self, s=None):",def load_settings(self):,KEEP ADD REP,Add Parameter
Refractive_Index_Parameter_Considered,"def waist2rayleigh(w, wavelen, n=1):","def waist2rayleigh(w, wavelen):",KEEP KEEP ADD REP,Add Parameter
updates,"def seq2seq_pad_concat_convert(xy_batch, eos_id=2, bos_id=1, n_gpu=0):","def seq2seq_pad_concat_convert(xy_batch, eos_id=2, bos_id=1):",KEEP KEEP KEEP ADD REP,Add Parameter
Pass default index into cell extractors,"def extract_3_cells(cells, index):",def extract_3_cells(cells):,KEEP ADD REP,Add Parameter
Update extracted faces to use PNG EXIF data (#1123),def _compile_output(self):,def compile_output(self):,KEEP REP,Rename Method
Deprecate add_term & add_y. add_formula becomes add,"def _add_y(self, variable, prior=None, family='gaussian', link=None, *args,","def add_y(self, variable, prior=None, family='gaussian', link=None, *args,",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Method
Make rmgpy/tools/* unit tests PEP-8 compliant,def test_inplace_remove_isotope_for_reactions(self):,def testInplaceRemoveIsotopeForReactions(self):,KEEP REP,Rename Method
Speed improvements (#522) (#523),def ask_enable_cuda(): ,def Enable_CUDA():,KEEP REP,Rename Method
more consistent variable names,"def train(self, labeled_sequences=None, unlabeled_sequences=None,","def train(self, labelled_sequences=None, unlabeled_sequences=None,",KEEP KEEP REP KEEP,Rename Parameter
[msm/analysis/correlations] fix case for complex eigenvalues of transfer operator.,"def time_correlation_by_diagonalization(P, pi, obs1, obs2=None, time=1, rdl=None):","def time_correlation_by_diagonalization(P, pi, obs1, obs2=None, time=1, rdl=None, return_rdl=False):",KEEP KEEP KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
support expectation evaluation in for the paulis mode in vqe.,"def construct_evaluation_circuit(self, operator_mode, input_circuit, backend, has_aer=False):","def construct_evaluation_circuit(self, operator_mode, input_circuit, backend):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
wip,"def __init__(self, u, u_const):","def __init__(self, u):",KEEP KEEP ADD REP,Add Parameter
Pool improvements (#141),def delete(self): ,def destroy(self): for store in self.output_stores.values(): store.array.close() ,KEEP REP DEL DEL DEL DEL DEL,Rename Method
Fix bug where info was stuck in a recursive loop,"def __init__(self, name, version, experiment=None, parent=None, children=tuple()):","def __init__(self, name, experiment=None, parent=None, children=tuple()):",KEEP KEEP KEEP ADD KEEP KEEP KEEP,Add Parameter
Vocab blacklist and replace,"def score_answers(answers, name):",def score_answers(answers):,KEEP ADD REP,Add Parameter
wip,"def __init__(self, it, lag, return_trajindex):","def __init__(self, it, it_lagged, return_trajindex):",KEEP KEEP KEEP REP KEEP,Rename Parameter
minor,"def __init__(self, relation_type, entity1, entity2, bidirectional=True):","def __init__(self, relation_type, entity1, entity2):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Updated kinetics classes to use Quantity objects.,"def fitToData(self, Tlist, klist, T0=298.15, numReactants=1):","def fitToData(self, Tlist, klist, T0=298.15):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Fix lint and style issues,"def get_subsystems_postselected(complete_system_counts, index, postselect_value):","def get_subsystems_counts_postselected(complete_system_counts, index, postselect_value):",KEEP REP KEEP KEEP,Rename Method
Load specific version for Experiment if asked,"def __init__(self, name, user=None, version=None):","def __init__(self, name, user=None):",KEEP KEEP KEEP ADD REP,Add Parameter
add augmentation to sessions,"def generator(self, format='keras'):",def generator(self):,KEEP ADD REP,Add Parameter
Improve training performance when using augmentations / crop and minor model improvements (#1050),"def y_transform(self, record: Union[TubRecord, List[TubRecord]]) \ -> Dict[str, Union[float, List[float]]]: """""" Transforms the record into dictionary for y for training the model to x,y. All model ouputs layer's names must be matched by dictionary keys. """"""","def y_transform(self, record: Union[TubRecord, List[TubRecord]]) -> XY:  raise NotImplementedError(f'{self} not ready yet for new training ' f'pipeline')",KEEP KEEP KEEP KEEP KEEP ADD KEEP ADD ADD REP REP REP REP REP REP REP KEEP ADD REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Change Return Type
"ensure auto scaling is applied properly, and PEP8","def _scale_random(self, term): ","def _scale_random(self, term, sd_corr):",KEEP KEEP REP DEL,Remove Parameter
make resnext picklable,"def __init__(self, *args):","def __init__(self, fn, *args):",KEEP KEEP DEL KEEP,Remove Parameter
Pep8 updates,"def are_files_identical(filename1, filename2, debug=True):","def are_files_identical(filename1, filename2):",KEEP KEEP ADD REP,Add Parameter
[plots]: improved plots,"def plot_cktest(cktest, figsize=None, diag=False,  y01=True, layout=None, padding_between=0.1, padding_top=0.075, units='steps', dt=1.):","def plot_cktest(cktest, figsize=None, diag=False, y01=True, layout=None, padding_between=0.1, padding_top=0.075):",KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP ADD ADD REP,Add Parameter
[GSoC 2018] Multistream API for vocabulary building in *2vec (#2078),"def _scan_vocab_singlestream(self, sentences, progress_per, trim_rule):","def scan_vocab(self, sentences, progress_per=10000, trim_rule=None):  logger.info(""collecting all words and their counts"")",KEEP REP KEEP REP REP DEL DEL DEL DEL DEL DEL DEL,Rename Method
Smart Training Implementation (#914),"def _monitor(self, thread): """""" Monitor the background :func:`_training` thread for key presses and errors.  Returns ------- bool ``True`` if there has been an error in the background thread otherwise ``False`` """""" is_preview = self._args.preview","def monitor(self, thread):  is_preview = self.args.preview",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP REP,Rename Method
Added directory to species() and transitionState() CanTherm input blocks.,"def loadSpecies(label, geomLog, statesLog, extSymmetry, spinMultiplicity, freqScaleFactor, linear, rotors, atoms, bonds, directory=None, E0=None, energyLog=None):","def loadSpecies(label, geomLog, statesLog, extSymmetry, spinMultiplicity, freqScaleFactor, linear, rotors, atoms, bonds, E0=None, energyLog=None):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
"more utility tests and some new decorators, closed #89","def __init__(self, model, ax=None, **kwargs):","def __init__(self, ax=None, **kwargs):",KEEP KEEP ADD KEEP KEEP,Add Parameter
New input file format for specifying hindered rotors.,"def loadTransitionState(label, geomLog, statesLog, extSymmetry, freqScaleFactor, linear, rotors, atoms, bonds):","def loadTransitionState(label, geomLog, statesLog, extSymmetry, freqScaleFactor, linear, rotorPivots, rotorTops, rotorScans, rotorSymmetry, atoms, bonds):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL DEL KEEP KEEP,Remove Parameter
Fix Bugs with OperatorStateFn and bind_parameters (#970),"def assign_parameters(self, param_dict: dict) -> OperatorBase:","def bind_parameters(self, param_dict: dict) -> OperatorBase:",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
PCADecomposition test enhancements (#483),"def pca_decomposition(X, y=None, ax=None, features=None, scale=True, proj_dim=2, proj_features=False, color=None, colormap=palettes.DEFAULT_SEQUENCE, random_state=None, **kwargs): """"""Produce a two or three dimensional principal component plot of the data array ``X`` projected onto it's largest sequential principal components. It is common practice to scale the data array ``X`` before applying a PC decomposition. Variable scaling can be controlled using the ``scale`` argument.  Parameters ---------- X : ndarray or DataFrame of shape n x m A matrix of n instances with m features.  y : ndarray or Series of length n An array or series of target or class values.  ax : matplotlib Axes, default: None The axes to plot the figure on. If None is passed in the current axes. will be used (or generated if required).  features: list, default: None a list of feature names to use If a DataFrame is passed to fit and features is None, feature names are selected as the columns of the DataFrame.  scale : bool, default: True Boolean that indicates if user wants to scale data.  proj_dim : int, default: 2 Dimension of the PCA visualizer.  proj_features : bool, default: False Boolean that indicates if the user wants to project the features in the projected space. If True the plot will be similar to a biplot.  color : list or tuple of colors, default: None Specify the colors for each individual class.  colormap : string or cmap, default: None Optional string or matplotlib cmap to colorize lines. Use either color to colorize the lines on a per class basis or colormap to color them on a continuous scale.  random_state : int, RandomState instance or None, optional (default None) If input data is larger than 500x500 and the number of components to extract is lower than 80% of the smallest dimension of the data, then the more efficient `randomized` solver is enabled, this parameter sets the random state on this solver.  kwargs : dict Keyword arguments that are passed to the base class and may influence the visualization as defined in other Visualizers.  Examples -------- >>> from sklearn import datasets >>> iris = datasets.load_iris() >>> X = iris.data >>> y = iris.target >>> pca_decomposition(X, color=y, proj_dim=3, colormap='RdBu_r')  """"""  visualizer = PCADecomposition( ax=ax, features=features, scale=scale, proj_dim=proj_dim, proj_features=proj_features, color=color, colormap=colormap, random_state=random_state, **kwargs )   visualizer.fit(X, y) visualizer.transform(X) visualizer.poof()   return visualizer.ax","def pca_decomposition(X, y=None, ax=None, scale=True, proj_dim=2, colormap=palettes.DEFAULT_SEQUENCE, color=None, **kwargs): """"""Produce a two or three dimensional principal component plot of the data array ``X`` projected onto it's largest sequential principal components. It is common practice to scale the data array ``X`` before applying a PC decomposition. Variable scaling can be controlled using the ``scale`` argument.  Parameters ---------- X : ndarray or DataFrame of shape n x m A matrix of n instances with m features.  y : ndarray or Series of length n An array or series of target or class values.  ax : matplotlib Axes, default: None The axes to plot the figure on.  scale : bool, default: True Boolean that indicates if the values of X should be scaled.  proj_dim : int, default: 2 Dimension of the PCA visualizer.  colormap : string or cmap, default: None Optional string or matplotlib cmap to colorize lines. Use either color to colorize the lines on a per class basis or colormap to color them on a continuous scale.  color : list or tuple of colors, default: None Specify the colors for each individual class.  kwargs : dict Keyword arguments that are passed to the base class and may influence the visualization as defined in other Visualizers.  Examples -------- >>> from sklearn import datasets >>> iris = datasets.load_iris() >>> X = iris.data >>> y = iris.target >>> pca_decomposition(X, color=y, proj_dim=3, colormap='RdBu_r')  """"""  visualizer = PCADecomposition(X=X, y=y, ax=ax, scale=scale, proj_dim=proj_dim, colormap=colormap, color=color)   visualizer.fit(X, y, **kwargs) visualizer.transform(X)   return visualizer.poof() ",KEEP KEEP KEEP KEEP ADD KEEP KEEP ADD ADD KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP REP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP ADD ADD REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP ADD ADD ADD ADD REP REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP ADD ADD KEEP ADD ADD REP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP REP,Add Parameter
Renamed adjacent resonance generation methods,def find_adj_lone_pair_multiple_bond_delocalization_paths(atom1):,def find_lone_pair_multiple_bond_delocalization_paths(atom1):,KEEP REP,Rename Method
Block.tsx refactor (#4053),def column_proto(normalized_weight):,def column_proto(weight):,KEEP REP,Rename Parameter
Make it possible to change default priors for response variable (#335),"def _add_response(self, response, family=""gaussian"", link=None, priors=None):","def _add_response(self, response, prior=None, family=""gaussian"", link=None):",KEEP KEEP KEEP REP REP REP,Rename Parameter
add Unicode deaccent option to simple_preprocess,"def simple_preprocess(doc, deacc=False):",def simple_preprocess(doc):,KEEP ADD REP,Add Parameter
Improve priors and internal model specification (#385),"def pps_negativebinomial(model, posterior, mu, draws, draw_n): mu, idxs = _get_mu_and_idxs(mu, draws, draw_n)","def pps_negativebinomial(model, posterior, mu, draws): mu, idxs = _get_mu_and_idxs(mu, draws)",KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
cascade -> series,def test_StateSpaceModel_series():,def test_StateSpaceModel_cascade():,KEEP REP,Rename Method
Implements histogram alongside ResidualsPlot (#480),def test_prediction_error(self):,def test_pred_error_integration(self):,KEEP REP,Rename Method
Refactored Rejections sampler,@property def next(self):  return self._current_batch_index  @property def total(self):,def new_index(self): self._current_batch_index += 1,ADD KEEP ADD ADD REP KEEP ADD ADD REP REP,Rename Method
Smart Masks to Convert (#957),"def _remove_skipped_faces(self): """""" If the user has specified an input aligned directory, remove any non-matching faces from the alignments file. """"""",def remove_skipped_faces(self): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
"[#37] fix writers ""who"" param","def __init__(self, to_save_to, dataset, who=""ml:nala""):","def __init__(self, to_save_to, dataset):",KEEP KEEP KEEP ADD REP,Add Parameter
Minor Updates,"def __init__(self, parent, configurations, name, theme):","def __init__(self, parent, configurations, name):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_experiment_w_parent_w_name(three_experiments_with_trials, capsys):","def test_experiment_w_parent_w_name(clean_db, three_experiments_with_trials, capsys):",KEEP REP DEL KEEP,Remove Parameter
"Most refactoring done, checkpoints missing","def debug(self, msg, logger=""default""):","def debug(self, msg):",KEEP KEEP ADD REP,Add Parameter
InferenceTask specific key names.,"def read_data(self, node_name, sl, key_version):","def read_data(self, node_name, sl, node_version):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Change status --recursive to --collapse,"def test_three_related_wout_ac(clean_db, three_family_with_trials, capsys):  orion.core.cli.main(['status'])  captured = capsys.readouterr().out  expected = """"""\ test_double_exp =============== status         quantity -----------  ---------- broken                1 completed             1 interrupted           1 new                   1 reserved              1 suspended             1   test_double_exp_child ===================== status         quantity -----------  ---------- broken                1 completed             1 interrupted           1 new                   1 reserved              1 suspended             1   test_double_exp_child2 ====================== status         quantity -----------  ---------- broken                1 completed             1 interrupted           1 new                   1 reserved              1 suspended             1   """"""  assert captured == expected   def test_three_related_branch_wout_ac(clean_db, three_family_branch_with_trials, capsys):  orion.core.cli.main(['status'])  captured = capsys.readouterr().out  expected = """"""\ test_double_exp =============== status         quantity -----------  ---------- broken                1 completed             1 interrupted           1 new                   1 reserved              1 suspended             1   test_double_exp_child ===================== status         quantity -----------  ---------- broken                1 completed             1 interrupted           1 new                   1 reserved              1 suspended             1   test_double_exp_grand_child =========================== status         quantity -----------  ---------- broken                1 completed             1 interrupted           1 new                   1 reserved              1 suspended             1   """"""  assert captured == expected   def test_one_wout_trials_w_a_wout_c(clean_db, one_experiment, capsys):","def test_three_related_w_r_wout_a(clean_db, three_family_with_trials, capsys):  orion.core.cli.main(['status', '--recursive'])",KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Rename Method
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def srl_instances(self, fileids=None, pos_in_tree=None, flatten=True):","def srl_instances(self, files=None, pos_in_tree=None, flatten=True):",KEEP KEEP REP KEEP KEEP,Rename Parameter
BSL remove likelihood estimation node (#430),"def gaussian_syn_likelihood(ssx, ssy, shrinkage=None, penalty=None, whitening=None, standardise=False):","def gaussian_syn_likelihood(*ssx, shrinkage=None, penalty=None, whitening=None, standardise=False, observed=None, **kwargs):",KEEP ADD REP KEEP KEEP KEEP REP DEL DEL,Add Parameter
add timer decorator and new demo,def demo_sent140(): ''' This is an example using only the first 20000 entries of the shuffled training set Sentiment140 training set can be found at: http://help.sentiment140.com/for-students ''' corpus_path = os.path.expanduser('~/nltk_data/corpora/sentiment140/')  tokenizer = treebank.TreebankWordTokenizer() ,def demo():   corpus_path = os.path.expanduser('~/nltk_data/corpora/sentiment140/'),KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP KEEP KEEP KEEP ADD ADD ADD ADD,Rename Method
Otherpoint condition in rec,"def _calc_vel(self, frame, rel_pos):","def _calc_vel(self, frame):",KEEP KEEP ADD REP,Add Parameter
Refactored remaining toolbox modules.,@staticmethod def end_sim():,def end_sim(self):,ADD KEEP REP,Remove Parameter
#24: add option for custom dissimilarity function; some refactoring,"def init_cao(X, n_clusters, dissim):","def init_cao(X, n_clusters):",KEEP KEEP ADD REP,Add Parameter
Fix osx test,"def test_socket_on_osx(self, monkeypatch):",def test_socket_on_osx(monkeypatch):,KEEP ADD REP,Add Parameter
Dynamically generate protobuf python interfaces (#237),"def add_onnx_graph(self, graph, walltime=None):","def add_graph_onnx(self, graph, walltime=None):",KEEP REP KEEP KEEP,Rename Method
[coor] hide impl detail in transformers (fixes #169),def _get_constant_memory(self):,def get_constant_memory(self):,KEEP REP,Rename Method
Resolve some EVC failures,"def test_adapter_rename_missing(self, parent_config, cl_config, storage):","def test_adapter_rename_missing(self, parent_config, cl_config):",KEEP KEEP KEEP ADD REP,Add Parameter
"Global caching works with Aqua 0.4, but for some reason execution is slower. Will convert caching to instance variable of QuantumInstance next.","def eval(self, operator_mode, input_circuit, backend, backend_config=None, compile_config=None, run_config=None, qjob_config=None):","def eval(self, operator_mode, input_circuit, backend, execute_config={}, qjob_config={}):",KEEP KEEP KEEP KEEP KEEP ADD ADD REP REP,Add Parameter
set data source attribute of transformer,"def __init__(self, dmin):","def __init__(self, data_source, dmin):",KEEP KEEP DEL KEEP,Remove Parameter
finish minhash,def jaccard(mhs):,def jaccard(minhashs):,KEEP REP,Rename Parameter
[vamp] w.i.p. to make future-proof for serializable estimators/models,"def cktest(self, n_observables=None, observables='psi', statistics='phi', mlags=10, n_jobs=1, show_progress=False, iterable=None): ","def cktest(self, n_observables=None, observables='psi', statistics='phi', mlags=10, n_jobs=1, show_progress=False): ",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
streamlit.Runtime (#5136),"def initialize(self, runtime: Runtime) -> None: self._runtime = runtime self._session_id: Optional[str] = None","def initialize(self, server: ""Server"") -> None: self._server = server self._session: Optional[AppSession] = None",KEEP KEEP REP REP KEEP KEEP REP KEEP REP REP REP KEEP KEEP,Rename Parameter
Refactor data_utils,"def _try_n_times(fn, n, *args, **kargs): ","def try_n_times(fn, n, *args, **kargs): ",KEEP REP KEEP KEEP KEEP,Rename Method
Close #1777 (#1816),"def _pandas_style_to_css(style_type, style, uuid, separator=""""):","def _pandas_style_to_css(style, uuid, separator=""""):",KEEP ADD REP KEEP KEEP,Add Parameter
a rename in examples (not a breaking change),"def _build_graph(self, inputs): x, y, label = inputs","def _build_graph(self, input_vars): x, y, label = input_vars",KEEP KEEP REP KEEP KEEP KEEP KEEP REP,Rename Parameter
Montecarlo fix,"def get_two_short_notation(self, input_cards, add_O_to_pairs=False):","def get_two_short_notation(self, input_cards):",KEEP KEEP ADD REP,Add Parameter
[vamp] pass scaling to vampmodel and added test,"def set_model_params(self, mean_0, mean_t, C00, Ctt, C0t, dim, epsilon, scaling=None):","def set_model_params(self, mean_0, mean_t, C00, Ctt, C0t, dim, epsilon):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
update corpus and add infer.,"def infer(save_model_path, test_id_path, test_word_path, test_label_path,","def infer(save_model_path, test_word_path, test_label_path,",KEEP KEEP ADD KEEP KEEP,Add Parameter
Added a couple new model tests,def test_many_fixed_effects(crossed_data):,def test_fixed_only_and_check_agreement(crossed_data):,KEEP REP,Rename Method
Make testing/databaseTest.py unit tests PEP-8 compliant,"def kinetics_check_reactant_and_product_template(self, family_name):","def kinetics_checkReactantAndProductTemplate(self, family_name):",KEEP REP KEEP,Rename Method
"update results dict, rename ""history"" variables with ""s"" at end","def _find_next_k(self, k, up, theta_interval, min_ratio=2):","def find_next_k(self, k, up, theta_interval, min_ratio=2):",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
merged devel,"def count_lagged(self, lag, count_mode='sliding', mincount_connectivity='1/n'):","def count_lagged(self, lag, count_mode='sliding'):",KEEP KEEP KEEP ADD REP,Add Parameter
Refactored to new bhmm code,"def bayesian_hidden_markov_model(dtrajs, nstates, lag, nsamples=100, reversible=True, stationary=False, connectivity='largest', observe_active=True, separate=None, conf=0.95, dt_traj='1 step', store_hidden=False, show_progress=True):","def bayesian_hidden_markov_model(dtrajs, nstates, lag, nsamples=100, reversible=True, connectivity='largest', observe_active=True, conf=0.95, dt_traj='1 step', store_hidden=False, show_progress=True):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP,Add Parameter
Plugin preset support,"def __init__(self, top_level, parent, configurations, tree, theme):","def __init__(self, parent, configurations, tree, theme):",KEEP KEEP ADD KEEP KEEP KEEP KEEP,Add Parameter
More rv_names -> rv_mode,"def normalize_rvs(dist, rvs, crvs, rv_mode):","def normalize_rvs(dist, rvs, crvs, rv_names):",KEEP KEEP KEEP KEEP REP,Rename Parameter
transformed camelCase to snake_case test names (#3033),def test_sharding(self):,def testSharding(self):,KEEP REP,Rename Method
Add name to logger.autodir for different runs and simplify (#301),"def auto_set_dir(action=None, name=None):",def auto_set_dir(action=None):,KEEP ADD REP,Add Parameter
Virtual box integration,"def __init__(self, vbox_mode): super().__init__()",def __init__(self):,KEEP ADD ADD REP,Add Parameter
Automatic normalisation feature implemented & normalisation codes can be directly inserted after -n instead of a file name,def filterLowExpression(X):,def detectBestNormalisation(X):,KEEP REP,Rename Method
collapsed _iter/iter_ and non-iter methods; merged nbest_parse into parse; changed return of parse from a single item vs None to an iterator,"def apply(self, chart, grammar, edge1):","def apply_iter(self, chart, grammar, edge1):",KEEP REP KEEP KEEP KEEP,Rename Method
changed the way N and bins were set,"def __init__(self, freqdist, gamma, bins=None, override_N=None):","def __init__(self, freqdist, gamma, bins=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
session_state docstrings (+ minor housekeeping) (#4403),"def _is_keyed_widget_id(key: str) -> bool: return _is_widget_id(key) and not key.endswith(""-None"")","def is_keyed_widget_id(key: str) -> bool: return is_widget_id(key) and not key.endswith(""-None"")",KEEP REP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP,Rename Method
add option for lapack driver for lstsq,"def __init__(self, x, y, disp_res=False, sorted_data=False, lapack_driver='gelsd'):","def __init__(self, x, y, disp_res=False, sorted_data=False):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
-,"def test_resilience(storage, monkeypatch):",def test_resilience(monkeypatch):,KEEP ADD REP,Add Parameter
Optimizing add/mult functions for LogOperations.,"def exp(x, func=np.exp): return func(x) / Z",def exp(x): return np.exp(x) / Z,KEEP ADD REP KEEP REP KEEP KEEP,Add Parameter
SessionState widget registration refactor (#4432),"def _set_widget_metadata(self, widget_metadata: WidgetMetadata) -> None:","def _set_metadata(self, widget_metadata: WidgetMetadata) -> None:",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
Unify optimizer parameters (#1084),"def __init__(self, rho_initial: float = 10000, factor_c: float = 100000, beta: float = 1000, maxiter: int = 10, tol: float = 1.e-4, max_time: float = np.inf, three_block: bool = True, vary_rho: int = UPDATE_RHO_BY_TEN_PERCENT, tau_incr: float = 2, tau_decr: float = 2, mu_res: float = 10, mu_merit: float = 1000, max_iter: Optional[int] = None) -> None:","def __init__(self, rho_initial: float = 10000, factor_c: float = 100000, beta: float = 1000, max_iter: int = 10, tol: float = 1.e-4, max_time: float = np.inf, three_block: bool = True, vary_rho: int = UPDATE_RHO_BY_TEN_PERCENT, tau_incr: float = 2, tau_decr: float = 2, mu_res: float = 10, mu_merit: float = 1000) -> None:",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP KEEP KEEP,Add Parameter
fix some concurrency bug,"def set_logger_dir(dirname, action=None): """""" Set the directory for global logging. :param dirname: log directory :param action: an action (k/b/d/n) to be performed. Will ask user by default. """"""",def set_logger_dir(dirname):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Remove draws argument from model predict (#504),"def posterior_predictive(self, model, posterior, linear_predictor):","def posterior_predictive(self, model, posterior, linear_predictor, draws, draw_n):",KEEP KEEP KEEP KEEP REP DEL DEL,Remove Parameter
lshensemble redis,"def benchmark_lshensemble(threshold, num_perm, num_part, m, storage_config, index_data, query_data):","def benchmark_lshensemble(threshold, num_perm, num_part, m, index_data, query_data):",KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
Made toolbox compatible with new Keras version 1.0,"def normalize_weights(model, X_train, filename=None):","def normalize_weights(model, X_train, path, filename=None):",KEEP KEEP KEEP DEL KEEP,Remove Parameter
fix pylint errors,def _discover_entry_pt_chem_drivers():,def _discover_entry_point_chemistry_drivers():,KEEP REP,Rename Method
"remove transformer lib, use offical.","def __init__(self, d_model_dir=config.electra_D_model_dir, g_model_dir=config.electra_G_model_dir, device=-1):","def __init__(self, d_model_dir=config.electra_D_model_dir, g_model_dir=config.electra_G_model_dir):",KEEP KEEP KEEP ADD REP,Add Parameter
Make rmgpy/rmg/* unit tests PEP-8 compliant,def test_check_for_existing_reaction_keeps_identical_reactions_with_duplicate_flag(self):,def test_checkForExistingReaction_keeps_identical_reactions_with_duplicate_flag(self):,KEEP REP,Rename Method
"Clean up some Python module names (vega_lite, for example) and do some linting.","def _handle_dict_builder_spec(df, user_params, spec_value, curr_out_value,","def handle_dict_builder_spec(df, user_params, spec_value, curr_out_value,",KEEP REP KEEP KEEP KEEP,Rename Method
Core Updates (#1015),"def get_card_most_free(self): """""" Obtain statistics for the GPU with the most available free VRAM.  Returns ------- dict The dictionary contains the following data:  **card_id** (`int`):  The index of the card as pertaining to :attr:`_handles`  **device** (`str`): The name of the device  **free** (`float`): The amount of available VRAM on the GPU  **total** (`float`): the total amount of VRAM on the GPU  If a GPU is not detected then the **card_id** is returned as ``-1`` and the amount of free and total RAM available is fixed to 2048 Megabytes. """""" if self._device_count == 0:","def get_card_most_free(self, supports_plaidml=True): """""" Return the card and available VRAM for active card with most VRAM free """""" if self.device_count == 0 or (self.is_plaidml and not supports_plaidml):",KEEP ADD REP REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP KEEP ADD ADD ADD ADD ADD REP REP REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD REP REP REP REP REP REP REP REP REP REP,Remove Parameter
Change status --recursive to --collapse,"def test_three_unrelated_wout_ac(clean_db, three_experiments_with_trials, capsys):  orion.core.cli.main(['status'])  captured = capsys.readouterr().out  expected = """"""\ test_double_exp ===============","def test_three_unrelated_w_r_wout_a(clean_db, three_experiments_with_trials, capsys):  orion.core.cli.main(['status', '--recursive'])",KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Rename Method
fix how TF session is passed in client object,"def like_or_dislike_users(self, users):","def like_or_dislike_users(self, users, sess):",KEEP KEEP REP DEL,Remove Parameter
Remove exp_config dependency from database tests,"def test_count_query(self, orion_db):","def test_count_query(self, exp_config, orion_db):",KEEP KEEP DEL KEEP,Remove Parameter
minor changes,"@classmethod def ternary_coplanar(cls, q1, q2, q3):","def ternary_coplanar(self, q1, q2):",ADD KEEP REP KEEP ADD REP,Add Parameter
Switch all testing to pytest.,"@pytest.mark.slow @pytest.mark.flaky(reruns=5) @pytest.mark.parametrize('d', [random_distribution(2, 3) for _ in range(5)]) def test_cis1(d):",@attr('scipy') @attr('slow') def test_cis1():,ADD ADD ADD ADD ADD ADD ADD REP REP KEEP REP,Add Parameter
"Ship Audio, Video, and Image(list) elements over HTTP instead of Websockets (#1029)","def marshall_video(proto, data, mimetype=""video/mp4"", start_time=0): """"""Marshalls a video proto, using url processors as needed.","def marshall_video(proto, data, format=""video/mp4"", start_time=0): """"""Marshalls a video proto, using data and url processors as needed.",KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP DEL DEL KEEP KEEP KEEP KEEP,Rename Parameter
remove deprecated function/method/class,"def evaluate_with_result(self, result, statevector_mode, use_simulator_operator_mode=False,","def evaluate_with_result(self, operator_mode=None, circuits=None, backend=None, result=None, use_simulator_operator_mode=False, statevector_mode=None,",KEEP KEEP REP REP DEL DEL KEEP DEL,Remove Parameter
Wrote abstract base class for SNN output model and simulation.,"def wrapper(self): f(self) with warnings.catch_warnings(): warnings.simplefilter('ignore') warnings.warn('deprecated', UserWarning)",def connect_layer(self): ,KEEP ADD ADD ADD ADD ADD ADD REP,Rename Method
RealSense-part added to the self test in realsense435i.py.  Added default config in cfg_complete.py.  Integrated into complete.py,"def __init__(self, width = WIDTH, height = HEIGHT, channels = CHANNELS, enable_rgb=True, enable_depth=True, enable_imu=False, device_id = None):","def __init__(self, enable_rgb=True, enable_depth=True, enable_imu=False, device_id = None):",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
add more parameters to demos and fix python2.6 compatibility issues,"def demo_tweets(trainer, n_instances=None, output=None):",def demo_tweets(trainer):,KEEP ADD ADD REP,Add Parameter
Training startup updates,"def get_image_paths(directory, extension=None):",def get_image_paths(directory):,KEEP ADD REP,Add Parameter
"added data, some bug fixes","def corr2(X): ''' computes correlations between all variable pairs in a segmented time series .. note:: this feature is expensive to compute with the current implementation ''' N = X.shape[0] D = X.shape[2] trii = np.triu_indices(D, k=1) DD = len(trii[0]) r = np.zeros((N, DD)) for i in np.arange(N): rmat = np.corrcoef(X[i])   r[i] = rmat[trii] return r","def _corr_features(X): ''' calculates pearson correlation for all variables in a segmented time series  Parameters ---------- X : array-like shape [n_samples, segment_width, n_variables] segmented time series instance  Returns ------- r : array-like shape [n_samples, n_correlations] correlation feature data ''' D = X.shape[2] N = X.shape[0]  trii = np.triu_indices(D, k=1) DD = len(trii[0]) r = np.zeros((N, DD)) for i in np.arange(N): rmat = np.corrcoef(X[i])  r[i] = rmat[trii] return r ",KEEP REP KEEP REP REP REP REP REP REP KEEP KEEP KEEP KEEP KEEP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP KEEP KEEP DEL DEL DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
Fix tests in general,def setUpClass(cls):,def set_up_class(cls):,KEEP REP,Rename Method
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def __init__(self, root, fileids, extension='',","def __init__(self, root, files, extension='',",KEEP KEEP KEEP REP KEEP,Rename Parameter
prune word2vec vocab automatically if too large,"def __init__( self, sentences=None, size=100, alpha=0.025, window=5, min_count=5, max_vocab_size=10000000, sample=0, seed=1, workers=1, min_alpha=0.0001, sg=1, hs=1, negative=0, cbow_mean=0, hashfxn=hash, iter=1, null_word=0):","def __init__(self, sentences=None, size=100, alpha=0.025, window=5, min_count=5, sample=0, seed=1, workers=1, min_alpha=0.0001, sg=1, hs=1, negative=0, cbow_mean=0, hashfxn=hash, iter=1, null_word=0):",KEEP ADD REP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
revamp Path stringification,"def str_full(self, str_token=lambda t: t.word): return ' '.join(filter(None, [self.str_token_only(str_token), self.str_directed_edge_only()]))","def str_full(self, token_to_string_fun=lambda token: token.word): return ' '.join(filter(None, [self.str_token_only(token_to_string_fun), self.str_directed_edge_only()]))",KEEP KEEP REP REP REP KEEP KEEP KEEP REP KEEP,Rename Parameter
change name for .print,"def _build_graph(self, input_vars):","def _build_graph(self, input_vars, is_training):",KEEP KEEP REP DEL,Remove Parameter
GUI Updates (#940),"def __init__(self, opt_name, tk_var, control_frame, sysbrowser_dict):","def __init__(self, tk_var, control_frame, sysbrowser_dict):",KEEP KEEP ADD KEEP KEEP KEEP,Add Parameter
refine parallel assessment configuration,"def assert_benchmark_figures(figures, num, assessments, tasks): ","def assert_benchmark_figures(figures, num): print(figures)",KEEP KEEP ADD REP REP,Add Parameter
Smart Training Implementation (#914),"def _reload_model(self): """""" Clear out the model from VRAM and reload for the next side to be trained with ping-pong training """"""",def reload_model(self): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
Fixed show_text bug. Apprently the text does not really like a title xD.,"def __show_text(self, text, name=None, env_appendix="""", **kwargs):","def __show_text(self, text, name=None, title=None, env_appendix="""", **kwargs):",KEEP KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
bugfix: Frame ranges for ffmpeg/gif writers,"def __init__(self, output_folder, total_count, frame_ranges, **kwargs): logger.debug(""total_count: %s, frame_ranges: %s"", total_count, frame_ranges)","def __init__(self, output_folder, total_count, **kwargs):",KEEP KEEP KEEP KEEP ADD KEEP ADD ADD ADD ADD ADD ADD,Add Parameter
[#124] Create PMIDReader,"def __init__(self, one_part=False):",def __init__(self):,KEEP ADD REP,Add Parameter
added in brake functionality for simulator only,"def run_threaded(self, steering, throttle, brake=None):","def run_threaded(self, steering, throttle):",KEEP KEEP KEEP ADD REP,Add Parameter
[GSoC 2018] Multistream API for vocabulary building in *2vec (#2078),"def train(self, documents=None, input_streams=None, total_examples=None, total_words=None,","def train(self, documents, total_examples=None, total_words=None,",KEEP KEEP ADD REP KEEP KEEP,Add Parameter
adjust test cases,"def test_experiments_parallel(self, benchmark_config_py, monkeypatch):","def test_experiments_parallel( self, benchmark_config_py, benchmark_algorithms, experiment_config, monkeypatch ): from orion.benchmark import Study from orion.testing import create_experiment  def foo(x): return [dict(name=""result"", type=""objective"", value=x * 2)] ",KEEP REP DEL KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
remove unused imports and refactor variable names,"def extract_features(self, document):","def extract_features(self, tweet):",KEEP KEEP REP,Rename Parameter
update data reader.,"def get_validation_data(input_texts, target_texts, vocab2id, maxlen=400):","def get_validation_data(input_texts, target_texts, char2id, maxlen=400):",KEEP KEEP KEEP REP KEEP,Rename Parameter
Fix Issue #769,"def test_set_state_dict( parser: OrionCmdlineParser, commandline: List[str], json_config: List[str], tmp_path: Path, json_converter, weird_argument: WeirdArgument, ):","def test_set_state_dict(parser, commandline, json_config, tmpdir, json_converter):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP,Add Parameter
Add distributional models (#607),"def make_str(self, extras=None):","def __str__(self, extras=None):",KEEP REP KEEP,Rename Method
Add documentation for PBT,def _truncate(,def truncate(,KEEP REP,Rename Method
Reapply on_config_parsed after applying cli args (#1448),"def on_config_parsed(func, force_connect=False):",def on_config_parsed(func):,KEEP ADD REP,Add Parameter
Legacy alignments update,@staticmethod def get_faces(arguments): ,"def get_faces(self, arguments): """""" If faces argument is specified, load faces_dir otherwise return None """"""",ADD KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
updated with fully working Long division,"def subtract_in(qc, a, b, b0, c ,z, r,n):  ","def subtract_in(qc, a, b, b0, c ,z, r):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP,Add Parameter
"template statistics now can be computed (and sorted) on provided test data, making an interesting comparison with the training","def __init__(self, initial_tagger, rules, training_stats=None):","def __init__(self, initial_tagger, rules):",KEEP KEEP KEEP ADD REP,Add Parameter
"consistently named pretty print methods, resolves #804","def pretty_format(self, width=70, prefix='', depth=4):","def pp(self, width=70, prefix='', depth=4):",KEEP REP KEEP KEEP KEEP,Rename Method
[Angelica] Move validation split from processing to neural net classes.,"def extract_hog_feature(self, params, image):","def _extract_hog_feature(self, params, image):",KEEP REP KEEP KEEP,Rename Method
Make rmgpy/rmg/* unit tests PEP-8 compliant,def test_react(self):,def testReact(self):,KEEP REP,Rename Method
pattern.vector,def sigmoid_derivative(y):,def dsigmoid(y):,KEEP REP,Rename Method
[WIP] fix import and bring in actual updated code,"def __init__(self, num_target_qubits, value, geq=True, i_state=None, i_compare=None, i_objective=None):","def __init__(self, num_target_qubits, value, geq=True):",KEEP KEEP KEEP KEEP ADD ADD ADD REP,Add Parameter
Fixes for separate development data file in alex-context,"def _load_trees(self, ttree_file, selector=None):","def _load_trees(self, ttree_file):",KEEP KEEP ADD REP,Add Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def tagged_sents(self, fileids=None, simplify_tags=False):","def tagged_sents(self, files=None, simplify_tags=False):",KEEP KEEP REP KEEP,Rename Parameter
Updated variable names,"def print_coverage(module_path, c, c_missing_doc, c_missing_doctest, c_indierect_doctest, c_sph, f, f_missing_doc, f_missing_doctest, f_indierect_doctest, f_sph, score, total_doctests, total_members,","def print_coverage(module_path, c, c_md, c_mdt, c_idt, c_sph, f, f_md, f_mdt, f_idt, f_sph, score, total_doctests, total_members,",KEEP KEEP KEEP REP REP REP KEEP KEEP REP REP REP KEEP KEEP KEEP KEEP,Rename Parameter
fixes readers,"def _reshape(self, array):","def __reshape(self, array):",KEEP REP KEEP,Rename Method
Smart Masks to Convert (#957),"def _add_actions(self, parent, config_key): """""" Add Action Buttons.  Parameters ---------- parent: tkinter object The tkinter object that will hold this configuration frame config_key: str The section/plugin key for these configuration options """"""","def add_actions(self, parent, config_key): ",KEEP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
address some review comments,"def test_figure_layout(self, algorithms, generate_experiment_trials):",def test_figure_layout(self):,KEEP ADD ADD REP,Add Parameter
Add support for disabling Streamlit with st.set_config({'client.enabled': False}),"def __init__(self, enabled=True):",def __init__(self):,KEEP ADD REP,Add Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def docs(self, fileids=None): return concat([StreamBackedCorpusView(fileid, self._read_block,","def docs(self, files=None): return concat([StreamBackedCorpusView(filename, self._read_block,",KEEP KEEP REP KEEP REP KEEP,Rename Parameter
Bugfixes:,def _selections_to_list(self) -> List[str]:,def _selections_to_list(self):,KEEP ADD ADD REP,Change Return Type
Minor refactor: Make creation of `Experiment` objects more explicit (#968),"def test_reserve_success(self, random_dt, space: Space):","def test_reserve_success(self, random_dt):",KEEP KEEP ADD ADD REP,Add Parameter
Fixed ranges,"def get_current_call_value(self,p):",def get_current_call_value(self):,KEEP REP,Add Parameter
Bugfix: Alignments don't error on from-faces job,"def _sort_alignments(self, alignments: Dict[str, Dict[str, List[Tuple[int, AlignmentFileDict, str, dict]]]] ) -> Dict[str, Dict[str, List[AlignmentFileDict]]] :","def _sort_alignments(self, alignments: dict) -> dict:",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD REP KEEP ADD ADD ADD REP,Change Return Type
update docs/logging/deprecation,def get_data(train_or_test):,"def get_data(train_or_test, fake=False): if fake: return FakeData([[64, 224, 224, 3], [64]], 1000, random=False, dtype='uint8')",KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
map features of TokenTextgenerator,"def token_features(self, token, addendum, edge, feature_set, is_training_mode): feature_name_1 = self.gen_prefix_feat_name(""prefix_txt"", addendum, token.word)","def token_features(self, token, prefix, edge, feature_set, is_training_mode): feature_name_1 = '73_'+prefix+'txt_'+token.word+'_[0]'",KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP ADD ADD REP,Rename Parameter
simplified decisions stumps,def test_string_representation(self):,def testStringRepresentation(self):,KEEP REP,Rename Method
"""runner.fastReruns"" experimental feature (#4628)",def get_widget_states(self) -> List[WidgetStateProto]:,def as_widget_states(self) -> List[WidgetStateProto]:,KEEP REP KEEP KEEP,Rename Method
added option to allow PTB MXPOST parentheses,"def tokenize(self, tokens, convert_parentheses=False):","def tokenize(self, tokens):",KEEP KEEP ADD REP,Add Parameter
Added ability to change input channel size,"def vanilla_encoder(input_height=224,  input_width=224, channels=3):","def vanilla_encoder(input_height=224,  input_width=224):",KEEP KEEP KEEP ADD REP,Add Parameter
harmonic potential has been tested and now works correctly. This is the reference version for harmonic potential.,"def construct_circuit(self, mode, reverse = False, shift = False, register=None):","def construct_circuit(self, mode, ordering = 'normal', shift = False, register=None):",KEEP KEEP KEEP REP KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
"custom training results name, updated test params, print current test","def save_results(results, name):",def save_results(results):,KEEP ADD REP,Add Parameter
allow softness in consistency checking 鈥?partially solves: https://github.com/Rostlab/relna/issues/22,"def __init__(self, directory, read_only_class_id=None, delete_incomplete_docs=True, is_predicted=False, read_relations=False, whole_basename_as_docid=False, raise_exception_on_incosistencies=True):","def __init__(self, directory, read_only_class_id=None, delete_incomplete_docs=True, is_predicted=False, read_relations=False, whole_basename_as_docid=False):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
still some bugs present. getting closer,def draw(self):,def _draw(self):,KEEP REP,Rename Method
Serialize masks to alignments file,"def train_one_batch(self, do_preview):",def train_one_batch(self):,KEEP ADD REP,Add Parameter
Make Arkane unit tests PEP-8 compliant,def test_tunneling(self):,def testTunneling(self):,KEEP REP,Rename Method
maybe more negatives should be a thing,"def test_booster_boosts_the_score(self): pos = ""The food is really great"" neg = ""The service is really horrible""  pos_score = self.si.polarity_scores(pos) neg_score = self.si.polarity_scores(neg)  self.assertEqual(pos_score[""compound""], 0.659) self.assertEqual(neg_score[""compound""], -0.5849)","def test_booster_increases_the_score(self): line = ""The food is really great"" scores = self.si.polarity_scores(line) self.assertEqual(scores[""compound""], 0.659)",KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP KEEP ADD ADD,Rename Method
Faceswap 2.0 (#1045),"def _faceswap_logrecord(*args, **kwargs): """""" Add a flag to :class:`logging.LogRecord` to not strip formatting from particular records. """""" record = _old_factory(*args, **kwargs)","def faceswap_logrecord(*args, **kwargs):  record = old_factory(*args, **kwargs)",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP KEEP REP KEEP,Rename Method
[msm/estimation] Added sparse_return keyword,"def count_matrix_mult(dtrajs, lag, sliding=True, sparse=True):","def count_matrix_mult(dtrajs, lag, sliding=True):",KEEP KEEP KEEP ADD REP,Add Parameter
Wrapper for FastText (#847),"def word_vec(self, word, use_norm=False): """""" Accept a single word as input. Returns the word's representations in vector space, as a 1D numpy array.  Example::  >>> trained_model.word_vec('office', use_norm=True) array([ -1.40128313e-02, ...])  """""" if word in self.vocab: if use_norm: return self.syn0norm[self.vocab[word].index] else: return self.syn0[self.vocab[word].index] else: raise KeyError(""word '%s' not in vocabulary"" % word) ","def word_vec(word): if isinstance(word, ndarray): return word elif word in self.vocab: all_words.add(self.vocab[word].index) return self.syn0norm[self.vocab[word].index] else: raise KeyError(""word '%s' not in vocabulary"" % word)  positive = [word_vec(word) for word in positive] negative = [word_vec(word) for word in negative]",KEEP ADD ADD REP REP REP REP REP KEEP ADD ADD ADD ADD REP REP KEEP ADD REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP KEEP ADD ADD REP,Add Parameter
Started refactoring project.,"def __scroll_handler(self, *l): op, how_many = l[0], l[1]","def __scrollHandler(self, *L): op, howMany = L[0], L[1]",KEEP REP REP KEEP REP KEEP REP REP,Rename Method
AMD Support for Manual Tool,"def init_extractor(self, loglevel, amd): ","def init_extractor(self, loglevel): ",KEEP KEEP ADD REP,Add Parameter
Change status --recursive to --collapse,"def test_two_related_w_a_wout_c(clean_db, family_with_trials, capsys):","def test_two_related_w_a_wout_r(clean_db, family_with_trials, capsys):",KEEP REP KEEP KEEP,Rename Method
gif writer: Create new filename if output pre-exists,"def _set_dimensions(self, frame_dims: str) -> None: """""" Set the attribute :attr:`_output_dimensions` based on the first frame received. This protects against different sized images coming in and ensure all images get written to the Gif at the sema dimensions. """"""","def set_dimensions(self, frame_dims): """""" Set the dimensions based on a given frame frame. This protects against different sized images coming in and ensure all images go out at the same size for writers that require it """"""",KEEP ADD ADD ADD REP REP KEEP KEEP KEEP ADD REP KEEP KEEP REP REP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP REP REP REP REP REP DEL DEL KEEP,Rename Method
Minor: rename Qchem as QChem,def testLoadNpropylModesFromQChemLog(self):,def testLoadNpropylModesFromQchemLog(self):,KEEP REP,Rename Method
update docs,"def __init__(self, multipliers, verbose=True):","def __init__(self, multipliers, verbose=True, log=None):",KEEP KEEP KEEP REP DEL,Remove Parameter
"Simplify tests suite, remove spy_phase and related functions (#886)",def test_has_observed(self):,"@phase def test_has_observed(self, mocker, num, attr):",DEL KEEP REP DEL DEL DEL,Remove Parameter
units docs: setting dimensions and scale factors for unit system vs globally,"def set_quantity_dimension(self, quantity, dimension): """""" Set the dimension for the quantity in a unit system.  If this relation is valid in every unit system, use ``quantity.set_global_dimension(dimension)`` instead. """"""","def set_quantity_dimension(self, unit, dimension):",KEEP KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Parameter
Stats optimization (#1067),"def _select_item(self, event): """""" Update the session summary info with the selected item or launch graph.  If the mouse is clicked on the graph icon, then the session summary pop-up graph is launched. Otherwise the selected ID is stored.  Parameters ---------- event: :class:`tkinter.Event` The tkinter mouse button release event """""" region = self._tree.identify(""region"", event.x, event.y) selection = self._tree.focus() values = self._tree.item(selection, ""values"")","def select_item(self, event): """""" Update the session summary info with the selected item or launch graph """""" region = self.tree.identify(""region"", event.x, event.y) selection = self.tree.focus() values = self.tree.item(selection, ""values"")",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP REP KEEP KEEP REP KEEP,Rename Method
user-specified starting values for HMMs,"def __init__(self, dtrajs, nstate, lag=1, conv=0.01, maxiter=None, timeshift=None, TCinit = None, chiInit = None):","def __init__(self, dtrajs, nstate, lag=1, conv=0.01, maxiter=None, timeshift=None):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD REP,Add Parameter
Prepare Distribution to be base class for JointDistribution.,"def __init__(self, pmf, events=None, alphabet=None, base=None,","def __init__(self, pmf, events=None, eventspace=None, base=None,",KEEP KEEP KEEP KEEP REP KEEP,Rename Parameter
added several demo functions and reorganized code,"def _demo_prepare_data(tagged_data, train, num_sents, randomize, separate_baseline_data):   if tagged_data is None: print(""Loading tagged data from treebank... "") tagged_data = treebank.tagged_sents() if num_sents is None or len(tagged_data) <= num_sents: num_sents = len(tagged_data) if randomize: random.seed(len(tagged_data)) random.shuffle(tagged_data) cutoff = int(num_sents * train) training_data = tagged_data[:cutoff] gold_data = tagged_data[cutoff:num_sents] testing_data = [[t[0] for t in sent] for sent in gold_data] if not separate_baseline_data: baseline_data = training_data else: bl_cutoff = len(training_data) // 3 (baseline_data, training_data) = (training_data[:bl_cutoff], training_data[bl_cutoff:]) (trainseqs, traintokens) = corpus_size(training_data) (testseqs, testtokens) = corpus_size(testing_data) (bltrainseqs, bltraintokens) = corpus_size(baseline_data) print(""Read testing data ({0:d} sents/{1:d} wds)"".format(testseqs, testtokens)) print(""Read training data ({0:d} sents/{1:d} wds)"".format(trainseqs, traintokens)) print(""Read baseline data ({0:d} sents/{1:d} wds) {2:s}"".format( bltrainseqs, bltraintokens, """" if separate_baseline_data else ""[reused the training set]"")) return (training_data, baseline_data, gold_data, testing_data)","def _demo_prepare_data(tagged_data, train, num_sents, randomize):   if tagged_data is None: print(""Loading tagged data from treebank... "") tagged_data = treebank.tagged_sents() if num_sents is None or len(tagged_data) <= num_sents: num_sents = len(tagged_data) if randomize: random.seed(len(tagged_data)) random.shuffle(tagged_data) cutoff = int(num_sents * train) training_data = tagged_data[:cutoff] gold_data = tagged_data[cutoff:num_sents] testing_data = [[t[0] for t in sent] for sent in gold_data] return (training_data, gold_data, testing_data) ",KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP ADD KEEP KEEP,Add Parameter
Remove warning from vectorize tool. Make it a bit more robust. (#183),"def simulator(a, b, random_state=None):","@elfi.tools.vectorize def simulator(a, b, random_state=None, index_in_batch=None):",DEL KEEP KEEP KEEP REP DEL,Remove Parameter
[testing] minor changes,def setup_pyemma_config(): ,@pytest.fixture(scope='session') def no_progress_bars(): ,DEL KEEP REP,Rename Method
[WIP] move the additional params to only euro-call-exp-val and q_factory,"def __init__(self, num_target_qubits, value, geq=True):","def __init__(self, num_target_qubits, value, geq=True, i_state=None, i_compare=None, i_objective=None):",KEEP KEEP KEEP KEEP REP DEL DEL DEL,Remove Parameter
Fix qsvm unit tests,def test_qsvm_variational_with_minibatching(self):,def todo_test_qsvm_variational_with_minibatching(self):,KEEP REP,Rename Method
[msm...]: PEP 8 coding style and other cosmetics,"def timescales_from_eigenvalues(ev, tau=1):","def timescales_from_eigenvalues(eval, tau=1):",KEEP REP KEEP,Rename Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def sents(self, fileids=None, categories=None):","def sents(self, files=None, categories=None):",KEEP KEEP REP KEEP,Rename Parameter
Remove unused parameter,"def __init__(self, images, target_dimensions=None, augment_data=False, rgb=False, time_series=False):","def __init__(self, images, target_dimensions=None, augment_data=False, rgb=False, channels=3, time_series=False):",KEEP KEEP KEEP KEEP KEEP KEEP DEL KEEP,Remove Parameter
Adjust points at which loglike function is evaluated,"def _get_second_deriv(self, exog, predictor, full_mod=None, points=3):","def _get_second_deriv(self, exog, predictor, full_mod=None, length=3, increment=.1):",KEEP KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
Fix serving tests,"def __init__(self, storage): self.storage = storage",def __init__(self): self.storage = setup_storage(),KEEP ADD REP KEEP KEEP REP,Add Parameter
wip for updating constructors,"def __init__(self, num_qubits, state=""zero"", state_vector=None): """"""Constructor.","def init_args(self, num_qubits, state=""zero"", state_vector=None): """"""",KEEP REP KEEP KEEP KEEP REP,Rename Method
[analysis/api] Added ncv keyword to rdl_decomposition,"def rdl_decomposition(T, k=None, norm='standard', ncv=None):","def rdl_decomposition(T, k=None, norm='standard'):",KEEP KEEP KEEP ADD REP,Add Parameter
"""runner.fastReruns"" experimental feature (#4628)",def require_valid_user_key(key: str) -> None: ,def validate_key(key: str) -> None: ,KEEP REP KEEP KEEP KEEP,Rename Method
further rename in tests,def test_qsvm_multiclass_one_against_all(self):,def test_qsvm_kernel_multiclass_one_against_all(self):,KEEP REP,Rename Method
remove operator_mode setting,"def __init__(self, operator, optimizer, p=1, initial_state=None, mixer=None,","def __init__(self, operator, optimizer, p=1, initial_state=None, mixer=None, operator_mode=None,",KEEP KEEP KEEP KEEP KEEP KEEP KEEP DEL,Remove Parameter
"Fix error ""connection error"" error message (#136)","def __init__(self, ioloop, script_path, command_line):","def __init__(self, ioloop, script_path, script_argv):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Fix AMD Tests + docs,"def train_args(model, model_path, faces, iterations=1, batchsize=4, extra_args=""""):","def train_args(model, model_path, faces, alignments, iterations=5, batchsize=8, extra_args=""""):",KEEP KEEP KEEP KEEP REP REP DEL KEEP,Remove Parameter
"Adding tools.py as main script for using tools, as well as integrating all feature requests from #255 and #278 (#298)",@staticmethod def find_images(input_dir):,"def find_images(self, input_dir):",ADD KEEP REP DEL,Remove Parameter
"refactor complete, to test on pi","def __init__(self, session=None, sessions_dir=None):","def __init__(self, session=None):",KEEP KEEP ADD REP,Add Parameter
tiny,"def test(data_set, mx_model, batch_size, nfolds, data_extra = None, label_shape = None):","def test(data_set, mx_model, batch_size, data_extra = None, label_shape = None):",KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
Faceswap 2.0 (#1045),"def __init__(self, name, model_path, model_kwargs=None, allow_growth=False, exclude_gpus=None):","def __init__(self, name, model_path, model_kwargs=None, allow_growth=False):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
ElfiDistribution interface,"def random_wrapper(rvs, input_dict):","def distribution_wrapper(rvs, input_dict):",KEEP REP KEEP,Rename Method
some more cosmetic changes,def test_error_count(self):,def testErrorCount(self):,KEEP REP,Rename Method
switch to configparser,"def check_if_image_in_range(img, screenshot, x1, y1, x2, y2, extended=False):","def check_if_image_in_range(img, screenshot, x1, y1, x2, y2):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
dragging along refactor changes,"def estimate_markov_model(dtrajs, lag, reversible=True, sparse=False, connectivity='largest', compute=True,","def msm(dtrajs, lag, reversible=True, sparse=False, connectivity='largest', compute=True,",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Method
Fix tests for numpy representation,def parse_kgs_coords(s):,def parse_coords(s):,KEEP REP,Rename Method
(backwards incompatible) nltk.sourcedstring is removed,"def sents(self, fileids=None):","def sents(self, fileids=None, sourced=False):",KEEP KEEP REP DEL,Remove Parameter
Save changes,"def save_image_grid(self, tensor, name, n_iter=None, prefix=False, iter_format=""{:05d}"", nrow=8, padding=2,","def store_image_grid(self, tensor, name, n_iter=None, prefix=False, iter_format=""{:05d}"", nrow=8, padding=2,",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
rpn regression loss,@staticmethod def subsample_negative_labels(labels): num_bg = RPN_BATCHSIZE - numpy.sum(labels[labels == 1]),"def subsample_negative_labels(self, labels): num_bg = self.RPN_BATCHSIZE - numpy.sum(labels == 1)",ADD KEEP REP DEL KEEP KEEP REP KEEP REP KEEP REP,Remove Parameter
refactoring of circuit factory (getting rid of params),"def __init__(self, num_target_qubits, i_objective):","def __init__(self, num_target_qubits):",KEEP KEEP ADD REP,Add Parameter
Add option to change dlib-cnn buffer size,"def __init__(self, input_image_bgr, detector, dlib_buffer=64, mtcnn_kwargs=None, verbose=False, input_is_predetected_face=False):","def __init__(self, input_image_bgr, detector, mtcnn_kwargs=None, verbose=False, input_is_predetected_face=False):",KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP,Add Parameter
1. update svm qkernel binary with pluggable feature map,"def get_predictied_confidence(self, data, return_kernel_matrix=False):","def _get_prediction(self, data, return_kernel_matrix=False):",KEEP REP KEEP KEEP,Rename Method
change from test to inference,"def get_validation_data(video_path, annotation_path, dataset_name, file_type, spatial_transform=None, temporal_transform=None, target_transform=None):","def get_validation_set(video_path, annotation_path, dataset_name, file_type, spatial_transform=None, temporal_transform=None, target_transform=None):",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
refactor imgaug,"def _augment(self, img, _):","def _augment(self, img):",KEEP KEEP ADD REP,Add Parameter
Filter wikipedia articles by their namespace,"def _extract_pages(f, filter_namespaces=False):",def _extract_pages(f):,KEEP ADD REP,Add Parameter
Adapt codebase to new name Orion (#61),"def test_insert_one(self, database, orion_db):","def test_insert_one(self, database, moptdb):",KEEP KEEP KEEP REP,Rename Parameter
[coordinates.datasource(s)] all readers support column selection in iterator creation,"def _create_iterator(self, skip=0, chunk=0, stride=1, return_trajindex=False, cols=None):","def _create_iterator(self, skip=0, chunk=0, stride=1, return_trajindex=False):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Revert reviewer change,"def _eval_simplify(self, *args, **kwargs): a, b = (x.simplify(**kwargs).factor() for x in self.args)","def _eval_simplify(self, a, b, **kwargs): a = a.simplify(**kwargs).factor() b = b.simplify(**kwargs).factor()",KEEP KEEP REP REP REP REP KEEP ADD REP REP REP REP,Remove Parameter
pep8 fixes,"def extract_ner_labels(self, predicted_labels):","def extract_labels(self,predicted_labels):",KEEP ADD REP,Rename Method
Started refactoring project.,"def check_file(self, p):","def check_file(self, P):",KEEP KEEP REP,Rename Parameter
float32 random; diversified dv seed; disable bad test,def disabled_test_infer_vector(self):,def test_infer_vector(self):,KEEP REP,Rename Method
New documentation (#166),"def set_objective(self, n_samples, threshold=None, quantile=None, n_sim=None):","def init_inference(self, n_samples, threshold=None, quantile=None, n_sim=None):",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
Update `ntheory.digits` - tweak `is_palindromic` and `count_digits` + update tests,def test_is_palindromic__base_smaller_than_2__raises_value_error():,def test_is_palindromic_integer__base_smaller_than_2__raises_value_error():,KEEP REP,Rename Method
[coordinates.clustering.interface]: advancing Martin's fix for dimension(): @doc_inherit removed as there is no superclass impl,"def assign(self, X=None, stride=1):","def assign(self, X):",KEEP KEEP ADD REP,Add Parameter
remove unused keyword,"def padded_key(key, symbols):","def padded_key(key, symbols, filter=True):",KEEP KEEP REP DEL,Remove Parameter
"changed parameter name from ""language"" to ""lang""","def pos_tag(tokens, tagset=None, lang='eng'):","def pos_tag(tokens, tagset=None, language='english'):",KEEP KEEP KEEP REP,Rename Parameter
Add ReshapedSpace and Linearize transformer,"def reverse(self, transformed_point, index=None):","def reverse(self, transformed_point):",KEEP KEEP ADD REP,Add Parameter
"Remove IndexedBase, use extension in Poly","def solve_riccati(fx, x, b0, b1, b2):","def solve_riccati(eq, fx, x, b0, b1, b2):",KEEP REP DEL KEEP KEEP KEEP KEEP,Remove Parameter
added gym RL examples,"def observe(self, reward, terminal, train_policy=True, feed_dict=None):","def observe(self, reward, terminal, mode):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Ensure that s3.url is an absolute URL (#828),def test_check_conflicts_s3_credentials(self):,def test_check_conflicts_4(self):,KEEP REP,Rename Method
Base optimizer (#136),"def i_broja(d, inputs, output, maxiter=1000):","def i_broja(d, inputs, output, maxiters=1000):",KEEP KEEP KEEP KEEP REP,Rename Parameter
New documentation (#166),"def set_objective(self, *args, **kwargs):","def init_inference(self, *args, **kwargs):",KEEP REP KEEP KEEP,Rename Method
clean laplace results (#563),"def _clean_results(self, idata, omit_offsets, include_mean):","def _clean_mcmc_results(self, idata, omit_offsets, include_mean):",KEEP REP KEEP KEEP KEEP,Rename Method
Clean up feature making code,"def geoparse(self, doc, verbose = False): """"""Main geoparsing function. Text to extracted, resolved entities  Parameters ---------- doc : str (or spaCy) The document to be geoparsed. Can be either raw text or already spacy processed. In some cases, it makes sense to bulk parse using spacy's .pipe() before sending through to Mordecai  Returns ------- proced : list of dicts Each entity gets an entry in the list, with the dictionary including geo info, spans, and optionally, the input features. """"""","def geoparse(self, doc): ",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
refactoring of circuit factory (getting rid of params),"def __init__(self, a_factory, i_objective):","def __init__(self, a_factory):",KEEP KEEP ADD REP,Add Parameter
Add alternative default priors (#360),"def _set_priors(self, priors=None, common=None, group_specific=None):","def _set_priors(self, priors=None, common=None, group_specific=None, match_derived_names=True):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
"Global caching works with Aqua 0.4, but for some reason execution is slower. Will convert caching to instance variable of QuantumInstance next.","def __init__(self, num_qubits, state=""zero"", state_vector=None): """"""Constructor.","def init_args(self, num_qubits, state=""zero"", state_vector=None): """"""",KEEP REP KEEP KEEP KEEP REP,Rename Method
[#60] regex optimize,"def has_dna_symbols(self, str):","def dna_symbols(self, str):",KEEP REP KEEP,Rename Method
[coordinates.api] Renamed NystroemTICA api function,"def tica_nystroem(data, lag, max_columns,","def nystroem_tica(data, lag, max_columns,",KEEP REP KEEP KEEP,Rename Method
Add masker to Travis Tests,"def extract_args(detector, aligner, masker, in_path, out_path, args=None):","def extract_args(detector, aligner, in_path, out_path, args=None):",KEEP KEEP KEEP ADD KEEP KEEP KEEP,Add Parameter
nltk/corpus/reader/util.py,"def tagged_words(self, documents=None): return self._pos_reader.tagged_words(documents) def tagged_sents(self, documents=None): return self._pos_reader.tagged_sents(documents) def tagged_paras(self, documents=None): return self._pos_reader.tagged_paras(documents) def chunked_words(self, documents=None): return self._pos_reader.chunked_words(documents) def chunked_sents(self, documents=None): return self._pos_reader.chunked_sents(documents) def chunked_paras(self, documents=None): return self._pos_reader.chunked_paras(documents) def parsed_sents(self, documents=None): return self._mrg_reader.parsed_sents(documents)","def tagged_words(self, items=None): return self._pos_reader.tagged_words(items) def tagged_sents(self, items=None): return self._pos_reader.tagged_sents(items) def tagged_paras(self, items=None): return self._pos_reader.tagged_paras(items) def chunked_words(self, items=None): return self._pos_reader.chunked_words(items) def chunked_sents(self, items=None): return self._pos_reader.chunked_sents(items) def chunked_paras(self, items=None): return self._pos_reader.chunked_paras(items) def parsed_sents(self, items=None): return self._mrg_reader.parsed_sents(items)",KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP,Rename Parameter
Mainly PEP8,"def test(left, right):","def test(s, t):",KEEP REP REP,Rename Parameter
add statevector_simulator support for dj,"def construct_circuit(self, measurement=False): """""" Construct the quantum circuit  Args: measurement (bool): Boolean flag to indicate if measurement should be included in the circuit.  Returns: the QuantumCircuit object for the constructed circuit """""" ",def construct_circuit(self):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
1. fix copyright,"def __init__(self, paulis, basis, atol=1e-12, name=None): super().__init__(paulis, basis, atol, name=name)","def __init__(self, paulis, basis, atol=1e-12): super().__init__(paulis, basis, atol)",KEEP KEEP KEEP KEEP ADD REP KEEP KEEP ADD REP,Add Parameter
Adapted aedat methods to incorporate different frame generation mechanisms.,"def get_binary_frame(xaddr, yaddr, timestamps, pol, is_x_first, is_x_flipped, is_y_flipped, shape, data_format, frame_width):","def get_binary_frame(xaddr, yaddr, timestamps, shape, data_format, frame_width):",KEEP KEEP KEEP KEEP ADD ADD ADD ADD KEEP KEEP KEEP,Add Parameter
remove QMTP driver class as parameter from qmverifier,"def __init__(self,molfile):","def __init__(self,molfile, QMTP):",KEEP REP DEL,Remove Parameter
update docs,def validate_coords(coords):,def _valid_coords(coords):,KEEP REP,Rename Method
Update matplotlib requirement,"def _axes_set_yscale(self, scale: str) -> None: """""" Set the Y-Scale to log or linear  Parameters ---------- scale: str Should be one of ``""log""`` or ``""linear""`` """"""","def axes_set_yscale(self, scale): ",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Rename Method
Features Audit (part 1) (#945),"def __init__( self, ax=None, fig=None, algorithm=None, features=None, show_feature_names=True, **kwargs ):","def __init__(self, ax=None, algorithm=None, features=None, show_feature_names=True, **kwargs):",KEEP ADD REP KEEP ADD KEEP KEEP KEEP ADD REP,Add Parameter
Make rmgpy/thermo/* unit tests PEP-8 compliant,def test_to_wilhoit(self):,def testToWilhoit(self):,KEEP REP,Rename Method
Merge branch 'temporal_pattern_coding',"def get_eventframe_sequence(xaddr, yaddr, timestamps, pol, is_x_first, is_x_flipped, is_y_flipped, shape, data_format, frame_width):","def get_eventframe_sequence(xaddr, yaddr, timestamps, shape, frame_width):",KEEP KEEP KEEP KEEP ADD ADD ADD ADD KEEP ADD KEEP,Add Parameter
Cell separator,"def __init__(self, tree_str=None, cell_extractor=None, zero_based=False, cell_separator=None):","def __init__(self, tree_str=None, cell_extractor=None, zero_based=False):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
updated connectors: Extended connector definition to allow any modules as inputs,"def _build(self, inputs):  """"""Transforms the inputs with an MLP layer and packs the results to have the same structure with the decoder state.","def _build(self, encoder_result):  """"""Transforms the encoder results with an MLP layer.",KEEP KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD REP KEEP ADD ADD ADD ADD ADD KEEP REP REP REP,Rename Parameter
Improve clamp detection. Rename functions. Add references.,"def perturb_support(pmf, eps=.1, prng=None):","def perturb(pmf, eps=.1, prng=None):",KEEP REP KEEP KEEP,Rename Method
changed chunkparser api to use root_label and chunk_label instead of top_node and chunk_node,"def conllstr2tree(s, chunk_types=('NP', 'PP', 'VP'), root_label=""S""):","def conllstr2tree(s, chunk_types=('NP', 'PP', 'VP'), top_node=""S""):",KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
"[msm/analysis] implemented mfpt between sets; adapted doc, API and unit tests","def mfpt(T, target, origin=None, mu=None): r""""""Mean first passage times (from a set of starting states - optional) to a set of target states.","def mfpt(T, target): r""""""Mean first passage time to target state.",KEEP KEEP ADD ADD REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP ADD ADD ADD KEEP REP,Add Parameter
Add TODO in the head for Mask R-CNN,"def ResHead(classes, mask=False):",def ResHead(classes):,KEEP ADD REP,Add Parameter
Simple backend unit tests (#1020),"def conv_sep(self, input_tensor, filters, kernel_size=5, strides=2, **kwargs): """""" Seperable Convolution Layer.  Parameters ---------- input_tensor: tensor The input tensor to the layer filters: int The dimensionality of the output space (i.e. the number of output filters in the convolution) kernel_size: int, optional An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions. Default: 5 strides: tuple or int, optional An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Default: `2` kwargs: dict Any additional Keras standard layer keyword arguments  Returns ------- tensor The output tensor from the Upscale layer """""" logger.debug(""input_tensor: %s, filters: %s, kernel_size: %s, strides: %s, kwargs: %s)"", input_tensor, filters, kernel_size, strides, kwargs) name = self._get_name(""separableconv2d_{}"".format(input_tensor.shape[1])) kwargs = self._set_default_initializer(kwargs)","def conv_sep(self, inp, filters, kernel_size=5, strides=2, **kwargs):  logger.debug(""inp: %s, filters: %s, kernel_size: %s, strides: %s, kwargs: %s)"", inp, filters, kernel_size, strides, kwargs) name = self.get_name(""separableconv2d_{}"".format(inp.shape[1])) kwargs = self.set_default_initializer(kwargs)",KEEP KEEP REP KEEP KEEP KEEP KEEP ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP REP,Rename Parameter
support parameterized circuits,"def execute(self, circuits, had_transpiled=False, **kwargs):","def execute(self, circuits, **kwargs):",KEEP KEEP KEEP ADD KEEP,Add Parameter
filter for my computer,"def get_game_count(self, strategy, my_computer_only=False): computer_name = COMPUTER_NAME if my_computer_only else 'All'","def get_game_count(self, strategy):",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
add branin and carromtable,def get_max_trials(self):,def get_task_max_trials(self):,KEEP REP,Rename Method
GUI Updates (#940),"def load_session(self, fullpath=None):",def load_session(self):,KEEP ADD REP,Add Parameter
Various improvements (#202),"def get_result(self, task_id): """"""Get the result of the task.","def get(self, task_id): raise NotImplementedError",KEEP REP KEEP ADD ADD ADD ADD REP REP,Rename Method
Adding missing DependencyGraph top relation label code.,"def __init__(self, tree_str=None, cell_extractor=None, zero_based=False, cell_separator=None, top_relation_label='ROOT'):","def __init__(self, tree_str=None, cell_extractor=None, zero_based=False, cell_separator=None):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Rename ignore_hash to allow_output_mutation (#422),def off_test_allow_output_mutation(self):,def off_test_ignore_hash(self):,KEEP REP,Rename Method
enable dynamics to use basis gates only,"def init_args( self, operator, operator_mode, initial_state, evo_operator, evo_time, num_time_slices, paulis_grouping='default', expansion_mode='trotter', expansion_order=1, use_basis_gates=True):","def init_args(self, operator, operator_mode, initial_state, evo_operator, evo_time, num_time_slices, paulis_grouping='default', expansion_mode='trotter', expansion_order=1):",KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
don't declare default constants,"def __init__(self, entity1_class, entity2_class, relation_type): super().__init__(entity1_class, entity2_class, relation_type)","def __init__(self): super().__init__(PRO_CLASS_ID, MUT_CLASS_ID, PRO_REL_MUT_CLASS_ID)",KEEP ADD ADD ADD REP REP REP REP,Add Parameter
Reorganize methods related to fixing molecules created from augInChI,"def _fix_charge(mol, u_indices): """""" Tries to fix a number of structural features in the molecule related to charge, based on the information from the parameter list of atom indices with unpaired electrons. """"""","def fixCharge(mol, u_indices): """""" Tries to fix a number of structural features in the molecule related to charge, based on the information from the parameter list of atom indices with unpaired electrons.",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD,Rename Method
Make testing/databaseTest.py unit tests PEP-8 compliant,"def kinetics_check_sample_descends_to_group(self, family_name):","def kinetics_checkSampleDescendsToGroup(self, family_name):",KEEP REP KEEP,Rename Method
Now storing dict of edges on Vertex and vertices on Edge.,def test_hasEdge(self):,def testHasEdge(self):,KEEP REP,Rename Method
Output Sharpening Added (#285),"def __init__(self, encoder, trainer, blur_size=2, seamless_clone=False, mask_type=""facehullandrect"", erosion_kernel_size=None, match_histogram=False, sharpen_image=None, **kwargs):","def __init__(self, encoder, trainer, blur_size=2, seamless_clone=False, mask_type=""facehullandrect"", erosion_kernel_size=None, match_histogram=False, **kwargs):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_multiple_bigrams_single_entry(self):,def testMultipleBigramsSingleEntry(self):,KEEP REP,Rename Method
Add GenericConverter for parsing unknown config file types,"def infer_converter_from_file_type(config_path, regex=None, default_keyword=''):",def infer_converter_from_file_type(config_path):,KEEP ADD ADD REP,Add Parameter
SMC fix (#100),"def inference_task(n_obs=100, true_params=None, seed_obs=12345):","def inference_task(n_obs=100, params_obs=None, seed_obs=12345):",KEEP KEEP REP KEEP,Rename Parameter
"Simplify tests suite, remove spy_phase and related functions (#886)","@pytest.mark.parametrize(""seed"", [123, 456]) def test_sample(self, tpe: TPE, seed: int):","def test_sample(self, tpe: TPE):",ADD ADD ADD KEEP KEEP KEEP ADD ADD REP,Add Parameter
Futurize & a few post-fixes to make it run on Py3,def __next__(self):,def next(self):,KEEP REP,Rename Method
"complete refactor of prior handling; adds families and link functions; closes #5, closes #4","def fit(self, fixed=None, random=None, family='gaussian', link=None, **kwargs):","def fit(self, fixed=None, random=None, **kwargs):",KEEP KEEP KEEP KEEP ADD ADD KEEP,Add Parameter
Clean up show_config output. Don't open report. Add visible=True/False to config options.,"def _set_option(key, value, where_defined, visible=True):","def _set_option(key, value, where_defined):",KEEP KEEP KEEP ADD REP,Add Parameter
Prefix legacy and arrow commands with _ (#3563),"def _arrow_add_rows(self, data=None, **kwargs): """"""Concatenate a dataframe to the bottom of the current one.  Parameters ---------- data : pandas.DataFrame, pandas.Styler, numpy.ndarray, Iterable, dict, or None Table to concat. Optional.  **kwargs : pandas.DataFrame, numpy.ndarray, Iterable, dict, or None The named dataset to concat. Optional. You can only pass in 1 dataset (including the one in the data parameter).  Example ------- >>> df1 = pd.DataFrame( ...    np.random.randn(50, 20), ...    columns=('col %d' % i for i in range(20))) ... >>> my_table = st._arrow_table(df1) >>> >>> df2 = pd.DataFrame( ...    np.random.randn(50, 20), ...    columns=('col %d' % i for i in range(20))) ... >>> my_table._arrow_add_rows(df2) >>>  >>>   You can do the same thing with plots. For example, if you want to add more data to a line chart:  >>>  >>> my_chart = st._arrow_line_chart(df1) >>> my_chart._arrow_add_rows(df2) >>>  >>>   And for plots whose datasets are named, you can pass the data with a keyword argument where the key is the name:  >>> my_chart = st._arrow_vega_lite_chart({ ...     'mark': 'line', ...     'encoding': {'x': 'a', 'y': 'b'}, ...     'datasets': { ...       'some_fancy_name': df1,   ...      }, ...     'data': {'name': 'some_fancy_name'}, ... }), >>> my_chart._arrow_add_rows(some_fancy_name=df2)    """"""","def arrow_add_rows(self, data=None, **kwargs):",KEEP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
"Saner ""execution control request"" handling (#4383)",def _maybe_handle_execution_control_request(self) -> None:,def maybe_handle_execution_control_request(self) -> None:,KEEP REP KEEP KEEP,Rename Method
style correction,"def load_model(self, load_dir):","def load_model(self, dir):",KEEP KEEP REP,Rename Parameter
Cell separator,"def _parse(self, input_, cell_extractor=None, zero_based=False, cell_separator=None):","def _parse(self, input_, cell_extractor=None, zero_based=False):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Smart Masks to Convert (#957),"def _add_patch_callback(self, patch_callback): """""" Add callback to re-patch images on configuration option change.  Parameters ---------- patch_callback: python function The function to execute when the images require patching """"""","def add_patch_callback(self, patch_callback): ",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
Fix qsvm unit tests,def test_qsvm_kernel_binary_directly(self):,def todo_test_qsvm_kernel_binary_directly(self):,KEEP REP,Rename Method
Track integration2 (#289),"def reserve_trial(experiment, producer, _depth=1):","def reserve_trial(experiment, producer):",KEEP KEEP ADD REP,Add Parameter
rename methods for better semantic,"def test_update(self): h = self._class(4, hashobj=FakeHash) h.update(0b00011111)",def test_digest(self): h = self._class(4) h.digest(FakeHash(0b00011111)),KEEP REP KEEP KEEP ADD REP REP,Rename Method
revert,"def seq2seq_pad_concat_convert(xy_batch, eos_id=2, bos_id=1):","def seq2seq_pad_concat_convert(xy_batch, eos_id=2, bos_id=1, n_gpu=0):",KEEP KEEP KEEP REP DEL,Remove Parameter
"[featurizer.add_custom_func] bugfix in call to CustomFeature, plus proper tests and updated docstring","def add_custom_func(self, func, dim, *args, **kwargs):","def add_custom_func(self, func, dim, desc='', *args, **kwargs):",KEEP KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
add multiplicity in the constructor of Group,"def __init__(self, atoms=None, multiplicity=[]):","def __init__(self, atoms=None):",KEEP KEEP ADD REP,Add Parameter
add internal study to decouple assessment and task,"def display(self, task, experiments, notebook=True):","def display(self, notebook=False):",KEEP KEEP ADD ADD REP,Add Parameter
nltk/corpus/reader/util.py,"def docs(self, documents=None):","def docs(self, items=None):",KEEP KEEP REP,Rename Parameter
complete support for use of predicted entities in relationsips,"def add_n_grams(self, f_set, is_train, use_pred, edge, path, dep_type, n_gram):","def add_n_grams(self, f_set, is_train, edge, path, dep_type, n_gram):",KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP,Add Parameter
changed homogeneous to normal,def test_rotation_matrix_normal():,def test_rotation_matrix_homogeneous():,KEEP REP,Rename Method
Added thermo and kinetics methods to Species and Reaction objects.,"def __init__(self, index=-1, reactants=None, products=None, kinetics=None):","def __init__(self, index=-1, reactants=None, products=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
make tgrep._treepositions_no_leaves a public method,def treepositions_no_leaves(tree):,def _treepositions_no_leaves(tree):,KEEP REP,Rename Method
[Angelica] Update docstrings for imageprocessor class,def _get_raw_training_labels(self):,def get_raw_training_labels(self):,KEEP REP,Rename Method
Pool improvements (#204),"def set_context(self, context):","def init_context(self, context):",KEEP REP KEEP,Rename Method
Fix: score for empty trees; better debug prints,"def generate_tree(self, da, gen_doc=None): log_debug('GEN TREE for DA: %s' % unicode(da))","def generate_tree(self, da, gen_doc=None, gold_ttree=None):",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD REP REP,Remove Parameter
gives right inverses,def _ld_circuit(self):  k_r = self._precision,def _long_reciprocal_circuit(self): n = self._num_ancillae + 1 offset = n - 2 k = self._precision - offset k_r = self._precision,KEEP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP KEEP KEEP,Rename Method
add types to net_util.py (#4916),def get_internal_ip() -> Optional[str]:,def get_internal_ip():,KEEP ADD ADD REP,Change Return Type
add minimum frequency filter to unigram word feats,"def unigram_word_feats(self, words, top_n=None, min_freq=0):","def unigram_word_feats(self, words, top_n=None):",KEEP KEEP KEEP ADD REP,Add Parameter
Align _match_potential_end_contexts with NLTK 3.6.5 sent_tokenize results,"def _second_pass_annotation( self, aug_tok1: PunktToken, aug_tok2: Optional[PunktToken] ) -> Optional[str]:","def _second_pass_annotation(self, aug_tok1, aug_tok2):",KEEP ADD ADD ADD ADD ADD ADD REP REP REP,Change Return Type
update seq2seq model.,"def __init__(self, model_dir, arch='convseq2seq', embed_size=128, hidden_size=128, dropout=0.25, max_length=128):","def __init__(self, arch, model_dir, src_vocab_path=None, trg_vocab_path=None, embed_size=50, hidden_size=50, dropout=0.5, max_length=128):",KEEP KEEP DEL KEEP REP REP REP REP DEL KEEP,Remove Parameter
change from test to inference,"def get_training_data(video_path, annotation_path, dataset_name, file_type, spatial_transform=None, temporal_transform=None, target_transform=None):","def get_training_set(video_path, annotation_path, dataset_name, file_type, spatial_transform=None, temporal_transform=None, target_transform=None):",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
Tests for the ipyparallel client,"def test_different_states_for_different_batches(simple_model, client):",def test_different_states_for_different_batches(simple_model):,KEEP ADD REP,Add Parameter
implement,"def f(self, feat_key, dependency_XX, ngram_N=None):","def f(self, f_key, dependency_XX, ngram_N=None):",KEEP KEEP REP KEEP KEEP,Rename Parameter
Interactive plotting (#136),"def _give_name(self, name, model): if name is not None: if name[-1] == '*':  name = self._new_name(name[:-1], model) return name ","def _give_name(self, model):",KEEP KEEP ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Add Parameter
Smart Mask Exposure for Extraction & Training (#831),"def compile_sample(self, batch_size, samples=None, images=None, masks=None):","def compile_sample(self, batch_size, samples=None, images=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
[thermo] use save_convergence_info instead of err_out and lll_out,"def wham(ttrajs, dtrajs, bias, maxiter=100000, maxerr=1.0E-15, save_convergence_info=0):","def wham(ttrajs, dtrajs, bias, maxiter=100000, maxerr=1.0E-15, err_out=0, lll_out=0):",KEEP KEEP KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
Logging (#541),"def rotate_image(self, image, angle):","@staticmethod def rotate_image(image, angle):",REP REP REP KEEP,Add Parameter
"Unified init+kmodes dissimilarity functions, added unit tests for ng_diss, and added error checking to dissimilarity function for membship array","def k_modes(X, n_clusters, max_iter, dissim, init, n_init, verbose):","def k_modes(X, n_clusters, max_iter, init_dissim, kmodes_dissim, init, n_init, verbose):",KEEP KEEP KEEP KEEP REP DEL KEEP KEEP KEEP,Remove Parameter
add params in fresnet,"def residual_unit_v2(data, num_filter, stride, dim_match, name, bottle_neck, **kwargs):","def residual_unit_v2(data, num_filter, stride, dim_match, name, bottle_neck=True, use_se=False, bn_mom=0.9, workspace=256, memonger=False):",KEEP KEEP KEEP KEEP KEEP KEEP REP REP DEL DEL DEL,Remove Parameter
Fix third-party dependency issues and support scikit-learn 0.24 and scipy 1.6 (#1147),"def alphas(estimator, X, y=None, ax=None, is_fitted=""auto"", show=True, **kwargs):","def alphas(model, X, y=None, ax=None, is_fitted=""auto"", show=True, **kwargs):",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Parameter
Restructured pipeline and variable allocation in INI-Sim to reduce memory and computations.,"def absorb_bn(w, b, gamma, beta, mean, var, epsilon):","def absorb_bn(w, b, gamma, beta, mean, std, epsilon):",KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP,Rename Parameter
Added documentation,"def __show_histogram_3d(self, array, name, bins=50, env_appendix="""", **kwargs): """""" Internal show_histogram_3d method, called by the internal process. This function does all the magic. """"""","def __show_histogram_3d(self, array, name, bins=50, env_app="""", **kwargs):",KEEP KEEP KEEP KEEP KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Parameter
Accept pre-tokenized references & hypothesis for METEOR calculation (#2822),"def align_words( hypothesis: Iterable[str], reference: Iterable[str], stemmer: StemmerI = PorterStemmer(), wordnet: WordNetCorpusReader = wordnet, ) -> Tuple[List[Tuple[int, int]], List[Tuple[int, str]], List[Tuple[int, str]]]:","def align_words(hypothesis, reference, stemmer=PorterStemmer(), wordnet=wordnet):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP,Change Return Type
File-based fast training for Any2Vec models (#2127),"def train(self, sentences=None, corpus_file=None, total_examples=None, total_words=None,","def train(self, sentences=None, input_streams=None, total_examples=None, total_words=None,",KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
Restructured pipeline and variable allocation in INI-Sim to reduce memory and computations.,"def check_runlabel(self, p):  if self.initialized:  self.settings['log_dir_of_current_run'].set( os.path.join(self.gui_log.get(), p)) if not os.path.exists( self.settings['log_dir_of_current_run'].get()): os.makedirs(self.settings['log_dir_of_current_run'].get())  def check_dataset_path(self, p): """"""  Parameters ---------- p :  Returns -------  """"""","def check_runlabel(self, P):  if self.initialized:  self.settings['log_dir_of_current_run'].set( os.path.join(self.gui_log.get(), P)) if not os.path.exists( self.settings['log_dir_of_current_run'].get()): os.makedirs(self.settings['log_dir_of_current_run'].get()) ",KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Parameter
"Move vectorization decorators to own file, use partial in core.py","def vectorize_discrepancy(discrepancy, x, y): """"""Used to vectorize a sequential discrepancy operation","def _vec_dis(discrepancy, x, y): """"""Used with 'as_vectorized_discrepancy'",KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD REP REP,Rename Method
Issue 1204: Graphs using Vega-Lite (#56),"def __init__(self, enqueue, id=0, delta_type=None, last_index=None, is_root=True, container=BlockPath_pb2.BlockPath.MAIN, path=()):","def __init__( self, enqueue, id=0, is_root=True, container=BlockPath_pb2.BlockPath.MAIN, path=(), ):",KEEP REP DEL KEEP KEEP ADD ADD KEEP KEEP REP DEL,Add Parameter
GUI Fixups,"def get_sysbrowser(self, option, options, command):","@staticmethod def get_sysbrowser(option, command):",ADD REP REP REP KEEP,Add Parameter
updated vit,"def get_mbf(fp16, num_features, blocks=(1, 4, 6, 2), scale=2): return MobileFaceNet(fp16, num_features, blocks, scale=scale)  def get_mbf_large(fp16, num_features, blocks=(2, 8, 12, 4), scale=4): return MobileFaceNet(fp16, num_features, blocks, scale=scale)","def get_mbf(fp16, num_features): return MobileFaceNet(fp16, num_features)",KEEP KEEP ADD ADD ADD ADD ADD REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
ParallelMap: use infinite iterator when strict=False,"def reset_state(self): super(PrefetchDataZMQ, self).reset_state()",def _reset_once(self):,KEEP ADD ADD REP,Rename Method
Refactor ExperimentClient to use Executor,"def __init__(self, n_jobs, **kwargs):","def __init__(self, experiment, n_jobs, **kwargs): self.experiment = experiment",KEEP KEEP DEL KEEP KEEP DEL DEL DEL,Remove Parameter
"added support for padding at both ends of a text, cf https://github.com/nltk/nltk/pull/235","def __init__(self, n, train, pad_left=True, pad_right=False, estimator=None, *estimator_args, **estimator_kwargs):","def __init__(self, n, train, estimator=None, *estimator_args, **estimator_kw_args):",KEEP KEEP KEEP KEEP ADD ADD KEEP KEEP REP,Add Parameter
Mask tool,"def read_image(filename, raise_error=False, with_hash=False):","def read_image(filename, raise_error=False):",KEEP KEEP ADD REP,Add Parameter
Fixed RC control (#889),def show_record_count_status():,def show_record_acount_status():,KEEP REP,Rename Method
"Merged with hhl-test, fixed test","def init_args(self, num_ancillae=0, scale=0, evo_time = None, lambda_min = None,","def init_args(self, num_ancillae=0, scale=0,",KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD,Add Parameter
Replay st elements inside memo/singleton functions (#4936),"def read_result(self, key: str) -> CachedResult: """"""Read a value and messages from the cache. Raise `CacheKeyNotFoundError` if the value doesn't exist, and `CacheError` if the value exists but can't","def read_value(self, key: str) -> Any: """"""Read a value from the cache. Raise `CacheKeyNotFoundError` if the value doesn't exist, and `CacheError` if the value exists but can't",KEEP REP KEEP KEEP KEEP REP KEEP KEEP KEEP ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
Adapt codebase to new name Orion (#61),"def test_update_with_id(self, exp_config, database, orion_db):","def test_update_with_id(self, exp_config, database, moptdb):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Enable atom map constant for Fragment get_aromatic_rings,"def get_aromatic_rings(self, rings=None, save_order=False):","def get_aromatic_rings(self, rings=None):",KEEP KEEP ADD REP,Add Parameter
nltk/corpus/reader/util.py,"def raw(self, documents=None):","def raw(self, items=None):",KEEP KEEP REP,Rename Parameter
remove relna features from nalaf,"def __init__(self, class1, class2, rel_type, splitter=None, tokenizer=None, parser=None, feature_set=None):","def __init__(self, class1, class2, rel_type, splitter=None, tokenizer=None, parser=None):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
nltk/corpus/reader/util.py,"def __init__(self, root, documents, extension=''): if isinstance(documents, basestring): documents = find_corpus_items(root, documents, extension)","def __init__(self, root, items, extension=''): if isinstance(items, basestring): items = find_corpus_items(root, items, extension)",KEEP KEEP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP,Rename Parameter
update bert model for bert detector.,"def bert_lm_infer(self, sentence):","def bert_lm_infer(self, sentence, error_begin_idx=0, error_end_idx=0):",KEEP KEEP REP DEL DEL,Remove Parameter
discard fast evaluation -- unstable,"def __init__(self, log_max_evals, a_factory=None, i_objective=None, q_factory=None, likelihood_evals=None):","def __init__(self, log_max_evals, a_factory, i_objective=None, q_factory=None):",KEEP KEEP KEEP REP KEEP ADD REP,Add Parameter
remove all dependencies to old code from nala and 鉁?#fix travis test,"def __init__(self, ggp_e_id, entrez_gene_id, uniprot_id): super().__init__([ggp_e_id, entrez_gene_id, uniprot_id])","def __init__(self): super().__init__([ENTREZ_GENE_ID, UNIPROT_ID])",KEEP ADD ADD ADD ADD REP REP REP,Add Parameter
"Update: different concat methods on blanks, enters and OOV.","def get_errors(_corrected_text, _origin_text):","def get_errors(_corrected_text, _origin_text, blanks_cleaned=False):",KEEP KEEP REP DEL,Remove Parameter
enable corpus-level bleu,"def sentence_bleu(references, hypothesis, weights=[0.25, 0.25, 0.25, 0.25]):","def bleu(references, hypothesis, weights):",KEEP REP KEEP ADD ADD ADD REP,Rename Method
server working after refactor,"def initialize(self, recorder, predictor, vehicles):","def initialize(self, recorder, predictor):",KEEP KEEP KEEP ADD REP,Add Parameter
Update arlstem.py,"def plur2sing(self, token): """""" transform the word from the plural form to the singular form """""" if(len(token) > 4): for ps2 in self.pl_si2: if(token.endswith(ps2)): token = token[:-2] return token if(len(token) > 5): for ps3 in self.pl_si3: if(token.endswith(ps3)): token = token[:-3] return token if(len(token)>3 and token.endswith('\u0627\u062A')): token = token[:-2] return token if(len(token)>3 and token.startswith('\u0627') and token[2]=='\u0627'): token = token[0:2] + token[3:] return token if(len(token)>4 and token.startswith('\u0627') and token[-2]=='\u0627'): token = token[1:] token = token[:-2] + token[-1] return token  def verb(self, token): """""" stem the verb prefixes and suffixes or both """""" vb = self.verb_t1(token) if vb == None: vb = self.verb_t2(token) if vb == None: vb = self.verb_t3(token) if vb == None: vb = self.verb_t4(token) if vb == None: vb = self.verb_t5(token) if vb != None: token = vb return token else: return token else: token = vb return token else: token = vb return token else: token = vb return token else: token = vb return token  def verb_t1(self, token): """""" stem the present prefixes and suffixes """""" if(len(token)>5 and token.startswith('\u062A')):  for s2 in self.pl_si2: if(token.endswith(s2)): token = token[1:] token = token[:-2] return token if(len(token)>5 and token.startswith('\u064A')):  for s2 in self.verb_su2: if(token.endswith(s2)): token = token[1:] token = token[:-2] return token if(len(token)>4 and token.startswith('\u0627')):   if(len(token)>5 and token.endswith('\u0648\u0627')): token = token[1:] token = token[:-2] return token  if(token.endswith('\u064A')): token = token[1:] token = token[:-1] return token  if(token.endswith('\u0627')): token = token[1:] token = token[:-1] return token  if(token.endswith('\u0646')): token = token[1:] token = token[:-1] return token  if( len(token)>4 and token.startswith('\u064A') and token.endswith('\u0646') ): token = token[1:] token = token[:-1] return token  if( len(token)>4 and token.startswith('\u062A') and token.endswith('\u0646') ): token = token[1:] token = token[:-1] return token  def verb_t2(self, token): """""" stem the future prefixes and suffixes """""" if(len(token) > 6): for s2 in self.pl_si2:  if( token.startswith(self.verb_pr2[0]) and token.endswith(s2) ): token = token[2:] token = token[:-2] return token  if( token.startswith(self.verb_pr2[1]) and token.endswith(self.pl_si2[0]) ): token = token[2:] token = token[:-2] return token  if( token.startswith(self.verb_pr2[1]) and token.endswith(self.pl_si2[2]) ): token = token[2:] token = token[:-2] return token  if( len(token)>5 and token.startswith(self.verb_pr2[0]) and token.endswith('\u0646') ): token = token[2:] token = token[:-1] return token  if( len(token)>5 and token.startswith(self.verb_pr2[1]) and token.endswith('\u0646') ): token = token[2:] token = token[:-1] return token  def verb_t3(self, token): """""" stem the present suffixes """""" if(len(token) > 5): for su3 in self.verb_suf3: if(token.endswith(su3)): token = token[:-3] return token if(len(token) > 4): for su2 in self.verb_suf2: if(token.endswith(su2)): token = token[:-2] return token if(len(token) > 3): for su1 in self.verb_suf1: if(token.endswith(su1)): token = token[:-1] return token","def __plur2sing(self, token): """""" transform the word from the plural form to the singular form """""" if(len(token) > 4): for ps2 in self.pl_si2: if(token.endswith(ps2)): token = token[:-2] return token if(len(token) > 5): for ps3 in self.pl_si3: if(token.endswith(ps3)): token = token[:-3] return token if(len(token) > 3 and token.endswith('\u0627\u062A')): token = token[:-2] return token if(len(token) > 3 and token.startswith('\u0627') and token[2]=='\u0627'): token = token[0:2] + token[3:] return token if(len(token) > 4 and token.startswith('\u0627') and token[-2]=='\u0627'): token = token[1:] token = token[:-2] + token[-1] return token  def __verb(self, token): """""" stem the verb prefixes and suffixes or both """""" vb = self.__verb_t1(token) if vb == None: vb = self.__verb_t2(token) if vb == None: vb = self.__verb_t3(token) if vb == None: vb = self.__verb_t4(token) if vb == None: vb = self.__verb_t5(token) if vb != None: token = vb return token else: return token else: token = vb return token else: token = vb return token else: token = vb return token else: token = vb return token  def __verb_t1(self, token): """""" stem the present prefixes and suffixes """""" if(len(token) > 5 and token.startswith('\u062A')):  for s2 in self.pl_si2: if(token.endswith(s2)): token = token[1:] token = token[:-2] return token if(len(token) > 5 and token.startswith('\u064A')):  for s2 in self.verb_su2: if(token.endswith(s2)): token = token[1:] token = token[:-2] return token if(len(token) > 4 and token.startswith('\u0627')):  if(len(token) > 5 and token.endswith('\u0648\u0627')):  token = token[1:] token = token[:-2] return token if(token.endswith('\u064A')):  token = token[1:] token = token[:-1] return token if(token.endswith('\u0627')):  token = token[1:] token = token[:-1] return token if(token.endswith('\u0646')):  token = token[1:] token = token[:-1] return token if(len(token) > 4 and token.startswith('\u064A') and token.endswith('\u0646')):  token = token[1:] token = token[:-1] return token if(len(token) > 4 and token.startswith('\u062A') and token.endswith('\u0646')):  token = token[1:] token = token[:-1] return token  def __verb_t2(self, token): """""" stem the future prefixes and suffixes """""" if(len(token) > 6): for s2 in self.pl_si2: if(token.startswith(self.verb_pr2[0]) and token.endswith(s2)):  token = token[2:] token = token[:-2] return token if(token.startswith(self.verb_pr2[1]) and token.endswith(self.pl_si2[0])):  token = token[2:] token = token[:-2] return token if(token.startswith(self.verb_pr2[1]) and token.endswith(self.pl_si2[2])):  token = token[2:] token = token[:-2] return token if(len(token) > 5 and token.startswith(self.verb_pr2[0]) and token.endswith('\u0646')):  token = token[2:] token = token[:-1] return token if(len(token) > 5 and token.startswith(self.verb_pr2[1]) and token.endswith('\u0646')):  token = token[2:] token = token[:-1] return token  def __verb_t3(self, token): """""" stem the present suffixes """""" if(len(token) > 5): for su3 in self.verb_suf3: if(token.endswith(su3)): token = token[:-3] return token if(len(token) > 4): for su2 in self.verb_suf2: if(token.endswith(su2)): token = token[:-2] return token if(len(token) > 3): for su1 in self.verb_suf1: if(token.endswith(su1)): token = token[:-1] return token",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL KEEP KEEP KEEP REP REP DEL KEEP KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP KEEP KEEP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
[coor/api] removed stride param from _param_stage (handled by estimate),"def _param_stage(previous_stage, this_stage, chunk_size=None):","def _param_stage(previous_stage, this_stage, stride=1, chunk_size=None):",KEEP KEEP KEEP DEL KEEP,Remove Parameter
Allow overriding timeout arg for running a script (#6173),"def run( self, widget_state: WidgetStates | None = None, timeout: float = 3, ) -> ElementTree:","def run(self, widget_state: WidgetStates | None = None) -> ElementTree:",KEEP ADD REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD REP KEEP KEEP,Add Parameter
indirect typo,"def process_class(c_name, obj, c_skip, c_missing_doc, c_missing_doctest, c_indirect_doctest, c_has_doctest,","def process_class(c_name, obj, c_skip, c_missing_doc, c_missing_doctest, c_indierect_doctest, c_has_doctest,",KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP,Rename Parameter
"Add support for port ranges. Split proxy.port into client.proxyPort, browser.proxyPort and browser.proxyPortRange.",def _get_proxy_browser_port():,def _get_http_port():,KEEP REP,Rename Method
tsf add ds df,"def train_d1_step(self, sess, batch, gamma):","def train_d1_step(self, sess, batch, rho, gamma):",KEEP KEEP KEEP KEEP DEL KEEP,Remove Parameter
"added data, some bug fixes","def fit(self, X, y = None):","def fit(self, X, y = None, x_labels = None):",KEEP KEEP KEEP KEEP KEEP DEL DEL DEL KEEP,Remove Parameter
move punctuations and punc regex to VaderConstant,"def __init__(self, text, punc_list, regex_remove_punctuation):","def __init__(self, text):",KEEP KEEP ADD ADD REP,Add Parameter
update readme.,"def decode_sequence(model, rnn_hidden_dim, input_token_index, num_decoder_tokens, target_token_index, encoder_input_data, max_decoder_seq_length):","def decode_sequence(model, rnn_hidden_dim,input_token_index, num_decoder_tokens, target_token_index,encoder_input_data, reverse_target_char_index, max_decoder_seq_length):",KEEP KEEP ADD REP KEEP REP REP KEEP,Remove Parameter
changed nltk.data.paths back to nltk.data.path as it's documented and a common environment variable name,"def __init__(self, _path): self._path = _path","def __init__(self, path): self.__path = path",KEEP KEEP REP REP KEEP REP,Rename Parameter
1. support different shot setting for calibration matrix,"def maybe_refresh_cals_matrix(self, timestamp=None):",def maybe_refresh_cals_matrix(self):,KEEP ADD REP,Add Parameter
masks order,"def detections(metadata, deltas, proposals, scores, masks):","def detections(num_output, metadata, deltas, proposals, scores, masks):",KEEP REP DEL KEEP KEEP KEEP KEEP,Remove Parameter
Add QuantumInstance/Backend to algorithm init (#874),"def __init__(self, oracle: Oracle, init_state: Optional[InitialState] = None, incremental: bool = False, num_iterations: int = 1, mct_mode: str = 'basic', quantum_instance: Optional[Union[QuantumInstance, BaseBackend]] = None) -> None:","def __init__(self, oracle: Oracle, init_state: Optional[InitialState] = None, incremental: bool = False, num_iterations: int = 1, mct_mode: str = 'basic') -> None:",KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD REP KEEP KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_basic(self):,def testBasic(self):,KEEP REP,Rename Method
[msm.ui.msm]: Large commit! MSM has now a ton of useful features and functions,"def correlation(self, a, times, b=None, k=None, ncv=None):","def correlation(self, a, lag, b=None, k=None, ncv=None):",KEEP KEEP KEEP REP KEEP KEEP KEEP,Rename Parameter
Smart Training Implementation (#914),"def _start_thread(self): """""" Put the :func:`_training` into a background thread so we can keep control.  Returns ------- :class:`lib.multithreading.MultiThread` The background thread for running training """"""",def start_thread(self): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
"ensure auto scaling is applied properly, and PEP8","def __init__(self, name, scale=None, **kwargs):","def __init__(self, name, **kwargs):",KEEP KEEP KEEP ADD KEEP,Add Parameter
handle Kronecker,"def __new__(cls, name, n, m):","def __new__(cls, name, n, m, strict=True):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
[#87] Add weight option to the external prediction features,"def __init__(self, system_name, input_file, weight=1): self.weight = weight """""" the weight of the external features, by default 1 """"""","def __init__(self, system_name, input_file):",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Better multi line and legend handling when plotting values,"def show_value(self, value, name, counter=None, tag=None, show=True, *args, **kwargs):","def show_value(self, value, name, line_name=None, show=True, *args, **kwargs):",KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP,Add Parameter
convert Molecule.fingerprint to a property,"def __getFingerprint(self): """""" Return a string containing the ""fingerprint"" used to accelerate graph isomorphism comparisons with other molecules. The fingerprint is a short string containing a summary of selected information about the molecule. Two fingerprint strings matching is a necessary (but not sufficient) condition for the associated molecules to be isomorphic. """""" if self._fingerprint is None: self.fingerprint = self.getFormula() return self._fingerprint def __setFingerprint(self, fingerprint): self._fingerprint = fingerprint fingerprint = property(__getFingerprint, __setFingerprint) ","def getFingerprint(self): """""" Return a string containing the ""fingerprint"" used to accelerate graph isomorphism comparisons with other molecules. The fingerprint is a short string containing a summary of selected information about the molecule. Two fingerprint strings matching is a necessary (but not sufficient) condition for the associated molecules to be isomorphic. """""" if self._fingerprint is None: self._fingerprint = self.getFormula() return self._fingerprint ",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
[coordinates] add skip parameters to Estimators to allow to skip inital n_frames.,"def cluster_uniform_time(data=None, k=None, stride=1, metric='euclidean', n_jobs=None, chunk_size=5000, skip=0):","def cluster_uniform_time(data=None, k=None, stride=1, metric='euclidean', n_jobs=None, chunk_size=5000):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Fix qsvm unit tests,def test_qsvm_variational_callback(self):,def todo_test_qsvm_variational_callback(self):,KEEP REP,Rename Method
add docstrings,"def __init__(self, breakpoints, slopes, offsets, num_state_qubits, i_state=None, i_target=None):","def __init__(self, breakpoints, slopes, offsets, num_state_qubits, i_state=None, i_target=None, uncompute=True):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
Add support for all other (except KerasLatent) models: (#884),"def __init__(self, interpreter: Interpreter = KerasInterpreter(), input_shape: Tuple[int, ...] = (120, 160, 3), num_outputs: int = 2, num_imu_inputs: int = 6): self.num_outputs = num_outputs","def __init__(self, num_outputs=2, num_imu_inputs=6, input_shape=(120, 160, 3)): super().__init__()",KEEP KEEP ADD ADD ADD ADD ADD ADD REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Add Parameter
"Run tests in pytest, not nose (#2595)",def setup_module(): import pytest,def setup_module(module): from nose import SkipTest  raise SkipTest(,KEEP REP DEL DEL KEEP REP DEL DEL DEL,Remove Parameter
Updated PCA visualizer to extend Projection Visualizer (#937),"def layout(self, divider=None):",def layout(self):,KEEP ADD REP,Add Parameter
Fixed ranges,"def get_current_bet_value(self,p):",def get_current_bet_value(self):,KEEP REP,Add Parameter
lib.alignments: improve re-extraction speed by 500%,"def get_faces_in_frame(self, frame, update=False, image=None):","def get_faces_in_frame(self, frame, update=False):",KEEP KEEP KEEP ADD REP,Add Parameter
date limit in streaming requests,"def tweets(self, keywords='', follow='', to_screen=True, stream=True, limit=100, date_limit=None):","def tweets(self, keywords='', follow='', to_screen=True, stream=True, limit=100):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Isolate properly DB in branching tests,def test_full_x_remove_z_default_4(init_full_x_remove_z_default_4):,"def test_full_x_remove_z_default_4(init_full_x_remove_z_default_4, create_db_instance):",KEEP REP DEL,Remove Parameter
Force CONFIGURATION static prop for pluggable classes,def __init__(self): super().__init__(copy.deepcopy(ExactEigensolver.CONFIGURATION)),"def __init__(self, configuration=None): super().__init__(configuration or copy.deepcopy(ExactEigensolver.EXACTEIGENSOLVER_CONFIGURATION))",KEEP REP REP DEL DEL DEL,Remove Parameter
Fill config with resume values before setup,"def update(self, dict_like, deep=False, ignore=None):  if ignore is None: ignore = ()","def update(self, dict_like, deep=False):",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Better error messages for st.cache (#1146),"def _write_to_mem_cache( mem_cache, key, value, allow_output_mutation, func_or_code, hash_funcs ):","def _write_to_mem_cache(mem_cache, key, value, allow_output_mutation, hash_funcs):",KEEP ADD REP KEEP KEEP KEEP ADD ADD REP,Add Parameter
Simplified Cloud AI API integration. (#932),def call_get_cloudai_access_token():,def call_get_automl_access_token():,KEEP REP,Rename Method
Add min_subset_size and max_subset_size args,"def _process_data(df, sort_by, sort_categories_by, subset_size, sum_over, min_subset_size=0, max_subset_size=np.inf):","def _process_data(df, sort_by, sort_categories_by, subset_size, sum_over):",KEEP KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
Added opts for all display functions,"def __show_histogram_3d(self, array, name, bins=50, env_appendix="""", opts={}, **kwargs):","def __show_histogram_3d(self, array, name, bins=50, env_appendix="""", **kwargs):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
"""inits"" is the method to use","def _likelihood_ratio_ci(self, alpha=0.05, nevals=10000):","def compute_lr_ci(self, alpha=0.05, nevals=10000):",KEEP REP KEEP KEEP,Rename Method
"Move pool-size to worker conf, cancel deprecation","def suggest(self, pool_size):",def suggest(self):,KEEP ADD REP,Add Parameter
"Fix PEP8: imports, docstrings (#226)",def test_bdm():,def test_bdm(recwarn):,KEEP REP,Remove Parameter
Modified parameter quantization function and plot functions. Added precision metric. Fixed padding bug in fanout computation. Moved quantization function for Loihi parameters from parser to SNN constructor. Added normalization function for loihi parameters. Implemented reset between samples. Workaround for biasExp bug. Fixed probe reading.,"def partition_layer(self, num_neurons, compartment_kwargs):","def partition_layer(self, num_neurons):",KEEP KEEP ADD REP,Add Parameter
Fix bug that forced us to turn off preheating in #1060 (#1075),"def __init__(self, ioloop, script_path, script_argv):","def __init__(self, ioloop, script_path, script_argv, is_preheat):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
Changes poof to show (#973),"def show(self, outpath=None, **kwargs):","def poof(self, outpath=None, **kwargs):",KEEP REP KEEP KEEP,Rename Method
Rename and refactor `Report` machinery (#4141),"def _close_app_session(self, session_id: str) -> None: """"""Shutdown and remove a AppSession.","def _close_report_session(self, session_id: str) -> None: """"""Shutdown and remove a ReportSession.",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP,Rename Method
Sample space is no longer the Cartesian product of alphabets.,"def __init__(self, outcomes, pmf=None, sample_space=None, base=None, prng=None, sort=True, sparse=True, trim=False, validate=True):","def __init__(self, pmf, outcomes=None, alphabet=None, base=None, prng=None, sort=True, sparse=True, trim=False, validate=True):",KEEP KEEP REP REP REP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Parameter
Fix to LCBSC acquisition,"def beta(self, t):","def nu(self, t):",KEEP REP KEEP,Rename Method
updates,"def _init_cache( self, memory, memory_attention_bias, beam_search_decoding, batch_size=None):","def _init_cache(self, memory, memory_attention_bias, beam_search_decoding):",KEEP ADD REP KEEP KEEP ADD REP,Add Parameter
Change non-categorical Dimensions __contains__ to handle strings,def test_no_default_value(self):,def test_set_outside_bounds_default_value(self):,KEEP REP,Rename Method
update corrector with custom confusion.,"def __init__(self, language_model_path='', word_freq_path='', custom_confusion_path=''):","def __init__(self, language_model_path='', word_freq_path=''):",KEEP KEEP KEEP ADD REP,Add Parameter
Implemented logging experiment settings and intermediate results to text files.,"def print_description(snn=None, log=True):",def print_description(snn=None):,KEEP ADD REP,Add Parameter
add an 'copy' option to augmentors (#203),"def __init__(self, ds, augmentors, index=0, copy=False):","def __init__(self, ds, augmentors, index=0):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
wip,"def equilibrium_transition_matrix(Xi, omega, sigma, reversible=True, return_lcc=True):","def equilibrium_transition_matrix(Xi, omega, sigma, reversible=True):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
tsf lm adv set use finish and seqlayer,"def train_d0_step(self, sess, batch, gamma):","def train_d0_step(self, sess, batch):",KEEP KEEP KEEP ADD REP,Add Parameter
add rngdataflow as a base,"def _get_vars_to_restore_multimap(self, vars_available):",@staticmethod def _get_vars_to_restore_multimap(vars_available):,REP REP REP,Add Parameter
added cat throttle to default model. fix plots,"def bin_Y(Y, N=15):",def bin_Y(Y):,KEEP ADD REP,Add Parameter
Add entry points drivers and operatos discovery,"def _discover_local_drivers_in_dirs(self, directory, parentname, names_to_exclude=_NAMES_TO_EXCLUDE, folders_to_exclude=_FOLDERS_TO_EXCLUDE):","def _discover_local_drivers(self, directory, parentname, names_to_exclude=_NAMES_TO_EXCLUDE, folders_to_exclude=_FOLDERS_TO_EXCLUDE):",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
Allow loading development data from separate files,"def _init_training(self, das_file, ttree_file, data_portion, context_file, validation_files):","def _init_training(self, das_file, ttree_file, data_portion, context_file):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Continuing to finalise the parse->read name change,"def read_production(line, nonterm_parser, probabilistic=False):","def parse_production(line, nonterm_parser, probabilistic=False):",KEEP REP KEEP KEEP,Rename Method
polish bert modules and utility functions,"def _build(self, inputs, *args, **kwargs): """"""Encodes the inputs and (optionally) conduct downstream prediction.","def _build(self, inputs, sequence_length, *args, **kwargs): """"""Encodes the inputs and (optionally) conduct downstream prediction.  Args: inputs: Inputs to the bert module. sequence_length: Input tokens beyond respective sequence lengths are masked out automatically. *args: Other arguments. **kwargs: Keyword arguments.  Returns: Encoding results or prediction results. """""" raise NotImplementedError   class BertEncoder(BertBase): """"""raw BERT Transformer for encoding sequences.  This module basically stacks :class:`~texar.modules.embedders.WordEmbedder`, :class:`~texar.modules.embedders.PositionEmbedder`, :class:`~texar.modules.encoders.TransformerEncoder` and a dense pooler.  This module supports the architecture first proposed in `(Devlin et al.)` BERT. ",KEEP KEEP KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
Make rmgpy/pdep/* unit tests PEP-8 compliant,def test_path_reactions(self):,def test_pathReactions(self):,KEEP REP,Rename Method
handle files deleted,"def gather_records(cfg, tub_names, opts=None, verbose=False):","def gather_records(cfg, tub_names, opts=None):",KEEP KEEP KEEP ADD REP,Add Parameter
updating connectors,"def __init__(self, decoder_state_size, name, hparams=None): """"""Initializes the connector.","def __init__(self, name, hparams=None):",KEEP KEEP ADD KEEP KEEP ADD ADD ADD,Add Parameter
Convert settings tool (#737),"def __init__(self, mask_type, output_size, predicted_available, config=None): super().__init__(mask_type, output_size, predicted_available, config)","def __init__(self, mask_type, output_size, predicted_available): super().__init__(mask_type, output_size, predicted_available)",KEEP KEEP KEEP KEEP ADD REP KEEP KEEP ADD REP,Add Parameter
compute pr rates within annotate body,"def annotate(self, corpus, optional_mutable_list_of_pr_rates=None):","def annotate(self, corpus):",KEEP KEEP ADD REP,Add Parameter
added accuracy threshold to the trainers,"def _best_rule(self, train_sents, test_sents, min_score, min_acc):","def _best_rule(self, train_sents, test_sents, min_score):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
More rv_names -> rv_mode,"def parse_rvs(dist, rvs, rv_mode=None, unique=True, sort=True):","def parse_rvs(dist, rvs, rv_names=None, unique=True, sort=True):",KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
add more descriptions,def bravyi_kitaev_sf_edge_list(fer_op):,def bravyi_kitaev_fast_edge_list(fer_op):,KEEP REP,Rename Method
fix global_step scope problem,"def _build_graph(self, input_vars):","def _build_graph(self, input_vars, is_training):",KEEP KEEP REP DEL,Remove Parameter
lib.Slight update (#978),def _update_legacy_landmarksxy(self): ,def update_legacy_landmarksxy(self): ,KEEP REP,Rename Method
-,"def test_conflict_exp_w_child(self, exp_w_child_conflict, storage):","def test_conflict_exp_w_child(self, exp_w_child_conflict):",KEEP KEEP ADD REP,Add Parameter
Move all exp configuration tests to exp_builder,def test_build_no_commandline_config():,"@pytest.mark.usefixtures(""clean_db"", ""init_storage"") def test_build_from_config_no_commandline_config():",DEL DEL KEEP REP,Rename Method
added ranges,"def distribute_cards_to_players(self, deck, player_amount, player_card_list, table_card_list, opponent_allowed_cards):","def distribute_cards_to_players(self, deck, player_amount, player_card_list, table_card_list):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Integrated InputFile class into RMG-Py with the addition of pdepSettings and runSettings attributes.,"def update(self, reactionModel, database, pdepSettings):","def update(self, reactionModel, database):",KEEP KEEP KEEP ADD REP,Add Parameter
Add fixed_initial option to variable builder. Setting fixed_initial=False makes the initial condition of the variable a degree of freedom. The default behavior of APM is fixed_initial=True.,"def MV(self, value=None, lb=None, ub=None, integer=False, fixed_initial=True, name=None):","def MV(self, value=None, lb=None, ub=None, integer=False, name=None):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
[test-vamp] compare projected trajs phase agnostic.,"def assert_allclose_ignore_phase(A, B, atol, rtol=1e-5):","def assert_allclose_ignore_phase(A, B, atol):",KEEP KEEP KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_transform_float32(self):,def testTransformFloat32(self):,KEEP REP,Rename Method
Allow specification of base and mode for cdist_array().,"def cdist_array(cdists, base='linear', mode='asis'):",def cdist_array(cdists):,KEEP ADD ADD REP,Add Parameter
Big refactoring,"def dump(self, file_, indent=4, separators=("","", "": ""), **kwargs):","def dump(self, file_, **kwargs):",KEEP KEEP KEEP ADD ADD ADD ADD KEEP,Add Parameter
MinSaver takes into account checkpoint_dir. (#520),"def __init__(self, monitor_stat, reverse=False, filename=None, checkpoint_dir=None):","def __init__(self, monitor_stat, reverse=False, filename=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Extract updates:,"@classmethod def transform(cls, points: np.ndarray, center_scales: np.ndarray, resolutions: np.ndarray) -> np.ndarray: """""" Transform Image  Parameters ---------- points: :class:`numpy.ndarray` The points to transform center_scales: :class:`numpy.ndarray` The calculated centers and scales for the batch resolutions: :class:`numpy.ndarray` The resolutions """"""","@staticmethod def transform(points, center_scales, resolutions): ",REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP,Add Parameter
Fix generation from LM with seed,"def _weighted_choice(population, weights, random_generator=None):","def _weighted_choice(population, weights, random_seed=None):",KEEP KEEP KEEP REP,Rename Parameter
Fix mutex (#124),"def __init__(self, use_mutex = False):",def __init__(self):,KEEP ADD ADD ADD REP,Add Parameter
refactoring,def resnext152(**kwargs):,def resnet152(**kwargs):,KEEP REP,Rename Method
Bugfixes in DVS iterator to account for image_data_format = 'channels_last'.,"def next_eventframe_batch(x_b_xaddr, x_b_yaddr, x_b_ts, shape, data_format, frame_width):","def next_eventframe_batch(x_b_xaddr, x_b_yaddr, x_b_ts, shape, frame_width):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
fixes for tkinter in nltk.app and nltk.draw packages,def __next__(self):,def next(self):,KEEP REP,Rename Method
handle surface reactor phases properly,"def obj_to_dict(obj, spcs, names=None, label=""solvent""):","def obj_to_dict(obj, spcs, label=""solvent""):",KEEP KEEP KEEP ADD KEEP,Add Parameter
refactor(physics.units): hard code preferred units map into each unit system,"def __init__(self, base_units, units=(), name="""", descr="""", dimension_system=None, derived_units: tDict[Symbol, Quantity]={}):","def __init__(self, base_units, units=(), name="""", descr="""", dimension_system=None):",KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD REP,Add Parameter
Change 'logbase' to 'base'.,"def __init__(self, pmf, events=None, eventspace=None, base=None,","def __init__(self, pmf, events=None, eventspace=None, logbase=None,",KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
Simple backend unit tests (#1020),def _diff_y(img): ,def diff_y(img):,KEEP REP,Rename Method
added tests for Keras models and training,"def __init__(self, input_shape=(120, 160, 3), *args, **kwargs):","def __init__(self, model=None, input_shape=(120, 160, 3), *args, **kwargs):",KEEP KEEP DEL KEEP KEEP KEEP KEEP KEEP,Remove Parameter
Handle race conditions during version increment,"def test_old_experiment_wout_version(self, parent_version_config,","def test_old_experiment_wout_version(self, create_db_instance, parent_version_config,",KEEP KEEP DEL KEEP,Remove Parameter
fix pylint errors,def _get_pluggables_types_dict():,def _get_pluggables_types_dictionary():,KEEP REP,Rename Method
Refactored Rejections sampler,def submit(self): batch_index = self._current_batch_index self._current_batch_index += 1,"def submit(self, batch_index): if batch_index in self.pending_batches: return",KEEP REP REP REP REP REP REP REP,Remove Parameter
Got much better error checking in image serialization.,"def marshall_images(img, captions, width, proto_imgs, clamp):","def marshall_images(img, captions, width, proto_imgs):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
"Revert ""Revert ""Merge remote-tracking branch 'upstream/develop' into feature/i9e""""","@parameterized.expand([ ('dataframe', 'data_frame'), ('table', 'table') ]) def test_unstyled_has_no_style(self, element, proto):",def test_unstyled_has_no_style(self):,ADD ADD ADD ADD ADD ADD KEEP ADD ADD REP,Add Parameter
Convert refactor (#703),"def load_aligned(self, image, size=256, align_eyes=False, dtype=None):","def load_aligned(self, image, size=256, align_eyes=False):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Stats optimization (#1067),"def get_summary_stats(self): """""" Compile the individual session statistics and calculate the total.","def compile_stats(self):  logger.debug(""Compiling sessions summary data"") compiled_stats = self.sessions_stats if not compiled_stats: return compiled_stats logger.debug(""sessions_stats: %s"", compiled_stats) total_stats = self.total_stats(compiled_stats) compiled_stats.append(total_stats) compiled_stats = self.format_stats(compiled_stats) logger.debug(""Final stats: %s"", compiled_stats) return compiled_stats  @staticmethod def total_stats(sessions_stats): ",KEEP REP REP REP REP REP REP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
Only require email (not invite code),"def test__verify_code_bad_code(self):  ret = _verify_code('user@domain.com', '****')","def test_verify_code_bad_code(self):  ret = verify_code('user@domain.com', '****')",KEEP REP KEEP KEEP KEEP REP KEEP,Rename Method
add soft_query ; simplify query and soft_query interface,"def get_default_embed_fn(self, memory_size, embed_fn_hparams):","def get_default_embed_fn(self, embed_fn_hparams):",KEEP KEEP ADD KEEP,Add Parameter
Inferencer API renamed,"def _on_fetches(self, outputs):","def _datapoint(self, outputs):",KEEP REP KEEP,Rename Method
Legacy alignments update,"def __init__(self, alignments_file): logger.debug(""Initializing %s: (alignments file: '%s')"", self.__class__.__name__, alignments_file)","def __init__(self, alignments_file, destination_format): logger.debug(""Initializing %s: (alignments file: '%s', destination_format: '%s')"", self.__class__.__name__, alignments_file, destination_format)",KEEP KEEP REP DEL KEEP KEEP KEEP KEEP DEL DEL KEEP KEEP REP DEL,Remove Parameter
#13 doc update,"def _apply(self, corpus):","def apply(self, corpus):",KEEP REP KEEP,Rename Method
expose setup_graph in all multigpu trainers; TowerContext(use_vs=True) instead of passing a vs_name,"def __init__(self, tower_name, is_training=None, index=0, use_vs=False):","def __init__(self, tower_name, is_training=None, index=0, vs_name=''):",KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
changing code to follow coding conventions,def test_attributes_contain_an_attribute(self):,def testAttributesContainAnAttribute(self):,KEEP REP,Rename Method
"more wip, vqe works now","def __init__(self, operator,  timelimit=600, thread=1, display=2):","def init_args(self, operator,  timelimit=600, thread=1, display=2): self._ins.parse(operator.save_to_dict()['paulis']) self._timelimit = timelimit self._thread = thread self._display = display",KEEP REP KEEP KEEP KEEP KEEP KEEP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
Minor redesign of the corpus readers.  Instead of using 'items' or,"def tuples(self, files):","def tuples(self, documents):",KEEP KEEP REP,Rename Parameter
removed unnecessary RandomTerm class,"def __init__(self, name, data, categorical=False, random=False, prior=None):","def __init__(self, name, data, categorical=False, prior=None):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
fixes to brill to get rid of the yaml dependency,"def applicable_rules(self, tokens, index, correct_tag):","def applicable_rules(self, tokens, index, correctTag):",KEEP KEEP KEEP KEEP REP,Rename Parameter
GUI Updates (#940),"def initialize_config(root, cli_opts, statusbar, session): """""" Initialize the GUI Master :class:`Config` and add to global constant.","def initialize_config(root, cli_opts, scaling_factor, pathcache, statusbar, session): ",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP,Remove Parameter
code cleanup,"def predict_unsegmented(self, X, categorical_target=False):","def predict_segmented_series(self, X, categorical_target=False):",KEEP REP KEEP KEEP,Rename Method
rename for consistency,"def format_row_complete(self, strictnesses=None):","def format_complete(self, strictnesses=None):",KEEP REP KEEP,Rename Method
add branin and carromtable,def get_search_space(self):,def get_task_space(self):,KEEP REP,Rename Method
"Add Registry, rework how Space is passed to algorithms (#833)","def _mutate_population( self, red_team: Sequence[int], blue_team: Sequence[int], rung: dict, population_range: int, fidelity: int | float, ) -> tuple[list[Trial], np.ndarray]:","def _mutate_population(self, red_team, blue_team, rung, population_range, fidelity):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP,Change Return Type
[#60] regex optimize,"def is_special_type_2(self, str):","def type2(self, str):",KEEP REP KEEP,Rename Method
minor refactor,"def frames_from_file(file_name, top, frames, chunksize = 100,","def frames_from_file(file_name, topology, frames, chunksize = 100,",KEEP KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
Add ability to sample random distributions nonuniformly.,"def random_distribution(outcome_length, alphabet_size, alpha=None, prng=None):","def random_distribution(outcome_length, alphabet_size, prng=None):",KEEP KEEP KEEP ADD KEEP,Add Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_no_experiments(setup_pickleddb_database, monkeypatch, capsys):","def test_no_experiments(clean_db, monkeypatch, capsys):",KEEP REP KEEP KEEP,Rename Parameter
expand HHL unittests for different input vectors,"@parameterized.expand([[[0, 1]], [[1, 0]], [[1, 1]], [[1, 10]]]) def test_hhl_diagonal_sv(self, vector):",def test_hhl_diagonal_sv(self):,ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD REP,Add Parameter
small fix,"def _get_NN_prediction(self, image):","def _get_NN_prediction(self, image, is_training):",KEEP KEEP REP DEL,Remove Parameter
- Renamed Classifier.probdist() -> Classifier.prob_classify(),"def batch_prob_classify(self, featuresets):","def batch_probdist(self, featuresets):",KEEP REP KEEP,Rename Method
Combined feature branch for tooltips + theming (#2959),"def _main_run(file, args=None, flag_options=None): if args is None: args = []  if flag_options is None: flag_options = {} ","def _main_run(file, args=[]):",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
init version for quantum device,"def _reuse_shared_circuits(circuits, backend, backend_config, compile_config, run_config, qjob_config=None):","def _reuse_shared_circuits(circuits, backend, execute_config, qjob_config=None):",KEEP KEEP KEEP ADD ADD REP KEEP,Add Parameter
use self.tagtype consistently in raw_parse_sent,"def __init__(self, url='http://localhost:9000', encoding='utf8'): super(CoreNLPPOSTagger, self).__init__('pos', url, encoding)","def __init__(self, tagtype='pos', url='http://localhost:9000', encoding='utf8'): super(CoreNLPPOSTagger, self).__init__(tagtype, url, encoding)",KEEP KEEP DEL KEEP KEEP KEEP REP KEEP KEEP,Remove Parameter
add statevector_simulator support for simon,"def construct_circuit(self, measurement=False): """""" Construct the quantum circuit  Args: measurement (bool): Boolean flag to indicate if measurement should be included in the circuit.  Returns: the QuantumCircuit object for the constructed circuit """""" ",def construct_circuit(self):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Fix lr schedule in hyperband-cifar10 tutorial,"def train(loader, device, model, optimizer, lr_scheduler, criterion):","def train(loader, device, model, optimizer, criterion):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
changing code to follow coding conventions,"def create_klass(self, l):","def createKlass(self, l):",KEEP REP KEEP,Rename Method
implement a lockable FeatureDictionary and remove everywhere the bullshit is_training_mode parameter,"def generate(self, dataset, feature_set, use_gold=True, use_pred=False):","def generate(self, dataset, feature_set, is_training_mode, use_gold=True, use_pred=False):",KEEP KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
refactor controller,def __init__(self): super().__init__() self._controller = Controller(self),"def __init__(self, controller): super().__init__(controller)",KEEP ADD ADD REP REP REP,Remove Parameter
Added optional argument directed=True to all connectivity related api-functions. It is now possible to check connectivity using a undirected graph. This might become important for estimation with fixed stationary distribution,"def is_connected(C, directed=True):",def is_connected(C):,KEEP ADD REP,Add Parameter
start introduction of entity 1 and 2 in class Relation 鈥?don鈥檛 break things,"def __init__(self, start1, start2, text1, text2, type_of_relation, entity1=None, entity2=None):","def __init__(self, start1, start2, text1, text2, type_of_relation):",KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
fix things up,def test_entropy_1_1():,def test_entropy_1():,KEEP REP,Rename Method
Force CONFIGURATION static prop for pluggable classes,def __init__(self): super().__init__(self.CONFIGURATION.copy()),"def __init__(self, configuration=None): super().__init__(configuration or self.RYRZ_CONFIGURATION.copy())",KEEP REP REP DEL DEL DEL,Remove Parameter
allow scalar logging between steps,def _trigger_step(self):  if self.local_step != self._total - 1:,def _trigger(self): self._push(),KEEP ADD ADD ADD ADD ADD ADD REP REP,Rename Method
Refine Factory code and reuse benchmark configure,"def test_create_benchmark(self, benchmark_algorithms, benchmark_config):","def test_create_benchmark(self, benchmark_algorithms):",KEEP KEEP ADD REP,Add Parameter
Simplified widget behavior (#3754),def test_compact(self):,def test_compact_state(self):,KEEP REP,Rename Method
Make rmgpy/rmg/* unit tests PEP-8 compliant,def test_rmg_seed_mechanism_creation(self):,def testRMGSeedMechanismCreation(self):,KEEP REP,Rename Method
initial commit,"def total_degree(en, s): """""" total_degree","def _entry_deg(en, s): """"""_entry_deg",KEEP REP KEEP ADD REP,Rename Method
support pauli z order expansion and any pauli term expansion,"@staticmethod def construct_evolution_circuit(slice_pauli_list, evo_time, num_time_slices, state_registers,","def construct_evolution_circuit(self, slice_pauli_list, evo_time, num_time_slices, state_registers,",ADD KEEP REP DEL KEEP KEEP KEEP,Remove Parameter
Force CONFIGURATION static prop for pluggable classes,def __init__(self): super().__init__(self.CONFIGURATION.copy()),"def __init__(self, configuration=None): super().__init__(configuration or self.SLSQP_CONFIGURATION.copy())",KEEP REP REP DEL DEL DEL,Remove Parameter
Implemented testing of explicitly specified samples instead of the whole batch.,"def load_ann(filename, path=None): """""" Load network from file.  Parameters ----------  model : dict A dictionary of objects that constitute the input model. It must contain the following two keys:  - 'model': Model instance of the network in the respective ``model_lib``. - 'val_fn': Theano function that allows evaluating the original model.  For instance, if the input model was written using Keras, the 'model'-value would be an instance of ``keras.Model``, and 'val_fn' the ``keras.Model.evaluate`` method.  """"""  if path is None: path = settings['path']",def load_ann(filename):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
re #385: default to no vocab pruning,"def build_vocab(self, sentences, keep_raw_vocab=False):","def build_vocab(self, sentences):",KEEP KEEP ADD REP,Add Parameter
Smart Masks to Convert (#957),"def _get_erosion_kernel(self, mask): """""" Get the erosion kernel.  Parameters ---------- mask: :class:`numpy.ndarray` The mask to be eroded or dilated  Returns ------- :class:`numpy.ndarray` The erosion kernel to be used for erosion/dilation """"""","def get_erosion_kernel(self, mask): ",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
Created double and numpy.ndarray versions of methods for kinetics and reaction objects.,"def getEquilibriumConstant(self, T, type='Kc'):","def getEquilibriumConstant(self, Tlist, type='Kc'):",KEEP KEEP REP KEEP,Rename Parameter
restructure and clean,"def __init__(self, model_path=tempfile.NamedTemporaryFile().name, classification_threshold=0.0, use_tree_kernel=False, svmlight_dir_path=''):  self.model_path = model_path  print_debug(""SVM-Light model file path: "" + model_path)  self.classification_threshold = classification_threshold  self.use_tree_kernel = use_tree_kernel  ","def __init__(self, svmlight_dir_path='', model_path=tempfile.NamedTemporaryFile().name, use_tree_kernel=True):",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP,Add Parameter
Output saving functional,"def __init__(self, name=None, source_net=None, parameters=None, computation_context=None): self.name = name or ""model_{}"".format(random_name())","def __init__(self, source_net=None, parameters=None, computation_context=None):",KEEP KEEP ADD KEEP KEEP KEEP ADD ADD ADD ADD ADD,Add Parameter
Added documentation,"def __show_barplot(self, array, legend=None, rownames=None, name=None, env_appendix="""", **kwargs): """""" Internal show_barplot method, called by the internal process. This function does all the magic. """"""","def __show_barplot(self, array, legend=None, rownames=None, name=None, env_app="""", **kwargs):",KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Parameter
transformed camelCase to snake_case test names (#3033),def test_serialized(self):,def testSerialized(self):,KEEP REP,Rename Method
sort by Automatically switch to vector_linkage if not enough free RAM,"@staticmethod def get_model(git_model_id, model_filename, backend):","def get_model(self, git_model_id, model_filename, backend):",ADD KEEP REP DEL KEEP KEEP,Remove Parameter
Replace ExperimentBuilder methods by new functions,"def __init__(self, database=None, setup=True): if database is not None: setup_database(database)","def __init__(self, config=None, setup=True): if config is not None: setup_database(config)",KEEP KEEP REP KEEP KEEP REP KEEP KEEP KEEP REP,Rename Parameter
Remove the 'environ' variables and change how Jobs run,"def __init__(self, molfile, qmdata, pointGroup = None):","def __init__(self, molfile, qmdata, environ = os.environ.get(""RMG.workingDirectory""), pointGroup = None):",KEEP KEEP KEEP KEEP DEL DEL DEL KEEP KEEP KEEP,Remove Parameter
Make augmentors return a `Transform` instance. (#1290),"def __init__(self, y0, x0, h, w):","def __init__(self, h0, w0, h, w):",KEEP KEEP REP REP KEEP KEEP,Rename Parameter
word_tokenize for languages other than English,"def word_tokenize(text, language='english'):",def word_tokenize(text):,KEEP ADD REP,Add Parameter
Added unit tests for inverse training,"def __init__(self, Gm, depth=10, implementation_fwd=1, implementation_bwd=1, keep_input=False):","def __init__(self, Gm, depth=10, implementation=1, keep_input=False):",KEEP KEEP KEEP KEEP ADD REP KEEP,Add Parameter
Make testing/databaseTest.py unit tests PEP-8 compliant,"def kinetics_check_siblings_for_parents(self, family_name):","def kinetics_checkSiblingsForParents(self, family_name):",KEEP REP KEEP,Rename Method
more work on real gym donkey,"def __init__(self, name, broker=""iot.eclipse.org"", def_value=None):","def __init__(self, name, broker=""iot.eclipse.org""):",KEEP KEEP KEEP ADD REP,Add Parameter
updated BLEU to all return all-gram scores,"def corpus_bleu(list_of_references, hypotheses, lowercase=False, return_all=False):","def corpus_bleu(list_of_references, hypotheses, lowercase=False):",KEEP KEEP KEEP ADD REP,Add Parameter
Added sorting key,"def __init__(self, x, y, disp_res=False, sorted_data = True):","def __init__(self, x, y, disp_res=False):",KEEP KEEP KEEP KEEP ADD ADD ADD REP,Add Parameter
Start remove json api,"def test_vqe(self):  result = VQE(self.qubit_op, RYRZ(self.qubit_op.num_qubits), L_BFGS_B()).run( QuantumInstance(BasicAer.get_backend('statevector_simulator'), basis_gates=['u1', 'u2', 'u3', 'cx', 'id'], coupling_map=[[0, 1]], seed_simulator=aqua_globals.random_seed, seed_transpiler=aqua_globals.random_seed))","def test_vqe_via_run_algorithm(self):  coupling_map = [[0, 1]] basis_gates = ['u1', 'u2', 'u3', 'cx', 'id']  params = { 'problem': {'random_seed': self.seed}, 'algorithm': {'name': 'VQE'}, 'backend': {'name': 'statevector_simulator', 'provider': 'qiskit.BasicAer', 'coupling_map': coupling_map, 'basis_gates': basis_gates}, } result = run_algorithm(params, EnergyInput(self.qubit_op))",KEEP REP KEEP REP KEEP REP REP REP REP REP KEEP KEEP KEEP REP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
"make all mut_class_id a parameter of the mutation readers, which should be moved to nala anyway","def __init__(self, path, mut_class_id):","def __init__(self, path):",KEEP KEEP ADD REP,Add Parameter
Remove neighbors function.,"def projections(pmf, depth, base=2, method=None):","def projections(pmf, depth, base=2): """""" Returns the projections on the way to the nearest grid point.",KEEP KEEP KEEP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Add Parameter
Got progress bars working when saving reports.,"@gen.coroutine def _s3_upload_files(self, files, progress_coroutine): for i, (path, data) in enumerate(files):","@run_on_executor def _s3_upload_files(self, files): for path, data in files:",REP KEEP KEEP ADD REP KEEP ADD REP REP KEEP REP,Add Parameter
Support EVC in all algos,"def get_id(self, point, ignore_fidelity=True): ","def get_id(self, point): ",KEEP KEEP ADD REP,Add Parameter
ObjectDetection cleanup,"def detections(self, num_output, metadata, deltas, proposals, scores, masks): proposals = keras.backend.reshape(proposals, (-1, 4))","def detections(num_output, metadata, deltas, proposals, scores, masks): proposals = keras.backend.reshape(proposals, (-1, 4))",KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_s_one_pre(self):,def testSOnePre(self):,KEEP REP,Rename Method
Started rewriting class using utils ncx_na object. Maybe global phase missing after QPE?,"def _execute_rotation(self,shots):",def _execute_rotation(self):,KEEP REP,Add Parameter
updated configs,"def forward_impl(self, x):","def forard_impl(self, x):",KEEP REP KEEP,Rename Method
Fix third-party dependency issues and support scikit-learn 0.24 and scipy 1.6 (#1147),"def __init__(self, estimator, ax=None, is_fitted=""auto"", **kwargs):","def __init__(self, model, ax=None, is_fitted=""auto"", **kwargs):",KEEP KEEP REP KEEP KEEP KEEP,Rename Parameter
AppSession: handle script events on the main thread (#4467),def _create_script_finished_message(,def _enqueue_script_finished_message(,KEEP REP,Rename Method
Add evaluate option to matpow and hadamard,"def __new__(cls, base, exp, evaluate=False, **options):","def __new__(cls, base, exp):",KEEP KEEP KEEP ADD ADD REP,Add Parameter
"[msm/estimation] Implemented new feature for count_matrix function. The shape of the returned matrix is always (nstates, nstates) with nstates the number of states observed at lagtime=1. The implementation has a new optional nstates keyword. This keyword allows to specify the total number of states, nstates, in the model. If the specified number, nstates, is smaller than the number of states observed at lagtime=1 an error is raised. The leyword is potentially useful for analysing e.g umbrella sampling data. If most of the umbrellas never visit states with a high state index, but a set of compatible count-matrices (with same shape) is required, e.g. for TRAM analysis, the user can set the nstate keyword and obtain a set of compatible matrices. The unit tests have been extended to cover the keyword. The default value of some test-cases had to change in order to acompany the new convention","def count_matrix_mult(dtrajs, lag, sliding=True, sparse=True, nstates=None):","def count_matrix_mult(dtrajs, lag, sliding=True, sparse=True):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Features refactored (less flexible but faster),"def nodes_per_dai(tree, context):","def nodes_per_dai(cur_node, context, scope_func, incremental=False):",KEEP REP REP DEL DEL,Remove Parameter
Align _match_potential_end_contexts with NLTK 3.6.5 sent_tokenize results,"def _slices_from_text(self, text: str) -> Iterator[slice]:","def _slices_from_text(self, text):",KEEP KEEP ADD ADD ADD REP,Change Return Type
Make rmgpy/solver/* unit tests PEP-8 compliant,def test_solve(self):,def testSolve(self):,KEEP REP,Rename Method
cleanup the use of preact,"def se_resnet_bottleneck(l, ch_out, stride): shortcut = l","def se_resnet_bottleneck(l, ch_out, stride, preact): l, shortcut = apply_preactivation(l, preact)",KEEP KEEP KEEP REP DEL DEL KEEP KEEP REP DEL,Remove Parameter
Logging (#541),def get_driver(self):,@staticmethod def get_driver():,DEL KEEP REP,Add Parameter
Better error messages for st.cache (#1146),def _key(obj):,"def _key(obj, context):",KEEP REP DEL,Remove Parameter
Increase area and move centering (#1095),"def _get_mask(self, detected_face, predicted_mask, sub_crop_offset):","def _get_mask(self, detected_face, predicted_mask):",KEEP KEEP KEEP ADD REP,Add Parameter
Fix filling pluggables default parameters,def __init__(self): super().__init__(self.CONFIGURATION.copy()),"def __init__(self, configuration=None): super().__init__(configuration or self.CONFIGURATION.copy())",KEEP REP REP DEL DEL DEL,Remove Parameter
changing code to follow coding conventions,def test_divide_by_zero_error_thrown_if_den_is_zero(self):,def testDivideByZeroErrorThrownIfDenIsZero(self):,KEEP REP,Rename Method
- Removed test for ProbabilisticToken,def testsuite(reload_module=False):,def testsuite():,KEEP REP,Add Parameter
Optimize `FastText.load_fasttext_model` (#2340),"def _compute_ngrams_py(word, min_n, max_n): """"""Get the list of all possible ngrams for a given word. Parameters ---------- word : str The word whose ngrams need to be computed. min_n : int Minimum character length of the ngrams. max_n : int Maximum character length of the ngrams. Returns ------- list of str Sequence of character ngrams. """""" BOW, EOW = ('<', '>')   extended_word = BOW + word + EOW ngrams = [] for ngram_length in range(min_n, min(len(extended_word), max_n) + 1): for i in range(0, len(extended_word) - ngram_length + 1): ngrams.append(extended_word[i:i + ngram_length]) return ngrams   def _compute_ngrams_bytes_py(word, min_n, max_n): """"""Computes ngrams for a word.  Ported from the original FB implementation.  Parameters ---------- word : str A unicode string. min_n : unsigned int The minimum ngram length. max_n : unsigned int The maximum ngram length.  Returns: -------- list of str A list of ngrams, where each ngram is a list of **bytes**.  See Also -------- `Original implementation <https://github.com/facebookresearch/fastText/blob/7842495a4d64c7a3bb4339d45d6e64321d002ed8/src/dictionary.cc  """""" utf8_word = ('<%s>' % word).encode(""utf-8"") num_bytes = len(utf8_word) n = 0  ngrams = [] for i in range(num_bytes): if _is_utf8_continue(utf8_word[i]): continue  j, n = i, 1 while j < num_bytes and n <= max_n: j += 1 while j < num_bytes and _is_utf8_continue(utf8_word[j]): j += 1 if n >= min_n and not (n == 1 and (i == 0 or j == num_bytes)): ngram = bytes(utf8_word[i:j]) ngrams.append(ngram) n += 1 return ngrams          ","def _compute_ngrams(word, min_n, max_n): """"""Get the list of all possible ngrams for a given word.",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
decision tree is being constructed,"def best_decision_stump(self, ignore_attributes = [], algorithm = 'minimum_error'): stumps = self.create_empty_decision_stumps(ignore_attributes);",def best_decision_stump(self): stumps = self.create_empty_decision_stumps();,KEEP ADD ADD ADD ADD ADD ADD REP KEEP KEEP REP,Add Parameter
Make rmgpy/rmg/* unit tests PEP-8 compliant,def test_check_for_existing_species_for_bi_aromatics(self):,def testCheckForExistingSpeciesForBiAromatics(self):,KEEP REP,Rename Method
Add support for all other (except KerasLatent) models: (#884),"def run(self, img_arr, other_arr=None): if img_arr.shape[2] == 3 and self.input_shape[2] == 1: img_arr = dk.utils.rgb2gray(img_arr)  while len(self.img_seq) < self.seq_length: self.img_seq.append(img_arr)  self.img_seq = self.img_seq[1:] self.img_seq.append(img_arr) new_shape = (self.seq_length, *self.input_shape) img_arr = np.array(self.img_seq).reshape(new_shape) img_arr_norm = normalize_image(img_arr) return self.inference(img_arr_norm, other_arr)  def interpreter_to_output(self, interpreter_out) \ -> Tuple[Union[float, np.ndarray], ...]: steering = interpreter_out[0] throttle = interpreter_out[1] return steering, throttle  def output_shapes(self):  img_shape = self.get_input_shapes()[0][1:]  shapes = ({'img_in': tf.TensorShape(img_shape)}, {'outputs': tf.TensorShape([self.num_outputs])}) return shapes   class KerasLatent(KerasPilot): def __init__(self, interpreter: Interpreter = KerasInterpreter(), input_shape: Tuple[int, ...] = (120, 160, 3), num_outputs: int = 2): self.num_outputs = num_outputs super().__init__(interpreter, input_shape)  def create_model(self): return default_latent(self.num_outputs, self.input_shape)  def compile(self): loss = {""img_out"": ""mse"", ""n_outputs0"": ""mse"", ""n_outputs1"": ""mse""} weights = {""img_out"": 100.0, ""n_outputs0"": 2.0, ""n_outputs1"": 1.0} self.interpreter.compile(optimizer=self.optimizer, loss=loss, loss_weights=weights)","def inference(self, img_arr, other_arr):  if img_arr.shape[2] == 3 and self.input_shape[2] == 1: img_arr = dk.utils.rgb2gray(img_arr)  while len(self.img_seq) < self.seq_length: self.img_seq.append(img_arr)  self.img_seq = self.img_seq[1:] self.img_seq.append(img_arr)  img_arr = np.array(self.img_seq).reshape((1, self.seq_length, *self.input_shape)) outputs = self.model([img_arr]) steering = outputs[0][0].numpy() throttle = outputs[0][1].numpy() return steering, throttle",KEEP REP KEEP REP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP KEEP KEEP REP KEEP KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
implement reading of hdfs files in HTMLReader,def __read_directory_local_fs(self):,def __read_directory(self):,KEEP REP,Rename Method
Add RVFunctions.from_mapping and RVFunctions.from_partition.,def test_rvfunctions4():,def test_booleanfunctions4():,KEEP REP,Rename Method
Update TFLite detector to support ssd_mobilenet_v2_coco.,"def __init__(self, model, labels, num_threads=1, threshold=0.5):","def __init__(self, model, labels):",KEEP KEEP KEEP ADD ADD REP,Add Parameter
Logging (#541),"def __init__(self, interface, loglevel):","def __init__(self, interface, verbose):",KEEP KEEP KEEP REP,Rename Parameter
Smart Masks to Convert (#957),"def reset_config_to_default(self, section=None): """""" Reset the GUI parameters to their default configuration values.  Parameters ---------- section: str, optional The configuration section to reset the values for, If ``None`` provided then all sections are reset. Default: ``None`` """"""","def reset_config_default(self, section=None): ",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
add tests for the secret key bounds,"def necessary_intrinsic_mutual_information(dist, rvs, crvs, rv_mode=None, bound_u=None, bound_v=None):","def necessary_intrinsic_mutual_information(dist, rvs, crvs, rv_mode=None):",KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
add embedder dropout,"def __init__(self, init_value=None, vocab_size=None, hparams=None, mode=None):","def __init__(self, init_value=None, vocab_size=None, hparams=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
nltk/corpus/reader/util.py,"def __init__(self, root, documents, extension, chunk_types): if isinstance(documents, basestring): documents = find_corpus_items(root, documents, extension)","def __init__(self, root, items, extension, chunk_types): if isinstance(items, basestring): items = find_corpus_items(root, items, extension)",KEEP KEEP KEEP REP KEEP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP,Rename Parameter
Specify encoding when reading the user's script. Fixes #399 (#441),"@parameterized.expand([ (""good_script.py"", text_utf), (""good_script_no_encoding.py"", text_no_encoding), (""good_script_latin_encoding.py"", text_latin), ]) def test_run_script(self, filename, text):",def test_run_script(self):,ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD REP,Add Parameter
updating core/layers.py,def default_regularizer_hparams():,def _default_regularizer_hparams():,KEEP REP,Rename Method
closed #62,"def __init__(self, models, ax=None, **kwargs):","def __init__(self, models, **kwargs):",KEEP KEEP KEEP ADD KEEP,Add Parameter
[Feature Branch] File uploader (#2130),"def file_uploader( dg, label, type=None, accept_multiple_files=False, key=None, **kwargs ):","def file_uploader(dg, label, type=None, key=None, **kwargs):",KEEP ADD REP KEEP KEEP ADD KEEP ADD REP,Add Parameter
refactor,"def _unmap(self, data, inds_inside, fill=0):","@staticmethod def _unmap(data, count, inds_inside, fill=0):",DEL KEEP REP REP KEEP KEEP,Rename Parameter
SemcorCorpusReader was returning incomplete sense information,"def __init__(self, root, fileids, wordnet, lazy=True):","def __init__(self, root, fileids, lazy=True):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
add `measurement` boolean flag to qpe's `construct_circuit()`,"def construct_circuit(self, measurement=False):",def construct_circuit(self):,KEEP ADD REP,Add Parameter
Resolve comments,"def _modify_config_data(max_seq_length, num_train_data, num_classes):","def modify_config_data(max_seq_length, num_train_data, num_classes):",KEEP REP KEEP KEEP,Rename Method
transformed camelCase to snake_case test names (#3033),def test_evaluate_word_pairs_from_file(self):,def testEvaluateWordPairsFromFile(self):,KEEP REP,Rename Method
Added method get_field_as_string to Entry; added method parse to Lexicon class.,"def __init__(self, file):",def __init__(self):,KEEP ADD REP,Add Parameter
add config for max learned throttle range,"def __init__(self, input_shape=(120, 160, 3), throttle_range=0.5, *args, **kwargs):","def __init__(self, input_shape=(120, 160, 3), *args, **kwargs):",KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
Better method signatures (#88),def test_remove_self_from_sig(self): wrapped = _remove_self_from_sig(FakeDeltaGenerator.fake_dataframe),def test_clean_up_sig(self): wrapped = _clean_up_sig(FakeDeltaGenerator.fake_dataframe),KEEP REP KEEP KEEP REP,Rename Method
Change 'event' to 'outcome'.,"def outcome_length(self, masked=False):","def event_length(self, masked=False):",KEEP REP KEEP,Rename Method
solvers.ode: Added docstring for _linear_neq_order1_solver,"def _linear_neq_order1_solver(A, t, b=None, B=None, type=""type4"", doit=False): r"""""" System of n equations linear first-order differential equations  .. math:: X'(t) = A(t) X(t) +  b(t)  Here, $A(t)$ is the coefficient matrix, $X(t)$ is the vector of n independent variables, $b(t)$ is the non-homogeneous term and $X'(t)$ is the derivative of $X(t)$  Depending on the properties of $A(t)$ and $b(t)$, this solver evaluates the solution differently.  When $A(t)$ is constant coefficient matrix and $b(t)$ is zero vector i.e. system is homogeneous, the solution is:  .. math:: X(t) = \exp(A t) C  Here, $C$ is a vector of constants and $A$ is the constant coefficient matrix.  When $A(t)$ is constant coefficient matrix and $b(t)$ is non-zero i.e. system is non-homogeneous, the solution is:  .. math:: X(t) = e^{A t} ( \int e^{- A t} b \,dt + C)  When $A(t)$ is coefficient matrix such that its commutative with its antiderivative $B(t)$ and $b(t)$ is a zero vector i.e. system is homogeneous, the solution is:  .. math:: X(t) = \exp(B(t)) C  When $A(t)$ is commutative with its antiderivative $B(t)$ and $b(t)$ is non-zero i.e. system is non-homogeneous, the solution is:  .. math:: X(t) =  e^{B(t)} ( \int e^{-B(t)} b(t) \,dt + C)  The final solution is the general solution for all the four equations since a constant coefficient matrix is always commutative with its antidervative.  Parameters ==========  A : Matrix Coefficient matrix of the system of linear first order ODEs. t : Symbol Independent variable in the system of ODEs. b : Matrix or None Non-homogeneous term in the system of ODEs. If None is passed, a homogeneous system of ODEs is assumed. B : Matrix or None Antiderivative of the coefficient matrix. If the antiderivative is not passed and the solution requires the term, then the solver would compute it internally. type : String Type of the system of ODEs passed. Depending on the type, the solution is evaluated. The type values allowed and the corresponding system it solves is given below: 1. ""type1"" : constant coefficient homogeneous 2. ""type2"" : constant coefficient non-homogeneous 3. ""type3"" : non-constant coefficient homogeneous 4. ""type4"" : non-constant coefficient non-homogeneous The default value is ""type4"" since that solution can be used to get solutions for all the four types. Passing the correct type is encouraged as evaluating ""type4"" solution takes more time than other types. doit : Boolean In some solutions, there maybe unevaluated expressions and if this argument is True, then the solutions would be evaluated. Default value is False  Returns =======  List  Examples ========  To solve the system of ODEs using this function directly, several things must be done in the right order. Wrong inputs to the function will lead to incorrect results.  >>> from sympy import symbols, Function, Eq >>> from sympy.solvers.ode.systems import (_canonical_equations, linear_ode_to_matrix, ...     _linear_neq_order1_solver, _is_commutative_anti_derivative) >>> from sympy.solvers.ode.subscheck import checksysodesol >>> f, g = symbols(""f, g"", cls=Function) >>> x, a = symbols(""x, a"") >>> funcs = [f(x), g(x)] >>> eqs = [Eq(f(x).diff(x) - f(x), a*g(x) + 1), Eq(g(x).diff(x) + g(x), a*f(x))]  Here, it is important to note that before we derive the coefficient matrix, it is important to get the system of ODEs into the desired form. For that we will use :obj:`~sympy.solvers.ode.systems._canonical_equations()`.  >>> eqs = _canonical_equations(eqs, funcs, x) >>> eqs [Eq(Derivative(f(x), x), a*g(x) + f(x) + 1), Eq(Derivative(g(x), x), a*f(x) - g(x))]  Now, we will use :obj:`~sympy.solvers.ode.systems.linear_ode_to_matrix()` to get the coefficient matrix and the non-homogeneous term if it is there.  >>> (A1, A0), b = linear_ode_to_matrix(eqs, funcs, x, 1) >>> A = -A0  We have the coefficient matrices and the non-homogeneous term ready. If you the system is homogeneous, then there is no need to pass the argument *b*.  >>> sol_vector = _linear_neq_order1_solver(A, x, b=b, type=""type2"")  Now, we can prove if the solution is correct or not by using :obj:`~sympy.solvers.ode.subscheck.checksysodesol()`  >>> sol = [Eq(f, s) for f, s in zip(funcs, sol_vector)] >>> checksysodesol(eqs, sol) (True, [0, 0])  We can also use the doit method to evaluate the solutions passed by the function.  >>> sol_vector_evaluated = _linear_neq_order1_solver(A, x, b=b, type=""type2"", doit=True)  Now, we will look at a system of ODEs which is non-constant.  >>> eqs = [Eq(f(x).diff(x), f(x) + x*g(x)), Eq(g(x).diff(x), -x*f(x) + g(x))]  The system defined above is already in the desired form, so we don't have to convert it.  >>> (A1, A0), b = linear_ode_to_matrix(eqs, funcs, x, 1) >>> A = -A0  A user can also pass the commutative antidervative required for type3 and type4 system of ODEs. Passing an incorrect one will lead to incorrect results. We can check if the coefficient matrix is commutative with the antiderivative and get the antiderivative using :obj:`~sympy.solvers.ode.systems._is_commutative_anti_derivative()`.  >>> B, is_commuting = _is_commutative_anti_derivative(A, x) >>> is_commuting True  Now, we can pass the antiderivative as an argument to get the solution. If it is not passed, then this solver computes the antiderivative for the solution.  >>> sol_vector = _linear_neq_order1_solver(A, x, B=B, type=""type3"")  Once again, we can verify the solution obtained.  >>> sol = [Eq(f, s) for f, s in zip(funcs, sol_vector)] >>> checksysodesol(eqs, sol) (True, [0, 0])  Raises ======  ValueError This error is raised when: 1. The coefficient matrix, its antiderivative or the non-homogeneous term if passed, isn't a matrix 2. There is a dimension mismatch between the coefficient matrix and either the antiderivative or the non-homogeneous term 3. The type passed isn't a valid one NonSquareMatrixError When the coefficient matrix or its antiderivative, if passed isn't a square matrix  See Also ========  linear_ode_to_matrix: Coefficient matrix computation function  """"""","def _linear_neq_order1_solver(A, t, rhs=None, B=None, type=""type4"", doit=False): r",KEEP KEEP KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Parameter
small internal rename,def get_input_tensors(self):,def _get_input_tensors(self):,KEEP REP,Rename Method
Merged Armando's remote branch in.,"def _print_remote_url(port, quoted_name):","def _get_remote_urls(port, quoted_name):",KEEP REP KEEP,Rename Method
minor fix for async,"def __init__(self, state, action, reward, misc=None): ","def __init__(self, state, action, reward):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Inferencer API renamed,"def _datapoint(self, results): pass  def _on_fetches(self, results): raise NotImplementedError() ","@abstractmethod def _datapoint(self, output): pass ",DEL KEEP KEEP REP KEEP ADD ADD ADD ADD ADD ADD,Rename Parameter
merged from hhl-test,"def init_args(self, matrix, vector, eigs, init_state, reciprocal, mode,","def init_args(self, matrix, invec, eigs, init_state, reciprocal, mode,",KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
"re-applied changes from https://github.com/jskda/nltk/commit/06d75ceaec1c561d5d5548b597db6e6bb26eb0a3, cf https://github.com/nltk/nltk/issues/670",def tree2semi_rel(tree):,def _tree2semi_rel(tree):,KEEP REP,Rename Method
"Various housekeeping fixes: doctests, python2 compat, linters","def __init__(self, order, **kwargs): super().__init__(WittenBell, order, **kwargs)","def __init__(self, *args, **kwargs): super().__init__(WittenBell, *args, **kwargs)",KEEP KEEP REP KEEP KEEP REP KEEP,Add Parameter
"renamed batch_parse/tag/tokenize to parse/tag/tokenize_sents, cf issue #561","def interpret_multi_sents(self, inputs, discourse_ids=None, question=False, verbose=False):","def batch_interpret_multisentence(self, inputs, discourse_ids=None, question=False, verbose=False):",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
setup.py: implement logging,"def __init__(self, updater: bool = False) -> None:","def __init__(self, logger: Optional[""Logger""] = None, updater: bool = False) -> None: """""" logger will override built in Output() function if passed in updater indicates that this is being run from update_deps.py so certain steps can be skipped/output limited """"""",KEEP KEEP DEL DEL DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
particle hole update for open fixes #595,"def particle_hole_transformation(n_qubits, num_particles, h1_old_matrix, h2_old_matrix):","def particle_hole_transformation(n_qubits, n_occupied, h1_old_matrix, h2_old_matrix):",KEEP KEEP REP KEEP KEEP,Rename Parameter
use init term instead of create for methods,"def init_led(self, port):","def assign_led(self, port):",KEEP REP KEEP,Rename Method
Add command-line option to control generation of plots in CanTherm.,"def execute(self, outputFile=None, plot=False):","def execute(self, outputFile=None):",KEEP KEEP ADD REP,Add Parameter
remove confusing test cases,"def test_experiment_number_same_list_status(clean_db,","def test_experiment_number_same_list_status(clean_db, only_invalidalgo_experiments_db,",KEEP KEEP DEL,Remove Parameter
"[msm/estimation] Implemented new feature for count_matrix function. The shape of the returned matrix is always (nstates, nstates) with nstates the number of states observed at lagtime=1. The implementation has a new optional nstates keyword. This keyword allows to specify the total number of states, nstates, in the model. If the specified number, nstates, is smaller than the number of states observed at lagtime=1 an error is raised. The leyword is potentially useful for analysing e.g umbrella sampling data. If most of the umbrellas never visit states with a high state index, but a set of compatible count-matrices (with same shape) is required, e.g. for TRAM analysis, the user can set the nstate keyword and obtain a set of compatible matrices. The unit tests have been extended to cover the keyword. The default value of some test-cases had to change in order to acompany the new convention","def count_matrix_bincount_mult(dtrajs, lag, sliding=True, sparse=True, nstates=None):","def count_matrix_bincount_mult(dtrajs, lag, sliding=True, sparse=True, ndim=None):",KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
Use newer annotations features in caching modules (#5738),def get_stats(self) -> list[CacheStat]:,def get_stats(self) -> List[CacheStat]:,KEEP KEEP KEEP REP,Change Return Type
Add git info to sourcepacker,"def __init__(self, file_name, base_dir=None, to_console=False): ","def __init__(self, file_name, base_dir=None): ",KEEP KEEP KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_save_load_string_scoring(self):,def testSaveLoadStringScoring(self):,KEEP REP,Rename Method
Replace DAWG with TinyFastSS,"def _levsim(self, t1, t2, distance):","def _levsim(self, t1, t2): from Levenshtein import distance ",KEEP KEEP KEEP REP REP DEL DEL DEL,Add Parameter
"Minibatching for VQSVM, with caching",def test_qsvm_variational_with_minbatching(self):,def test_qsvm_variational_with_minibatching(self):,KEEP REP,Rename Method
search for 3_atom_2_bond_paths in fixCharge,"def find_4_atom_3_bond_path(start, end):","def find_delocalized_path(start, end):",KEEP REP KEEP,Rename Method
Faceswap 2.0 (#1045),"def _get_supported_devices(self): """""" Obtain GPU devices from PlaidML that are marked as ""supported"".  Returns ------- list The :class:`pladml._DeviceConfig` objects for GPUs that PlaidML has discovered. """"""",def get_supported_devices(self): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
changing code to follow coding conventions,"def __pos_of_colon(self, line):","def __posOfColon(self, line):",KEEP REP KEEP,Rename Method
implement a lockable FeatureDictionary and remove everywhere the bullshit is_training_mode parameter,"def add_to_feature_set(self, feature_set, edge, feature_name, value=1):","def add_to_feature_set(self, feature_set, is_training_mode, edge, feature_name, value=1):",KEEP KEEP KEEP DEL KEEP KEEP KEEP,Remove Parameter
Allow dists for Bayesian networks to be functions.,"def prob(outcome, dists=dists): node_outcome = outcome_ctor([ outcome[rv_index[rv]] ])","def prob(outcome, dist=dist): rv_outcome = outcome_ctor([ outcome[rv_index[rv]] ])",KEEP KEEP REP REP KEEP KEEP KEEP KEEP,Rename Parameter
Make plots use trials in EVC by default,"def rankings(experiments, with_evc_tree=True, order_by=""suggested"", **kwargs):","def rankings(experiments, order_by, **kwargs):",KEEP KEEP ADD REP KEEP,Add Parameter
[coor/featurizer] add periodic argument to angle derived features.,"def add_chi1_torsions(self, selstr="""", deg=False, cossin=False, periodic=True):","def add_chi1_torsions(self, selstr="""", deg=False, cossin=False):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Reuse a circuit for multiple parameter sets in aer (#1222),"def validate_aer_templates_reused(prev_templates, cur_templates): self.assertIs(prev_templates, cur_templates)","def validate_aer_templates_reused(prev_status, cur_status): self.assertIs(prev_status, cur_status)",KEEP REP REP REP REP,Rename Parameter
Configurable ngram counter on model,"def __init__(self, order, vocabulary=None, counter=None, ngrams_fn=None, pad_fn=None):","def __init__(self, order, vocabulary=None, ngrams_fn=None, pad_fn=None):",KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
allow specifying substitution cost in edit distance,"def _edit_dist_step(lev, i, j, s1, s2, substitution_cost=1, transpositions=False):","def _edit_dist_step(lev, i, j, s1, s2, transpositions=False):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Implement save and load-method for brian2-simulator,"def build_dense(self, layer, input_weight=None):","def build_dense(self, layer):",KEEP KEEP ADD REP,Add Parameter
1. do not expose run_config,"def _reuse_shared_circuits(circuits, backend, compile_config, run_config,","def _reuse_shared_circuits(circuits, backend, backend_config, compile_config, run_config,",KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
Don't pass pdepSettings around between functions when they can get it themselves.,"def addSeedMechanismToCore(self, seedMechanism, react=False):","def addSeedMechanismToCore(self, seedMechanism, pdepSettings, react=False):",KEEP KEEP KEEP DEL KEEP,Remove Parameter
app_session_test cleanup (#4459),"def test_clear_cache_resets_session_state(self): session = _create_test_session() session._session_state[""foo""] = ""bar"" session.handle_clear_cache_request() self.assertTrue(""foo"" not in session._session_state)","@patch(""streamlit.app_session.LocalSourcesWatcher"") def test_clear_cache_resets_session_state(self, _1): rs = AppSession( None, SessionData("""", """"), UploadedFileManager(), None, MagicMock() ) rs._session_state[""foo""] = ""bar"" rs.handle_clear_cache_request() self.assertTrue(""foo"" not in rs._session_state)",DEL KEEP REP REP DEL KEEP REP REP DEL DEL DEL DEL DEL DEL DEL KEEP KEEP REP KEEP KEEP KEEP REP,Remove Parameter
HartreeFock and UCCSD num qubit param removal. (#939),"def __init__(self,","def __init__(self, num_qubits: int, depth: int,",KEEP KEEP DEL DEL DEL DEL,Remove Parameter
extend and use amplitude estimation run() method,"def _evaluate_statevector_results(self, probabilities):","def evaluate_results(self, probabilities):",KEEP REP KEEP,Rename Method
Logging (#541),"def __init__(self, model_path, ratio=1.0):   import tensorflow as tf self.tf = tf ","def __init__(self, model_path, verbose=False, ratio=1.0): self.verbose = verbose",KEEP KEEP KEEP ADD ADD ADD ADD ADD REP REP REP KEEP REP,Remove Parameter
object avoidance project + I2C mutex + updated docs (#88),"def __init__(self, port=""I2C"",gpg=None, use_mutex=False):","def __init__(self, port=""I2C"",gpg=None):",KEEP KEEP ADD REP,Add Parameter
refactor around trainer and add some docs,def _setup_predictor_factory(self):,"def _setup_predictor_factory(self, predict_tower):",KEEP REP DEL,Remove Parameter
"consistently named pretty print methods, resolves #804","def pprint(self, sentence=None, highlight=(), **viz_args):","def pretty_print(self, sentence=None, highlight=(), **viz_args):",KEEP REP KEEP KEEP KEEP,Rename Method
Don't drop widget state when script stops for rerun (#4882),"def _on_script_finished( self, ctx: ScriptRunContext, event: ScriptRunnerEvent ) -> None:","def _on_script_finished(self, ctx: ScriptRunContext) -> None:",KEEP ADD REP KEEP ADD ADD ADD REP KEEP KEEP,Add Parameter
[MaskRCNN] add GN,"@layer_register(log_shape=True) def fastrcnn_Xconv1fc_head(feature, num_classes, num_convs, norm=None): """""" Args: feature (any shape): num_classes(int): num_category + 1 num_convs (int): number of conv layers norm (str or None): either None or 'GN'  Returns: cls_logits (Nxnum_class), reg_logits (Nx num_class-1 x 4) """""" l = feature with argscope(Conv2D, data_format='channels_first', kernel_initializer=tf.variance_scaling_initializer( scale=2.0, mode='fan_out', distribution='normal')): for k in range(num_convs): l = Conv2D('conv{}'.format(k), l, cfg.FPN.FRCNN_CONV_HEAD_DIM, 3, activation=tf.nn.relu) if norm is not None: l = GroupNorm('gn{}'.format(k), l) l = FullyConnected('fc', l, cfg.FPN.FRCNN_FC_HEAD_DIM, kernel_initializer=tf.variance_scaling_initializer(), activation=tf.nn.relu) return fastrcnn_outputs('outputs', l, num_classes)   def fastrcnn_4conv1fc_head(*args, **kwargs): return fastrcnn_Xconv1fc_head(*args, num_convs=4, **kwargs)   def fastrcnn_4conv1fc_gn_head(*args, **kwargs): return fastrcnn_Xconv1fc_head(*args, num_convs=4, norm='GN', **kwargs)","@layer_register(log_shape=True) def fastrcnn_Xconv1fc_head(feature, num_classes, num_convs): """""" Args: feature (any shape): num_classes(int): num_category + 1 num_convs (int): number of conv layers  Returns: cls_logits (Nxnum_class), reg_logits (Nx num_class-1 x 4) """""" l = feature with argscope(Conv2D, data_format='channels_first', kernel_initializer=tf.variance_scaling_initializer( scale=2.0, mode='fan_out', distribution='normal')): for k in range(num_convs): l = Conv2D('conv{}'.format(k), l, cfg.FPN.FRCNN_CONV_HEAD_DIM, 3, activation=tf.nn.relu) l = FullyConnected('fc', l, cfg.FPN.FRCNN_FC_HEAD_DIM, kernel_initializer=tf.variance_scaling_initializer(), activation=tf.nn.relu) return fastrcnn_outputs('outputs', l, num_classes)   def fastrcnn_4conv1fc_head(*args, **kwargs):  return fastrcnn_Xconv1fc_head(*args, num_convs=4, **kwargs)  ",KEEP KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD KEEP KEEP ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD KEEP ADD ADD ADD ADD KEEP KEEP KEEP ADD KEEP,Add Parameter
Update partial_fc.py,"def main(local_rank): dist.init_process_group(backend='nccl', init_method='env://')","def main(local_rank, world_size, init_method='tcp://127.0.0.1:23499'): dist.init_process_group(backend='nccl', init_method=init_method, rank=local_rank, world_size=world_size)",KEEP REP DEL DEL KEEP REP DEL DEL,Remove Parameter
Make rmgpy/solver/* unit tests PEP-8 compliant,def test_liquid_input_reading(self):,def test_liquidInputReading(self):,KEEP REP,Rename Method
Make rmgpy/rmg/* unit tests PEP-8 compliant,def test_rmg_memory(self):,def testRMGMemory(self):,KEEP REP,Rename Method
added an option to use regexes for find_jar(),"def find_jar(name_pattern, path_to_jar=None, env_vars=(), searchpath=(), url=None, verbose=True, is_regex=False):","def find_jar(name, path_to_jar=None, env_vars=(), searchpath=(), url=None, verbose=True):",KEEP REP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
minor cleanup,"def chrf_precision_recall_fscore_support(reference, hypothesis, beta=3.0,","def chrf_precision_recall_fscore_support(reference, hypothesis, n, beta=3.0,",KEEP KEEP KEEP DEL KEEP,Remove Parameter
"expose polish to wyner, exact","def wyner_common_information(dist, rvs=None, crvs=None, rv_mode=None, nhops=5, polish=1e-6):","def wyner_common_information(dist, rvs=None, crvs=None, rv_mode=None, nhops=5):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
s/name/item/g,def raw(item):,def raw(name):,KEEP REP,Rename Parameter
Resolve comments,"def next_inputs(self, time, outputs, state):","def next_inputs(self, sample_ids, time, logits, state):",KEEP KEEP DEL KEEP REP KEEP,Remove Parameter
Improving performance of extraction. Two main changes to improve the 鈥?(#259),"def detect_faces(frame, detector, verbose, rotation=0): fd = FaceLandmarksExtractor.extract (frame, detector, verbose)","def detect_faces(frame, rotation=0, model=""hog""): fd = FaceLandmarksExtractor.extract (frame, True if model == ""cnn"" else False )",KEEP KEEP ADD REP REP KEEP KEEP KEEP KEEP REP REP DEL DEL DEL DEL DEL DEL,Add Parameter
allow weight assignment to word embedding features,"def __init__(self, model_file, weight=1):","def __init__(self, model_file):",KEEP KEEP ADD REP,Add Parameter
Fix fetch_lost_trials,def make_lost_trial(delay=2):,def make_lost_trial():,KEEP REP,Add Parameter
gif writer: Create new filename if output pre-exists,"def _get_writer(self) -> imageio.plugins.pillowmulti.GIFFormat.Writer: """""" Obtain the GIF writer with the requested GIF encoding options.  Returns ------- :class:`imageio.plugins.pillowmulti.GIFFormat.Writer` The imageio GIF writer """"""",def get_writer(self): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
Changed bessels_correction to bessel and set default value. Removed force_eigenvalues_le_one and mean in tica api function. Renamed CovarEstimator to EmpiricalCovariance and EquilibriumCorrectedCovarEstimator to KoopmanEquilibriumCovariance.,"def cov_XY(self, bessel=True): return self.storage_XY.moments.covar(bessel=bessel)","def cov_XY(self, bessels_correction): return self.storage_XY.moments.covar(bessels_correction=bessels_correction)",KEEP KEEP REP KEEP REP,Rename Parameter
update serialization interface for lean minhash,"def bytesize(self, byteorder='@'): '''Compute the byte size after serialization.  Args: byteorder (str, optional): This is byte order of the serialized data. Use one of the `byte order characters <https://docs.python.org/3/library/struct.html ``@``, ``=``, ``<``, ``>``, and ``!``. Default is ``@`` -- the native order.  Returns: int: Size in number of bytes after serialization. '''",def bytesize(self):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Fixes,"def distribute_cards_to_players(self, deck, player_amount, player_card_list, known_table_cards,","def distribute_cards_to_players(self, deck, player_amount, player_card_list, table_card_list,",KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
"Adding tools.py as main script for using tools, as well as integrating all feature requests from #255 and #278 (#298)","def sort_hist(self): input_dir = self.arguments.input_dir  print (""Sorting by histogram similarity..."")  img_list = [ [x, cv2.calcHist([cv2.imread(x)], [0], None, [256], [0, 256]) ] for x in tqdm( self.find_images(input_dir), desc=""Loading"", file=sys.stdout) ]  img_list_len = len(img_list) for i in tqdm( range(0, img_list_len-1), desc=""Sorting"", file=sys.stdout): min_score = float(""inf"") j_min_score = i+1 for j in range(i+1,len(img_list)): score = cv2.compareHist(img_list[i][1], img_list[j][1], cv2.HISTCMP_BHATTACHARYYA) if score < min_score: min_score = score j_min_score = j img_list[i+1], img_list[j_min_score] = img_list[j_min_score], img_list[i+1]  return img_list  def sort_hist_dissim(self): input_dir = self.arguments.input_dir  print (""Sorting by histogram dissimilarity..."")  img_list = [ [x, cv2.calcHist([cv2.imread(x)], [0], None, [256], [0, 256]), 0] for x in tqdm( self.find_images(input_dir), desc=""Loading"", file=sys.stdout) ]  img_list_len = len(img_list) for i in tqdm ( range(0, img_list_len), desc=""Sorting"", file=sys.stdout): score_total = 0 for j in range( 0, img_list_len): if i == j: continue score_total += cv2.compareHist(img_list[i][1], img_list[j][1], cv2.HISTCMP_BHATTACHARYYA)  img_list[i][2] = score_total   print (""Sorting..."") img_list = sorted(img_list, key=operator.itemgetter(2), reverse=True)  return img_list   def group_blur(self, img_list):  num_bins = self.arguments.num_bins    num_per_bin = len(img_list) // num_bins remainder = len(img_list) % num_bins  print (""Grouping by blur..."") bins = [ [] for _ in range(num_bins) ] image_index = 0 for i in range(num_bins): for j in range(num_per_bin): bins[i].append(img_list[image_index][0]) image_index += 1   for i in range(1, remainder + 1): bins[-1].append(img_list[-i][0])  return bins  def group_face(self, img_list): print (""Grouping by face similarity..."")   reference_groups = dict()     bins = [[]]    min_threshold = self.arguments.min_threshold  img_list_len = len(img_list)  for i in tqdm(range(1, img_list_len), desc=""Grouping"", file=sys.stdout): f1encs = img_list[i][1]    if f1encs is None or len(f1encs) <= 0: bins[0].append(img_list[i][0])  else: current_best = [-1, float(""inf"")]  for key, references in reference_groups.items():     try: score = self.get_avg_score_faces(f1encs, references) except TypeError: score = float(""inf"") except ZeroDivisionError: score = float(""inf"") if score < current_best[1]: current_best[0], current_best[1] = key, score  if current_best[1] < min_threshold: reference_groups[current_best[0]].append(f1encs[0]) bins[current_best[0]].append(img_list[i][0]) else: reference_groups[len(reference_groups)] = img_list[i][1] bins.append([img_list[i][0]])  return bins  def group_face_cnn(self, img_list): print (""Grouping by face-cnn similarity..."")   reference_groups = dict()    bins = []      min_threshold = self.arguments.min_threshold * 1000  img_list_len = len(img_list)  for i in tqdm ( range(0, img_list_len - 1), desc=""Grouping"", file=sys.stdout): fl1 = img_list[i][1]  current_best = [-1, float(""inf"")]  for key, references in reference_groups.items(): try: score = self.get_avg_score_faces_cnn(fl1, references) except TypeError: score = float(""inf"") except ZeroDivisionError: score = float(""inf"") if score < current_best[1]: current_best[0], current_best[1] = key, score  if current_best[1] < min_threshold: reference_groups[current_best[0]].append(fl1[0]) bins[current_best[0]].append(img_list[i][0]) else: reference_groups[len(reference_groups)] = [img_list[i][1]] bins.append([img_list[i][0]])  return bins  def group_hist(self, img_list): print (""Grouping by histogram..."")   reference_groups = dict()    bins = []  min_threshold = self.arguments.min_threshold  img_list_len = len(img_list) reference_groups[0] = [img_list[0][1]] bins.append([img_list[0][0]])  for i in tqdm(range(1, img_list_len), desc=""Grouping"", file=sys.stdout): current_best = [-1, float(""inf"")] for key, value in reference_groups.items(): score = self.get_avg_score_hist(img_list[i][1], value) if score < current_best[1]: current_best[0], current_best[1] = key, score  if current_best[1] < min_threshold: reference_groups[current_best[0]].append(img_list[i][1]) bins[current_best[0]].append(img_list[i][0]) else: reference_groups[len(reference_groups)] = [img_list[i][1]] bins.append([img_list[i][0]])  return bins   def final_process_rename(self, img_list): output_dir = self.arguments.output_dir  process_file = self.set_process_file_method(self.arguments.log_changes, self.arguments.keep_original)   if not os.path.exists (output_dir): os.makedirs (output_dir)  description = (""Copying and Renaming"" if self.arguments.keep_original else ""Moving and Renaming"")  for i in tqdm(range(0, len(img_list)), desc=description, leave=False, file=sys.stdout):",def process_hist(self):,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
add custom segment word.,"def __init__(self, language_model_path='', word_freq_path='', custom_confusion_path='', custom_word_path=''):","def __init__(self, language_model_path='', word_freq_path='', custom_confusion_path=''):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Visualization for eigenvalue estimation algorithm,"def init_args(self, qpe, state_in, num_q, shots, matrix, invec):","def init_args(self, qpe, state_in, num_q, shots, matrix):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
File-based fast training for Any2Vec models (#2127),"def _log_epoch_progress(self, progress_queue=None, job_queue=None, cur_epoch=0, total_examples=None, total_words=None, report_delay=1.0, is_corpus_file_mode=None):","def _log_epoch_progress(self, progress_queue, job_queue, cur_epoch=0, total_examples=None, total_words=None, report_delay=1.0):",KEEP KEEP REP REP KEEP KEEP KEEP ADD REP,Add Parameter
"fix index2entity, fix docs, hard-fail deprecated properties","def add_new_vector(self, key, vector):","def add_one(self, key, vector):",KEEP REP KEEP KEEP,Rename Method
Force CONFIGURATION static prop for pluggable classes,def __init__(self): super().__init__(self.CONFIGURATION.copy()),"def __init__(self, configuration=None): super().__init__(configuration or self.AllPairs_CONFIGURATION.copy())",KEEP REP REP DEL DEL DEL,Remove Parameter
Reorganize methods related parsing and generating InChI layers,"def _get_unpaired_electrons(mol): """""" Returns a sorted list of the indices of the atoms that bear one or more unpaired electrons.","def get_unpaired_electrons(mol): """""" Returns a sorted list of the indices of the atoms that bear one or more unpaired electrons.",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
"linting, logging and fixups","def __init__(self, method, shapes, args=tuple(), kwargs={}, ctype=c_float, workers=1, buffers=None): logger.debug(""Initializing %s: (method: '%s', shapes: %s, args: %s, kwargs: %s, "" ""ctype: %s, workers: %s, buffers: %s)"", self.__class__.__name__, method, shapes, args, kwargs, ctype, workers, buffers)","def __init__(self, target_function, shapes, args=tuple(), kwargs={}, ctype=c_float, workers=1, buffers=None, log_queue=None, log_level=logging.DEBUG):",KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP,Remove Parameter
Positioned and keyword arguments coded to the computational graph,"def get_reference(self, name):","def get_pointer(self, name):",KEEP REP KEEP,Rename Method
"Renamed `next` method for chart edges to `nextsym` -- edges are not iterators, so `next` is an unfortunate name",def nextsym(self):,def next(self):,KEEP REP,Rename Method
Remove exp_config dependency from database tests,"def test_count_query_with_id(self, orion_db, test_collection):","def test_count_query_with_id(self, exp_config, orion_db):",KEEP KEEP REP REP,Rename Parameter
"Averaged Perceptron Tagger, by @honnibal, ported by @longdt219, resolves #1143, #1122",def _get_pretrain_model():,"def _demo(): tagger = PerceptronTagger(load=False) tagger.train([[('today','NN'),('is','VBZ'),('good','JJ'),('day','NN')], [('yes','JV'),('it','NN'),('beautiful','ADJ')]], 'average_perceptron_tagger.pickle') print (tagger.tag(['today','is','a','beautiful','day'])) ",KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
JtPlotVis: Only warn of matplotlib maj ver 1 if that is so (fix #243) (#246),def test_jointplot_has_no_errors(self):,def test_jointplot(self):,KEEP REP,Rename Method
Futurize & a few post-fixes to make it run on Py3,def __bool__(self):,def __nonzero__(self):,KEEP REP,Rename Method
remove some get_storage imports,"def __init__(self, storage=None, debug=False, singleton=None) -> None: if storage is not None: self.storage = setup_storage(storage, debug=debug)","def __init__(self, storage_config=None, debug=False, singleton=None) -> None: if storage_config is not None: self.storage = setup_storage(storage_config, debug=debug)",KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP REP KEEP,Rename Parameter
Separate model update method,"def load_model(self, model, name, exclude_layers=(), warnings=True):","def load_model(self, model, name, exclude_layers=()):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
add more tests for SKAR-related PIDs,"def secrecy_capacity(dist, rvs=None, crvs=None, rv_mode=None, nhops=None, bound_u=None):","def secrecy_capacity(dist, rvs=None, crvs=None, rv_mode=None, bound_u=None):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
[GSoC 2018] Multistream API for vocabulary building in *2vec (#2078),"def build_vocab(self, sentences=None, input_streams=None, update=False, progress_per=10000, keep_raw_vocab=False, trim_rule=None, workers=None, **kwargs):","def build_vocab(self, sentences, update=False, progress_per=10000, keep_raw_vocab=False, trim_rule=None, **kwargs):",KEEP KEEP ADD REP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
File-based fast training for Any2Vec models (#2127),"def build_vocab(self, sentences=None, corpus_file=None, update=False, progress_per=10000,","def build_vocab(self, sentences=None, input_streams=None, workers=None, update=False, progress_per=10000,",KEEP KEEP KEEP REP DEL KEEP KEEP,Remove Parameter
Added partial support for mapping of tagsets.,"def tagged_sents(self, fileids=None, categories=None, tagset=None):","def tagged_sents(self, fileids=None, categories=None, simplify_tags=False):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Allow mask color/opacity configuration,def _handle_config(self) -> None:,def handle_config(self):,KEEP ADD ADD REP,Rename Method
Allow `check_for_errors` arg to be accessed from Arkane input file,"def create_log(log_path, check_for_errors=True):",def create_log(log_path):,KEEP ADD REP,Add Parameter
Avoid OrionState in hacked_exp fixture to fix storage fixture issue,"def test_no_lies_if_all_trials_completed(producer, storage, random_dt):","def test_no_lies_if_all_trials_completed(producer, random_dt):",KEEP KEEP ADD KEEP,Add Parameter
Added AffineAdapter class with necessary changes and pytests,"def __init__(self, Fm, Gm=None, adapter=None, implementation_fwd=1, implementation_bwd=1):","def __init__(self, Fm, Gm=None, implementation_fwd=1, implementation_bwd=1):",KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
Improve API for resnext,"def resnext101_32x4d(num_classes=1000, pretrained='imagenet'):",def resnext101_32x4d(pretrained=True):,KEEP ADD REP,Add Parameter
Features Audit (part 1) (#945),"def __init__( self, ax=None, fig=None, features=None, classes=None, colors=None, colormap=None, target_type=""auto"", **kwargs ): super(DataVisualizer, self).__init__(ax=ax, fig=fig, features=features, **kwargs)","def __init__(self, ax=None, features=None, classes=None, colors=None, colormap=None, target_type=""auto"", **kwargs): super(DataVisualizer, self).__init__(ax=ax, features=features, **kwargs)",KEEP ADD REP KEEP ADD KEEP KEEP KEEP KEEP KEEP ADD REP KEEP KEEP ADD KEEP KEEP,Add Parameter
finished blueprint migration. need to test,"return render_template('train.html', storyId=storyId,","def train(): _id = request.args.get(""storyId"") story = Story.objects.get(id=ObjectId(_id))",REP REP REP DEL DEL DEL DEL DEL,Rename Method
Rename `io.parsing` module to `resolve_config`,"def infer_config_and_db(user, starttime): ","def infer_config(user, starttime): ",KEEP REP KEEP,Rename Method
"Simplify tests suite, remove spy_phase and related functions (#886)",def test_suggest_n(self):,"def test_suggest_n(self, mocker, num, attr):",KEEP REP DEL DEL DEL,Remove Parameter
[MaskRCNN] GN on FPN; FreezeC2,"def resnet_fpn_backbone(image, num_blocks):","def resnet_fpn_backbone(image, num_blocks, freeze_c2=True):",KEEP KEEP REP DEL,Remove Parameter
Features Audit (part 1) (#945),"def __init__(self, ax=None, fig=None, **kwargs): super(FeatureVisualizer, self).__init__(ax=ax, fig=fig, **kwargs)","def __init__(self, ax=None, **kwargs): super(FeatureVisualizer, self).__init__(ax=ax, **kwargs)",KEEP KEEP KEEP ADD KEEP KEEP KEEP ADD KEEP,Add Parameter
add prior arg to add_y() that overrides family's default; closes #16,"def add_y(self, variable, family='gaussian', link=None, prior=None, *args,","def add_y(self, variable, family='gaussian', link=None, *args,",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Added ability to change input channel size,"def fcn_32_mobilenet(n_classes,  input_height=416, input_width=608, channels=3):","def fcn_32_mobilenet(n_classes,  input_height=416, input_width=608):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
add output_topk option,"def get_video_results(outputs, class_names, output_topk): sorted_scores, locs = torch.topk(outputs, k=min(output_topk, len(class_names)))","def get_video_results(outputs, class_names): sorted_scores, locs = torch.topk(outputs, k=min(5, len(class_names)))",KEEP KEEP ADD REP KEEP KEEP KEEP KEEP REP KEEP,Add Parameter
Initial refactoring of DependencyGraph.,"def __init__(self, tree_str=None, cell_extractor=None): """""" Dependency graph.  We place a dummy 'top' node in the first position in the nodelist, since the root node is often assigned '0' as its head. This also means that the indexing of the nodelist corresponds directly to the Malt-TAB format, which starts at 1. ","def __init__(self, tree_str=None): """""" We place a dummy 'top' node in the first position in the nodelist, since the root node is often assigned '0' as its head. This also means that the indexing of the nodelist corresponds directly to the Malt-TAB format, which starts at 1.",KEEP KEEP ADD REP KEEP ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
Add static type hints checking (#1020),"def _get_best_merit_solution(self) -> Tuple[np.ndarray, np.ndarray, float]:","def _get_best_merit_solution(self) -> (np.ndarray, np.ndarray, float):",KEEP KEEP KEEP REP KEEP REP,Change Return Type
Share stop event between ThreadedMapData workers,"def __init__(self, inq, outq, evt, map_func, strict): super(ThreadedMapData._WorkerThread, self).__init__(evt)","def __init__(self, inq, outq, map_func, strict): super(ThreadedMapData._WorkerThread, self).__init__()",KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP REP,Add Parameter
BSL methods implementation (#392),"def plot_marginals(samples, selector=None, bins=20, axes=None, reference_value=None, **kwargs):","def plot_marginals(samples, selector=None, bins=20, axes=None, **kwargs):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Fix the usage of the RC input,"def run(self, throttle, mode = None):","def run(self, throttle):",KEEP KEEP ADD ADD ADD REP,Add Parameter
add 'incremental' mode (auto increasing `num_iterations` until oracle satisfied) to grover,def _construct_circuit_components(self):,def _construct_circuit(self):,KEEP REP,Rename Method
Don't allow config.get_option to be called on file import (#3235),def get_file_watcher_class(watcher_type: str) -> FileWatcherType:,def get_file_watcher_class(watcher_type: str) -> Optional[FileWatcherType]:,KEEP KEEP KEEP KEEP REP,Change Return Type
Remove deprecated components (#1182),def test_ecev(self):,"@data(False, True) def test_ecev(self, use_circuits):",DEL DEL KEEP REP DEL,Remove Parameter
Skip exp update in ExpView (#218),"def configure(self, config, enable_branching=True, enable_update=True):","def configure(self, config, enable_branching=True):",KEEP KEEP KEEP ADD REP,Add Parameter
added augmentation,"def train(cfg, tub_names, model_name, transfer_model, model_type, continuous, aug):","def train(cfg, tub_names, model_name, transfer_model, model_type, continuous):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Consistency tests (#197),"def __init__(self, x_min, **kwargs):","def __init__(self, x, **kwargs):",KEEP KEEP REP KEEP,Rename Parameter
fix csv reader tests,"def __init__(self, it, lag, return_trajindex, actual_stride):","def __init__(self, it, lag, return_trajindex):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
add print_warning: always print,"def _print_err(*args, **kwargs):","def print_err(*args, **kwargs):",KEEP REP KEEP,Rename Method
typing: lib.gui.analysis.stats,"def _total_stats(self) -> Dict[str, Union[str, int, float]]:",def _total_stats(self) -> dict:,KEEP KEEP KEEP ADD ADD ADD REP,Change Return Type
pcca catches nonreversible transition matrices. Tests augmented,"def _fill_matrix(rot_crop_matrix, eigvectors):","def fill_matrix(rot_crop_matrix, eigvectors):",KEEP REP KEEP,Rename Method
added output layers for RNN encoders,"def _build(self, inputs, sequence_length=None, initial_state=None, time_major=False, mode=None,","def _build(self, inputs, sequence_length=None, initial_state=None,",KEEP KEEP KEEP KEEP KEEP ADD ADD,Add Parameter
Add support for Vega Lite charts.,"def _native_chart(self, chart):","@_export_to_io def chart(self, chart):",DEL KEEP REP KEEP,Rename Method
Reorganize methods related parsing and generating InChI layers,"def _create_P_layer(mol, auxinfo):","def create_P_layer(mol, auxinfo): """"""  Creates a string with the positions of the atoms that bear an unexpected number of lone pairs. The string can be used to complement the InChI with an additional layer that allows for the differentiation between structures with lone pairs.  The string is composed of a prefix ('P_LAYER_PREFIX') followed by the positions of each of the atoms with an unexpected number of lone pairs, sorted in numerical order.  Example: - singlet methylene biradical ([CH2]) : 'P_LAYER_PREFIX'1  When the molecule does not bear any atoms with an unexpected number of lone pairs, None is returned.   """"""   minmol = mol   p_layer = [] for i, at in enumerate(mol.atoms): try: exp = elements.PeriodicSystem.lone_pairs[at.symbol] except KeyError: raise Exception(""Unrecognized element: {}"".format(at.symbol)) else: if at.lonePairs != elements.PeriodicSystem.lone_pairs[at.symbol]: if at.lonePairs == 0: p_layer.append('{}{}'.format(i, '(0)')) else: p_layer.extend([i + 1] * at.lonePairs)   equivalent_atoms = parse_E_layer(auxinfo) if equivalent_atoms:  u_layer = find_lowest_p_layer(minmol, p_layer, equivalent_atoms)  if p_layer: return (P_LAYER_PREFIX + P_LAYER_SEPARATOR.join(map(str, p_layer))) else: return None   def find_lowest_p_layer(minmol, p_layer, equivalent_atoms): """""" Permute the equivalent atoms and return the combination with the lowest p-layer.  TODO: The presence of unpaired electrons complicates stuff. """""" return minmol ",KEEP REP KEEP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
"rename [lbl,label,LabeledSentence] -> [tag,tag,TaggedDocument]","def train_sentence_dbow(model, word_vocabs, doctag_indices, alpha, work=None, train_words=False, learn_doctags=True, learn_words=True, learn_hidden=True, word_vectors=None, word_locks=None, doctag_vectors=None, doctag_locks=None):","def train_sentence_dbow(model, word_vocabs, doclbl_indices, alpha, work=None, train_words=False, learn_doclbls=True, learn_words=True, learn_hidden=True, word_vectors=None, word_locks=None, doclbl_vectors=None, doclbl_locks=None):",KEEP KEEP KEEP REP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP REP REP,Rename Parameter
"broken, but progress...","def __init__(self, path): self.has_model_data = False","def __init__(self, path, theme='sandstone'):",KEEP KEEP ADD ADD REP REP,Remove Parameter
"[MaskRCNN] use ""spawn"" for safer multiprocessing","@staticmethod def worker(evt, rst_queue, stop_evt, devices): """""" Args: devices (list[int]) """"""","def worker(self, evt, rst_queue, stop_evt):",ADD KEEP ADD ADD ADD ADD ADD REP REP REP REP,Rename Parameter
"added data, some bug fixes",def base_features(self):,def _base_features(self):,KEEP REP,Rename Method
Switch all testing to pytest.,"@pytest.mark.parametrize('i', range(10)) def test_rand(i):",def test_rand():,ADD ADD KEEP REP,Add Parameter
Change relation comparison to be 鈥渆quivalent鈥?(not 鈥渆quals) 鈥?ODER MATTERS,"def __init__(self, rel_type, entity_map_fun=None, relation_equiv_fun=None):","def __init__(self, rel_type, entity_map_fun=None, relation_equals_fun=None):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Add option to sort trials by time,"def regret(experiment, order_by='suggested', **kwargs):","def regret(experiment, **kwargs):",KEEP KEEP ADD KEEP,Add Parameter
Switch all testing to pytest.,"@pytest.mark.parametrize('i', range(2, 10)) def test_p2(i):",def test_p2():,ADD ADD ADD KEEP REP,Add Parameter
rename outcome register -> output register,"def logic_or(clause_expr, circuit, variable_register, target_qubit, ancillary_register, mct_mode):","def _or(clause_expr, circuit, variable_register, target_qubit, ancillary_register, mct_mode):",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Method
Core Updates (#1015),"def _get_handles(self): """""" Obtain the internal handle identifiers for the system GPUs and allocate to :attr:`_handles`. """""" if self._is_plaidml: self._handles = self._plaid.devices",def get_handles(self):  if self.plaid is not None: self.handles = self.plaid.devices,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP REP REP KEEP REP,Rename Method
Let user set colors for freq dist and other ax.bar visualizers (PR #917),"def class_balance( y_train, y_test=None, ax=None, labels=None, color=None, colormap=None, **kwargs ):","def class_balance(y_train, y_test=None, ax=None, labels=None, **kwargs):",KEEP ADD REP KEEP KEEP KEEP ADD ADD ADD REP,Add Parameter
feat: enable phone number regex to recognize phone numbers (#2798),"def tokenize(self, text: str) -> List[str]: """"""Tokenize the input text.","def tokenize(self, text): """"""",KEEP KEEP ADD ADD ADD ADD ADD ADD REP REP,Change Return Type
Native circuits (#905),"@data(False, True) def test_vqc_minibatching_with_gradient_support(self, use_circuits):",def test_vqc_minibatching_with_gradient_support(self):,ADD ADD KEEP ADD REP,Add Parameter
Force CONFIGURATION static prop for pluggable classes,def __init__(self): super().__init__(self.CONFIGURATION.copy()),"def __init__(self, configuration=None): super().__init__(configuration or self.RY_CONFIGURATION.copy())",KEEP REP REP DEL DEL DEL,Remove Parameter
First version of experiment framework,"def save_checkpoint_static(checkpoint_dir, name, move_to_cpu=False, **kwargs):","def save_checkpoint_static(checkpoint_dir, name, **kwargs):",KEEP KEEP KEEP ADD KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_persistence_word2vec_format_with_vocab(self):,def testPersistenceWord2VecFormatWithVocab(self):,KEEP REP,Rename Method
fix two tests that weren't being applied,def test_not_supported_fit_with_breaks_force_points(self):,def not_supported_fit_with_breaks_force_points(self):,KEEP REP,Rename Method
Add new `status` command (#222),"def test_exp_name_with_child(clean_db, three_experiments, monkeypatch, capsys):","def test_exp_name_with_child(three_experiments, monkeypatch, capsys):",KEEP ADD REP KEEP KEEP,Add Parameter
Draft implementation of `sample_weight` for kmodes.,"def labels_cost(X, centroids, dissim, membship=None, sample_weight=None):","def labels_cost(X, centroids, dissim, membship=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Initial attempt at keras-style training,"def __init__(self, input, infs):","def __init__(self, input, infs, extra_hooks=None):",KEEP KEEP KEEP REP DEL,Remove Parameter
Implemented preliminary version of CSE lumping algorithm.,"def applyChemicallySignificantEigenvaluesMethod(self, lumpingOrder=None):",def applyChemicallySignificantEigenvaluesMethod(self):,KEEP ADD REP,Add Parameter
Force CONFIGURATION static prop for pluggable classes,def __init__(self): super().__init__(self.CONFIGURATION.copy()),"def __init__(self, configuration=None): super().__init__(configuration or self.COBYLA_CONFIGURATION.copy())",KEEP REP REP DEL DEL DEL,Remove Parameter
Make rmgpy/tools/* unit tests PEP-8 compliant,def test_generate_isotopomers(self):,def testGenerateIsotopomers(self):,KEEP REP,Rename Method
clean code,def demo(): ,def main():,KEEP REP,Rename Method
45: significant speedup kprototypes,"def move_point_num(point, to_clust, from_clust, cl_attr_sum, cl_memb_sum):","def move_point_num(point, ipoint, to_clust, from_clust, cl_attr_sum, membship):",KEEP KEEP DEL KEEP KEEP KEEP REP,Remove Parameter
[coordinates/data/csv_reader] support random access by dictionary,"def __init__(self, reader, chunksize=1, skiprows=None, header=None, stride=None, itraj=None):","def __init__(self, reader, chunksize=1, skiprows=None, header=None):",KEEP KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
Only use the mean of training set (fix #1072),"def get_per_channel_mean(self, names=('train', 'test')):",def get_per_channel_mean(self):,KEEP ADD ADD REP,Add Parameter
Add an option for verbose hover with hyperparameters,"def regret(experiment, order_by='suggested', verbose_hover=False, **kwargs):","def regret(experiment, order_by='suggested', **kwargs):",KEEP KEEP KEEP ADD KEEP,Add Parameter
Added approximate means for ILT method with Arrhenius kinetics such that n < 0.,"def calculateMicrocanonicalRates(self, Elist, densStates, T=None):","def calculateMicrocanonicalRates(self, Elist, densStates):",KEEP KEEP KEEP ADD REP,Add Parameter
added cat throttle to default model. fix plots,"def unbin_Y(Y, N=15):",def unbin_Y(Y):,KEEP ADD REP,Add Parameter
- Added in some comments and epydoc markup.,"def get(self, key, loadfn=None):","def get(this, key, loadfn=None):",KEEP REP KEEP KEEP,Rename Parameter
Prefix legacy and arrow commands with _ (#3563),def _arrow_dataframe(,def arrow_dataframe(,KEEP REP,Rename Method
"add type hints, fix args order in ae.py","def confidence_interval(self, alpha: float, kind: str = 'likelihood_ratio') -> List[float]: """"""Compute the (1 - alpha) confidence interval.","def confidence_interval(self, alpha, kind='likelihood_ratio'): """""" Compute the (1 - alpha) confidence interval",KEEP KEEP ADD ADD ADD ADD ADD REP REP REP REP KEEP KEEP KEEP KEEP KEEP REP,Change Return Type
"Add Registry, rework how Space is passed to algorithms (#833)",def sample(num: int) -> list[Trial]:,def sample(num):,KEEP ADD ADD ADD REP,Change Return Type
revamp Path stringification,"def __init__(self, token, edge_type, is_forward, is_source=False, is_target=False):","def __init__(self, token, edge_type, is_forward):",KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
[DQN] Let state have channels.,"def __init__(self, image_shape, channel, history, method, num_actions, gamma):","def __init__(self, image_shape, channel, method, num_actions, gamma): self.image_shape = image_shape",KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP DEL DEL DEL,Add Parameter
wip for updating constructors,"def __init__(self, num_qubits, depth=3, entangler_map=None, entanglement='full', initial_state=None): """"""Constructor.","def init_args(self, num_qubits, depth, entangler_map=None, entanglement='full', initial_state=None): """"""",KEEP REP KEEP REP KEEP KEEP KEEP REP,Rename Method
setup.py: implement logging,def _install_python_packages(self) -> None:,def install_python_packages(self):,KEEP ADD ADD REP,Rename Method
Kivy UI and minor fixes to templates and configs. (#823),"def train(cfg: Config, tub_paths: str, model: str = None, model_type: str = None, transfer: str = None, comment: str = None) \ -> tf.keras.callbacks.History:","def train(cfg: Config, tub_paths: str, model: str, model_type: str) -> \ tf.keras.callbacks.History:",KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP KEEP ADD KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_r_n_g(self):,def testRNG(self):,KEEP REP,Rename Method
change profile to load uff or tflite models,"def profile(model_path, model_type): cfg = dk.load_config('config.py') model_path = os.path.expanduser(model_path) model = dk.utils.get_model_by_type(model_type, cfg) model.load(model_path)  count, h, w, ch = 1, cfg.TARGET_H, cfg.TARGET_W, cfg.TARGET_D seq_len = 0",def profile(model_path):   model = keras.models.load_model(model_path),KEEP ADD ADD ADD ADD ADD REP REP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Logging (#541),"def align_face(self, faces, align_eyes, size, filename, padding=48): ","@staticmethod def align_face(faces, align_eyes, size, padding=48): ",REP REP REP KEEP KEEP ADD KEEP,Add Parameter
"Splitting up delta_generator, part 3! (#1805)",def test_enqueue_same_id(self):,def test_enqueue_new_element_delta_same_id(self):,KEEP REP,Rename Method
transformed camelCase to snake_case test names (#3033),def test_load_not_exist(self):,def testLoadNotExist(self):,KEEP REP,Rename Method
28.9 on en-vi dataset,"def _build(self, decoder_input, encoder_output, \ encoder_decoder_attention_bias, mode=None):","def _build(self, decoder_input, encoder_output, encoder_decoder_attention_bias):",KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
Training: Add Multi-Output Support,"def __init__(self, input_size, output_shapes, coverage_ratio, config):","def __init__(self, input_size, output_size, coverage_ratio, config):",KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
fix fix fix,"def __init__(self, entity_map_fun=None, entity_overlap_fun=None, entity_accept_fun=None):","def __init__(self, subclass_analysis=False, entity_map_fun=None, entity_overlap_fun=None, entity_accept_fun=None): self.subclass_analysis = subclass_analysis",KEEP KEEP DEL KEEP KEEP KEEP DEL DEL DEL,Remove Parameter
updates,"def _build_output_layer(self, dim):","def _build_output_layer(self, num_units):",KEEP KEEP REP,Rename Parameter
"Update facenet, update tensorflow requirement to 1.7.0, add support for facenet models with arbitrary number of embeddings, add example for database","def main(args, facebook_token, model_dir):     ","def main(args, facebook_token):    ",KEEP KEEP ADD REP,Add Parameter
pass noise setting when using a simulator,"def setup_quantum_backend(self, backend='local_statevector_simulator', shots=1024, skip_translation=False, timeout=None, wait=5, noise_config=None):","def setup_quantum_backend(self, backend='local_statevector_simulator', shots=1024, skip_translation=False, timeout=None, wait=5):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
changed PairedDataProvider to ParallelDataProvider to allow >2 datasets,"def test_vocab_construction(self): """"""Test vocabulary construction.","def test_vocab_load(self): """"""Test vocabulary load function.",KEEP REP KEEP KEEP REP DEL,Rename Method
Make augmentors return a `Transform` instance. (#1290),"def _get_augment_params(self, _):","def _get_augment_params(self, img):",KEEP KEEP REP,Rename Parameter
Now storing dict of edges on Vertex and vertices on Edge.,def test_updateConnectivityValues(self):,def testUpdateConnectivityValues(self):,KEEP REP,Rename Method
Align _match_potential_end_contexts with NLTK 3.6.5 sent_tokenize results,"def tokenize(self, text: str, realign_boundaries: bool = True) -> List[str]:","def tokenize(self, text, realign_boundaries=True):",KEEP KEEP ADD ADD ADD ADD ADD ADD REP REP,Change Return Type
"Update facenet, update tensorflow requirement to 1.7.0, add support for facenet models with arbitrary number of embeddings, add example for database","def evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder, embeddings, labels, image_paths, actual_issame, batch_size, nrof_folds, log_dir, step, summary_writer, stat, epoch, distance_metric, subtract_mean, use_flipped_images, use_fixed_image_standardization):","def evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder, embeddings, labels, image_paths, actual_issame, batch_size, nrof_folds, log_dir, step, summary_writer):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD REP,Add Parameter
add,"def __init__( self, stop_words=[], prefix_bow_stem=None ):","def __init__(self, stop_words=[]):",KEEP ADD ADD ADD REP REP,Add Parameter
added to demo.postagging,"def _demo_plot(learning_curve_output, teststats, trainstats=None, take=None):","def _demo_plot_learning_curve(learning_curve_output, trainstats, teststats, take=None):",KEEP REP REP REP KEEP,Rename Method
[msm.ui.msm]: Large commit! MSM has now a ton of useful features and functions,"def relaxation(self, p0, a, times, k=None, ncv=None):","def relaxation(self, p0, a, lag, k=None, ncv=None):",KEEP KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
Merge staging to Master (#470),"def __init__(self, image, detected_faces, keras_model, verbose):","def __init__(self, frame, detected_faces, keras_model, verbose):",KEEP KEEP REP KEEP KEEP KEEP,Rename Parameter
changed chunkparser api to use root_label and chunk_label instead of top_node and chunk_node,"def _chunksets(t, count, chunk_label):","def _chunksets(t, count, chunk_node):",KEEP KEEP KEEP REP,Rename Parameter
feature/session-state (#3479),"def selectbox( self, label, options, index=0, format_func=str, key=None, help=None, on_change=None, args=None, kwargs=None, ):","def selectbox(self, label, options, index=0, format_func=str, key=None, help=None):",KEEP ADD REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP,Add Parameter
"Concrete optimization result classes for optimizers, more algorithm specific properties in the result classes. (#1173)","def _minimize(x_0: np.array) -> Tuple[np.array, Any]: x = fmin_cobyla(objective, x_0, constraints, rhobeg=self._rhobeg, rhoend=self._rhoend, maxfun=self._maxfun, disp=self._disp, catol=self._catol) return x, None","def _minimize(x_0: np.array) -> np.array: return fmin_cobyla(objective, x_0, constraints, rhobeg=self._rhobeg, rhoend=self._rhoend, maxfun=self._maxfun, disp=self._disp, catol=self._catol)",KEEP KEEP KEEP KEEP ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD,Change Return Type
Create GK_Value class. Make x.value an instance of GK_Value to have changed attribute. Redo csv writer to only write values that were detected as changed by the user. Other changes: 1) avoid false positive in option mismatch checker with like function 2) remove multiple add/sub operators in model file 3) not print some debug stuff 4) add verify_input arguement to solve function,"def solve(self,remote=True,disp=True,verify_input=False):","def solve(self,remote=True,disp=True):",KEEP REP,Add Parameter
Space: Add _Discrete class and ban interval from Categorical,"def test_simple_instance(self, seed):","def test_as_you_are_as_you_were(self, seed):",KEEP REP KEEP,Rename Method
Adapt Producer to shared state algorithm,"def test_init_and_configuration(self, dumbalgo, palgo, fixed_suggestion_value):","def test_init_and_configuration(self, dumbalgo, palgo, fixed_suggestion):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Improved output and access to logdict,"def __init__(self, file_name, logger, log_to_output=False, log_temp_output=True):","def __init__(self, file_name, logger, log_to_output=False):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
make all loss layers training phase dependent,"def call(self, inputs, training=None, **kwargs):","def call(self, inputs, **kwargs):",KEEP KEEP KEEP ADD KEEP,Add Parameter
Replace the use of random and fixed effects terms (#279),"def _add_common_predictors(self, x_matrix, priors):","def _add_fixed_predictors(self, x_matrix, priors):",KEEP REP KEEP KEEP,Rename Method
compute SE,"def format_header(self, strictnesses=None):","def format_header(self, strictnesses=None, add_SE='macro'):",KEEP KEEP REP DEL,Remove Parameter
update HHL components to use Pluggables,def __init__(self): super().__init__(),"def __init__(self, configuration=None): super().__init__(configuration or copy.deepcopy(self.LINEARSYSTEMINPUT_CONFIGURATION))",KEEP REP REP DEL DEL DEL,Remove Parameter
Rename fetch_trial_by_status,"def test_fetch_trials_by_status(self, storage):","def test_fetch_trial_by_status(self, storage):",KEEP REP KEEP,Rename Method
Switch convention to X/O instead of X/x,"def update_groups(board, existing_X_groups, existing_O_groups, c):","def update_groups(board, existing_X_groups, existing_x_groups, c):",KEEP KEEP KEEP REP KEEP,Rename Parameter
make dataflow idiomatic python container objects (fix #869) (#872),def __iter__(self):,def get_data(self):,KEEP REP,Rename Method
"Add install checks for cvxopt, torch, pyscf","def optimize_svm(kernel_matrix: np.ndarray, y: np.ndarray, scaling: Optional[float] = None, max_iters: int = 500, show_progress: bool = False) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:","def optimize_svm(kernel_matrix, y, scaling=None, max_iters=500, show_progress=False):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP,Change Return Type
env_app fix in pytorch visdom logger,"def plot_model_statistics_weights(self, model, env_appendix=None, model_name=""""):","def plot_model_statistics_weights(self, model, env_app=None, model_name=""""):",KEEP KEEP KEEP REP KEEP,Rename Parameter
Stats optimization (#1067),"def _tree_configure(self, helptext): """""" Build a tree-view widget to hold the sessions stats.  Parameters ---------- helptext: str The helptext to display when the mouse is over the tree-view  Returns ------- list The list of tree-view columns """"""","def tree_configure(self, helptext): ",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
Enable Aer's parameter binding (#1206),def test_with_aer_qasm_snapshot_mode(self):,def test_qasm_snapshot_mode(self):,KEEP REP,Rename Method
lmdb and discretizer,"def get_nd_bin_ids(self, bin_id):","def _get_bin_id_nd(self, bin_id):",KEEP REP KEEP,Rename Method
"align parser methods with updated API, incorporate read_cfg into ContextFreeGrammar.read, and same for read_pcfg and read_fcfg",def _read_dependency_production(s):,def read_dependency_production(s):,KEEP REP,Rename Method
Resolve some EVC failures,"def test_bad_name_experiment(self, parent_config, child_config, monkeypatch, storage):","def test_bad_name_experiment(self, parent_config, child_config, monkeypatch):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
dlib-cnn rotation scale bugfix,"def process_rotations(self, detect_images, processed, scales):","def process_rotations(self, detect_images, processed):",KEEP KEEP KEEP ADD REP,Add Parameter
Add base=None to a few of the random distribution generators.,"def uniform_distribution(outcome_length, alphabet_size, base=None):","def uniform_distribution(outcome_length, alphabet_size):",KEEP KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_sentence_generation(self):,def testSentenceGeneration(self):,KEEP REP,Rename Method
"Returns list of string for tokenize() function, added a detokenizer","def penn_tokenize(self, text, return_str=False):","def penn_tokenize(self, text):",KEEP KEEP ADD REP,Add Parameter
Further edits to data providers,def get_covariance_matrix(self):,def get_covariance(self):,KEEP REP,Rename Method
add unit tests,def test_TransferFunctionMatrix_series(): tfm1 = TransferFunctionMatrix(,def test_TransferFunction_series(): tfm1 = TransferFunction(,KEEP REP KEEP KEEP REP,Rename Method
Add `props` attribute to Group,"def __init__(self, atoms=None, props=None, multiplicity=None):","def __init__(self, atoms=None, multiplicity=None):",KEEP KEEP KEEP ADD KEEP,Add Parameter
"Simplify tests suite, remove spy_phase and related functions (#886)",def test_n_suggested(self):,"@phase def test_n_suggested(self, mocker, num, attr):",DEL KEEP REP DEL DEL DEL,Remove Parameter
Added partial support for mapping of tagsets.,"def tagged_paras(self, fileids=None, categories=None, tagset=None):","def tagged_paras(self, fileids=None, categories=None, simplify_tags=False):",KEEP KEEP KEEP KEEP REP,Rename Parameter
"Simplify tests suite, remove spy_phase and related functions (#886)",def test_observe(self):,"@phase def test_observe(self, mocker, num, attr):",DEL KEEP REP DEL DEL DEL,Remove Parameter
transformed camelCase to snake_case test names (#3033),def test_training_from_file(self):,def testTrainingFromFile(self):,KEEP REP,Rename Method
Implement the changes requested by bouthilx in #68,def test_init_with_default_value_string(self):,"@pytest.mark.xfail(reason=""type implementation detail"") def test_init_with_default_value(self):",DEL DEL DEL KEEP REP,Rename Method
Length normalized decoding fixed,"def __init__(self, stop_token_id, dec_inputs=[], dec_states=[], logprob=0.0, length=-1): self.stop_token_id = stop_token_id","def __init__(self, dec_inputs=[], dec_states=[], logprob=0.0):",KEEP KEEP ADD KEEP KEEP ADD ADD ADD ADD REP,Add Parameter
introduced unsupervised equal widthdiscretiser,def test_equality(self):,def testEquality(self):,KEEP REP,Rename Method
Base optimizer (#136),"def _partition(self, maxiter=None):","def _partition(self, maxiters=1000):",KEEP KEEP REP,Rename Parameter
IBMQ v2 support,"def set_credentials(self, token, proxy_urls=None): if token is not None:","def set_credentials(self, token, url=IBMQ_URL, proxy_urls=None): if url is not None and token is not None:",KEEP KEEP KEEP DEL KEEP KEEP DEL DEL DEL DEL DEL KEEP KEEP KEEP KEEP,Remove Parameter
New example: bacteria in daycare centers (#250),"def get_model(n_obs=50, true_params=None, seed_obs=None, **kwargs):","def get_model(n_obs=50, true_params=None, seed_obs=None, stochastic=True):",KEEP KEEP KEEP KEEP REP,Remove Parameter
Make manage/push/pop_hopping_op methods in UCCSD public.,"def push_hopping_operator(self, excitation):","def _push_hopping_operator(self, excitation):",KEEP REP KEEP,Rename Method
fix remaining type hints errors (#1025),"def reorder_paulis(self) -> List[List[Union[complex, Pauli]]]:",def reorder_paulis(self):,KEEP ADD ADD ADD REP,Change Return Type
Algo redefinition should not drop algo config,def test_ignore_cli(init_full_x_ignore_cli):,def test_new_algo_ignore_cli(init_full_x_ignore_cli):,KEEP REP,Rename Method
Add: add a windows_tol for the visual unittest suite (#864),"def assert_images_similar(self, visualizer=None, ax=None, tol=0.01, windows_tol=None,  **kwargs):","def assert_images_similar(self, visualizer=None, ax=None, tol=0.01, **kwargs):",KEEP KEEP KEEP KEEP KEEP ADD ADD KEEP,Add Parameter
Simplified and generalized ui for adding meta data: --meta='key:value'.,"def __init__(self, path, inputs=None, types=None, user_meta=[]):","def __init__(self, path, inputs=None, types=None, location=None, task=None):",KEEP KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
Improve resiliency of trial reservation,"def __init__(self, experiment):","def __init__(self, experiment, max_idle_time=None):",KEEP KEEP REP DEL,Remove Parameter
Add hover to partial deps scatter,"def _plot_scatter(x, y, df):","def _plot_scatter(x, y):",KEEP KEEP ADD REP,Add Parameter
Fix according to comments on PR,"def test_create_permanent_dir(tmp_path, path):",def test_create_permanent_dir(tmp_path):,KEEP ADD REP,Add Parameter
"Global caching works with Aqua 0.4, but for some reason execution is slower. Will convert caching to instance variable of QuantumInstance next.",def _run_with_num_iterations(self): qc = self.construct_circuit(),"def _run_with_num_iterations(self, qc_prefix, qc_amplitude_amplification, qc_measurement): qc = qc_prefix + qc_amplitude_amplification + qc_measurement",KEEP REP DEL DEL DEL KEEP KEEP REP DEL DEL DEL DEL,Remove Parameter
fix negation handling and bigram extraction problems,"def extract_unigram_feats(document, unigrams, handle_negation=False):","def extract_unigram_feats(document, unigrams):",KEEP KEEP ADD REP,Add Parameter
examples with userids,def sampletoscreen_demo(limit=20):,def streamtoscreen_demo(limit=20):,KEEP REP,Rename Method
Get rid of build_view,"def _instantiate_algo(space, config=None, ignore_unavailable=False):","def _instantiate_algo(space, config):",KEEP KEEP ADD REP,Add Parameter
Fix some flake8 and pylint issues,"def load_modules_in_path(path, filter_function=None):","def load_modules_in_path(path, filter_function=None, from_list=['']):",KEEP KEEP REP DEL,Remove Parameter
[featurizer|md-iterload] cache mdtraj.Topology objects if they have the same input file.,"def __init__(self, topfile, use_cache=True):","def __init__(self, topfile):",KEEP KEEP ADD REP,Add Parameter
Allow MPA pages with duplicate names (#4769),"def reset(self, query_string: str = """", page_script_hash: str = """") -> None:","def reset(self, query_string: str = """", page_name: str = """") -> None:",KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Parameter
tsf att mask,"def __call__(self, query, keys, values, values_length, mask=None, scope=None):","def __call__(self, query, keys, values, values_length, scope=None):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Add type annotations to DeltaGenerator mixins (#2475),"def video(self, data, format=""video/mp4"", start_time=0):","def video(dg, data, format=""video/mp4"", start_time=0):",KEEP REP KEEP KEEP KEEP,Rename Parameter
Infer trial working dir based on exp.working_dir,"def test_invalid_result(self, trial_config):","def test_invalid_result(self, exp_config):",KEEP KEEP REP,Rename Parameter
Adding new statistics 鈥?tree sizes and scores,"def _extract_feats(self, tree, da):","def _extract_feats(self, ttree, da):",KEEP KEEP REP KEEP,Rename Parameter
[clustering] fix dtraj saving,"def save_dtrajs(self, trajfiles=None, prefix='', output_dir='.', output_format='ascii',","def save_dtrajs(self, trajfiles=None, prefix='', output_format='ascii',",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
increase speed,"def get_players_funds(self, my_funds_only=False, skip=[]):","def get_players_funds(self, my_funds_only=False):",KEEP KEEP ADD REP,Add Parameter
#24: add option for custom dissimilarity function; some refactoring,"def _labels_cost(X, centroids, dissim):","def _labels_cost(X, centroids):",KEEP KEEP ADD REP,Add Parameter
EMA callback don't create variables itself. add old SaverRestore to be fast,"def download(url, dir, filename=None):","def download(url, dir):",KEEP KEEP ADD REP,Add Parameter
Implement in-memory caching.,def read_from_disk_cache(path):,def read_from_cache(path):,KEEP REP,Rename Method
Update extracted faces to use PNG EXIF data (#1123),def _get_missing_alignments(self):,def get_missing_alignments(self):,KEEP REP,Rename Method
Fixed revop memory consumption during experiments. #37,"def __init__(self, fn, keep_input=False, keep_input_inverse=False, num_bwd_passes=1, disable=False):","def __init__(self, fn, keep_input=False, keep_input_inverse=False, disable=False):",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
[FasterRCNN] move GAP to fastrcnn_head,"def resnet_conv5(image, num_block): with argscope([Conv2D, BatchNorm], data_format='NCHW'), \","def resnet_conv5_gap(image, num_block): with argscope([Conv2D, GlobalAvgPooling, BatchNorm], data_format='NCHW'), \",KEEP REP KEEP KEEP KEEP DEL KEEP KEEP KEEP,Rename Method
Add option to flatten ints in Config,"def flat(self, keep_lists=True, max_split_size=10, flatten_int=False):","def flat(self, keep_lists=True, max_split_size=10):",KEEP KEEP KEEP ADD REP,Add Parameter
add fast option to TF port,"def __init__(self, x, y, disp_res=False, dtype='float64', fast=True):","def __init__(self, x, y, disp_res=False, dtype='float64'):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Don't require distributions to have rv_names for,"def prob(outcome, dists=dists, parents=parents, rv=rv):","def prob(outcome, dists=dists):",KEEP KEEP ADD ADD REP,Add Parameter
Update BOLFIRE posterior (#407),"def _negative_gradient_logpdf(self, x):  return -1 * self.gradient_logpdf(x)  def compute_map_estimates(self, n_opt_inits=10, max_opt_iters=1000): """"""Return the maximum a posterior estimate for each parameter.  Parameters ---------- n_inits : int, optional Number of initialization points in optimization. max_opt_iters : int, optional Maximum number of iterations performed in optimization.  Returns ------- OrderedDict  """"""","def _negative_gradient_pdf(self, x):  return -1 * self.gradient_pdf(x) ",KEEP REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
First attempt at easygopigo3 sensors,"def __init__(self, gpg,port=""A1""):","def __init__(self, port=""A1""):",KEEP KEEP REP,Add Parameter
Dependency parser.,"def make_tree(self, result): return Tree.fromstring(result['parse'])","def _make_tree(self, result): return Tree.fromstring(result)",KEEP REP KEEP KEEP REP,Rename Method
added bert modules and utility functions,"def _http_get(url, cache_dir):","def _http_get(url, dir):",KEEP KEEP REP,Rename Parameter
Replace the use of random and fixed effects terms (#279),"def _scale_common(self, term):","def _scale_fixed(self, term):",KEEP REP KEEP,Rename Method
"Simplify tests suite, remove spy_phase and related functions (#886)",def test_suggest_n(self):,"@phase def test_suggest_n(self, mocker, num, attr):",DEL KEEP REP DEL DEL DEL,Remove Parameter
Bugfix: Preview for extract in batch mode,def _save(self) -> Optional[IO]:,def _save(self):,KEEP ADD ADD REP,Change Return Type
fix mle search,"def mle(self, debug=False):",def mle(self):,KEEP ADD REP,Add Parameter
Native circuit library (#920),"@data('wrapped', 'library') def test_swaprz(self, mode):",def test_swaprz(self):,ADD ADD KEEP ADD REP,Add Parameter
Pass default index into cell extractors,"def extract_7_cells(cells, index): line_index, word, lemma, tag, _, head, rel = cells try: index = int(line_index) except ValueError:  pass","def extract_7_cells(cells): index, word, lemma, tag, _, head, rel = cells",KEEP ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD,Add Parameter
"wip, eoh and iqft and oracles","@classmethod def init_params(cls, params):","def init_params(self, params):",ADD KEEP REP KEEP,Rename Parameter
add infer of seq2seq model.,"def is_unknown_token(self, token):","def is_unknow_token(self, token):",KEEP REP KEEP,Rename Method
refactoring of circuit factory (getting rid of params),"def build_controlled_inverse_power(self, qc, q, q_control, power, q_ancillas=None, use_basis_gates=True):","def build_controlled_inverse_power(self, qc, q, q_control, power, q_ancillas=None, params=None):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
model update (#417),"def __init__(self, model_dir, gpus, encoder_type=ENCODER): ","def __init__(self, model_dir, gpus): ",KEEP KEEP KEEP ADD REP,Add Parameter
Flip Develop Into Master  / DexterOS 1.2 (#137),"def __init__(self, port=""AD1"",gpg=None, use_mutex = False):","def __init__(self, port=""AD1"",gpg=None):",KEEP KEEP ADD ADD ADD REP,Add Parameter
remove stan backend and replace sd with sigma (#205),"def _get_slope_stats(self, exog, predictor, sigma_corr, full_mod=None, points=4):","def _get_slope_stats(self, exog, predictor, sd_corr, full_mod=None, points=4):",KEEP KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
Further pool improvements (#206),"def new_model(name=None, set_current=True): model = ElfiModel(name=name)",def new_model(set_current=True): model = ElfiModel(),KEEP ADD REP KEEP KEEP REP,Add Parameter
- Added in some comments and epydoc markup.,"def removeOldestEntry(self): """""" Remove the oldest entry from the cache. """""" while self.oldestTimestamp < self.nextTimestamp:  if self.history.get(self.oldestTimestamp): key = self.history[self.oldestTimestamp] del self.history[self.oldestTimestamp] del self.values[key]",def removeOldestEntry(this):  while this.oldestTimestamp < this.nextTimestamp:  if this.history.get(this.oldestTimestamp): key = this.history[this.oldestTimestamp] del this.history[this.oldestTimestamp] del this.values[key],KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP REP KEEP REP KEEP REP KEEP KEEP REP KEEP KEEP REP KEEP REP KEEP REP,Rename Parameter
use self.tagtype consistently in raw_parse_sent,"def raw_tag_sents(self, sentences):","def raw_tag_sents(self, sentences, tagtype):",KEEP KEEP REP DEL,Remove Parameter
"bug fixes, unit testing, and doc updates for InterpLongToWide",def test_interp_long_to_wide():,def test_stacked_interp():,KEEP REP,Rename Method
create new symmetries class and a single place for operator conversion,"def __init__(self, paulis, basis, z2_symmetries=None, atol=1e-12, name=None, grouping_func=None, kwargs=None): super().__init__(paulis, basis, z2_symmetries, atol, name)","def __init__(self, paulis, basis, grouping_func=None, atol=1e-12, name=None, kwargs=None): super().__init__(paulis, basis, atol, name=name)",KEEP KEEP KEEP KEEP REP KEEP KEEP ADD KEEP KEEP KEEP ADD KEEP REP,Add Parameter
coordinates.io.featurizer: Added Unit Tests and removed some bugs,"def __init__(self, top, distance_indexes, threshold = 5.0, periodic=True):","def __init__(self, top, distance_indexes, threshold):",KEEP KEEP KEEP KEEP ADD ADD ADD REP,Add Parameter
"Unify EphemeralDB, MongoDB and PickledDB tests","@pytest.mark.db_types_only([""ephemeraldb"", ""pickleddb""]) def test_drop_ordered_compound_index_ephemeraldb(self, orion_db):","def test_drop_ordered_compound_index(self, orion_db):",ADD ADD KEEP REP KEEP,Rename Method
Idep (#127),"def maxent_dist(dist, rvs, rv_mode=None, x0=None, sparse=True, maxiters=1000):","def maxent_dist(dist, rvs, rv_mode=None, x0=None, sparse=True):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
[msm/estimation] largest_connected_submatrix accepts user specified largest connected set. Also added unit tests for this feature,"def largest_connected_submatrix(C, directed=True, lcc=None):","def largest_connected_submatrix(C, directed=True):",KEEP KEEP ADD REP,Add Parameter
Make OptimizationResult read-only (all parameters of the constructor become mandatory) (#1131),"def __init__(self, x: np.ndarray, fval: float, variables: List[Variable], state: ADMMState) -> None: """""" Args: x: the optimal value found by ADMM. fval: the optimal function value. variables: the list of variables of the optimization problem. state: the internal computation state of ADMM. """""" super().__init__(x=x, fval=fval, variables=variables, raw_results=state)","def __init__(self, x: Optional[Any] = None, fval: Optional[Any] = None, state: Optional[ADMMState] = None, results: Optional[Any] = None, variables: Optional[List[Variable]] = None) -> None: super().__init__(x=x, variables=variables, fval=fval, results=results or state) self._state = state",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP REP REP REP REP REP REP REP REP REP KEEP ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP REP REP REP REP REP REP REP REP,Remove Parameter
fix bugs and improve the approach making frames (#900),"def draw_user_input(self, record, img, img_drawon):","def draw_user_input(self, record, img):",KEEP KEEP KEEP ADD REP,Add Parameter
Adding lone electron pairs to group.py,"def __init__(self, atomType=None, radicalElectrons=None, spinMultiplicity=None, charge=None, label='', lonePairs=0):","def __init__(self, atomType=None, radicalElectrons=None, spinMultiplicity=None, charge=None, label=''):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
setup.py: implement logging,def _check_pip(self) -> None:,def check_pip(self) -> None:,KEEP REP KEEP KEEP,Rename Method
"lib,cli: Add suppressed colab flag","def __print_loss(self, loss, is_colab):","def __print_loss(self, loss):",KEEP KEEP ADD REP,Add Parameter
"MultiGPU version of ""mnist-keras.py""","def __call__(self, *input_tensors):","def __call__(self, input_tensors):",KEEP KEEP REP,Remove Parameter
"Extract: Expose ""allow_growth"" option","def __init__(self, model_path, allow_growth): super().__init__(""MTCNN-RNet"", model_path, allow_growth=allow_growth)","def __init__(self, model_path): super().__init__(""MTCNN-RNet"", model_path)",KEEP KEEP ADD REP KEEP ADD REP,Add Parameter
Some improvements to fromAdjacencyList().,"def fromAdjacencyList(adjlist, pattern=False, addH=False):","def fromAdjacencyList(adjlist, pattern=False, addH=False, withLabel=True):",KEEP KEEP KEEP REP DEL,Remove Parameter
Type check e2e scripts (#4932),"def validate_menu_items(menu_items: MenuItems) -> None: for k, v in menu_items.items():","def validate_menu_items(dict: MenuItems) -> None: for k, v in dict.items():",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
Prefix legacy and arrow commands with _ (#3563),def _arrow_line_chart(,def arrow_line_chart(,KEEP REP,Rename Method
- Added 'tree_class' param to ConllCorpusReader constructor,"def _get_srl_instances(self, grid, pos_in_tree): tree = self._get_parsed_sent(grid, pos_in_tree)","def _get_srl_instances(self, grid): tree = self._get_parsed_sent(grid)",KEEP KEEP ADD REP KEEP KEEP ADD REP,Add Parameter
Added toPrettyRepr() methods to Kinetics classes.,"def toPrettyRepr(self): """""" Return a string representation of the reference that can be used to reconstruct the object. """""" string = u'MultiKinetics(\n' string += u'    kineticsList = [\n' for kinetics in self.kineticsList: for line in kinetics.toPrettyRepr().splitlines()[:-1]: string += u'    {0}\n'.format(line) string += u'    ),\n' string += u'    ],\n' if self.Tmin is not None: string += '    Tmin = {0!r},\n'.format(self.Tmin) if self.Tmax is not None: string += '    Tmax = {0!r},\n'.format(self.Tmax) if self.Pmin is not None: string += '    Pmin = {0!r},\n'.format(self.Pmin) if self.Pmax is not None: string += '    Pmax = {0!r},\n'.format(self.Pmax) if self.comment != '': string += '    comment = ,\n'.format(self.comment) return string + u')'","def __repr__(self): """""" Return a string representation that can be used to reconstruct the MultiKinetics object. """""" string = 'MultiKinetics(kineticsList=[{0}]'.format(', '.join([repr(k) for k in self.kineticsList])) if self.Tmin is not None: string += ', Tmin={0!r}'.format(self.Tmin) if self.Tmax is not None: string += ', Tmax={0!r}'.format(self.Tmax) if self.Pmin is not None: string += ', Pmin={0!r}'.format(self.Pmin) if self.Pmax is not None: string += ', Pmax={0!r}'.format(self.Pmax) if self.comment != '': string += ', comment='.format(self.comment) string += ')' return string",KEEP REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP DEL KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP REP KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD REP REP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP REP REP REP REP KEEP KEEP ADD ADD,Rename Method
Vocabulary building no longer responsibility of NgramCounter; counting always done after initialization.,def test_NgramCounter_order_attr(self):,def test_NgramCounter_order_property(self):,KEEP REP,Rename Method
updated square example,"def __init__(self, model_path, **kwargs): ","def __init__(self, model, **kwargs):",KEEP KEEP REP KEEP,Rename Parameter
make the interface Edges define the fields,"def __init__(self, entity1_class, entity2_class, relation_type, distance, use_predicted_entities=True, rewrite_edges=True):","def __init__(self, entity1_class, entity2_class, relation_type, distance, use_predicted_entities=True):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_top_topics(self):,def testTopTopics(self):,KEEP REP,Rename Method
Moved walk back into replace,"def bottom_up(rv, F, atoms=False, nonbasic=False):","def bottom_up(rv, F, atoms=False, nonbasic=False, simultaneous=True):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
[cset] changed all cset functions to work with lists of separated trajectories,"def _compute_csets(connectivity, state_counts, count_matrices, ttrajs, dtrajs, bias_trajs, nn, factor=1.0):","def _compute_csets(connectivity, state_counts, count_matrices, tram_trajs, nn=None, factor=1.0):",KEEP KEEP KEEP KEEP ADD ADD REP REP KEEP,Add Parameter
a single-element combo with a multiple element u-layer is not a valid combo,"def valid_combo(combo, mol, u_layer):","def valid_combo(combo, mol):",KEEP KEEP ADD REP,Add Parameter
[doc] documentation updates,"def __init__(self, dtrajs, lag, T, reversible=True, sparse=False, connectivity='largest', estimate=True, dt='1 step', **kwargs): r""""""Estimates a Markov model from discrete trajectories.","def __init__(self, dtrajs, lag, reversible=True, sparse=False, connectivity='largest', estimate=True, dt='1 step', **kwargs): ",KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD,Add Parameter
GUI Updates (#940),"def initialize_images(): """""" Initialize the :class:`Images` handler  and add to global constant.  This should only be called once on first GUI startup. Future access to :class:`Images` handler should only be executed through :func:`get_images`. """"""",def initialize_images(pathcache=None): ,KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Remove Parameter
Replace (part of) pretest of CI with Pre-commit equivalent (#918),"def generate_trials_list(level, statuses=Trial.allowed_stati):","def generate_trials_list(level, stati=Trial.allowed_stati):",KEEP KEEP REP,Rename Parameter
Add type annotations to DeltaGenerator mixins (#2475),"def multiselect(self, label, options, default=None, format_func=str, key=None):","def multiselect(dg, label, options, default=None, format_func=str, key=None):",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Parameter
exact-solution,"def init_args(self, matrix, invec, eigs, init_state, reciprocal, mode, num_q, num_a):","def init_args(self, matrix, invec, eigs, init_state, reciprocal, num_q, num_a):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
Align _match_potential_end_contexts with NLTK 3.6.5 sent_tokenize results,"def span_tokenize( self, text: str, realign_boundaries: bool = True ) -> Iterator[Tuple[int, int]]:","def span_tokenize(self, text, realign_boundaries=True):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP,Change Return Type
reuse_input_vars,"def __init__(self, trainer, queue, enqueue_op, raw_input_var):","def __init__(self, trainer, enqueue_op, dataflow, queue):",KEEP KEEP KEEP ADD KEEP REP DEL,Rename Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_no_exp(monkeypatch, setup_pickleddb_database, capsys):","def test_no_exp(monkeypatch, clean_db, capsys):",KEEP KEEP REP KEEP,Rename Parameter
Finish rv_names -> rv_mode for dit.algorithms.,"def join(dist, rvs, rv_mode=None, int_outcomes=True):","def join(dist, rvs, rv_names=None, int_outcomes=True):",KEEP KEEP KEEP REP KEEP,Rename Parameter
BOLFI + NUTS (#135),"def _neg_unnormalized_loglikelihood(self, x): return -1 * self._unnormalized_loglikelihood(x)  def _neg_unnormalized_logposterior(self, x):","def _neg_unnormalized_loglikelihood_density(self, x): return -1 * self._unnormalized_loglikelihood_density(x)",KEEP REP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP,Rename Method
Make sure subprocess/process/thread/dask can create a runner instance (#816),"def new_runner(idle_timeout, n_workers=2, client=None, executor=None, backend=""joblib""):","def new_runner(idle_timeout, n_workers=2, client=None):",KEEP KEEP KEEP ADD ADD REP,Add Parameter
nltk/corpus/reader/util.py,"def sents(self, documents=None):","def sents(self, items=None):",KEEP KEEP REP,Rename Parameter
Merge Extract Monitors. Correctly exit GUI when terminating training with preview window open,"def monitor(self, thread):  is_preview = self.args.preview logger.debug(""Launching Monitor"")","def monitor_console(self, thread): """""" Monitor the console NB: A custom function needs to be used for this because input() blocks """""" logger.debug(""Launching Console Monitor"")",KEEP REP KEEP REP REP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL KEEP DEL KEEP,Rename Method
Asymmetrical unification works along with aliases now. The last thing to deal,"def forwardTo(self, other, ourbindings, otherbindings): """""" A unification wants this variable to be aliased to another variable. Forward this variable to the other one, and return the other. """"""","def become(self, other, ourbindings, otherbindings):",KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
Remove MongoDB dependencies from tests/functional/commands,"def test_three_unrelated_wout_ac(three_experiments_with_trials, capsys):","def test_three_unrelated_wout_ac(clean_db, three_experiments_with_trials, capsys):",KEEP REP DEL KEEP,Remove Parameter
For the Enhancement of converters of QuadraticProgram (#1061),"def _interpret_var(self, names, vals) -> List[int]: ","def _decode_var(self, names, vals) -> List[int]: ",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
Smart Masks to Convert (#957),"def _check_thread_error(self):  for thread in (self._predictor.thread, self._disk_io.load_thread, self._disk_io.save_thread, self._patch_threads):","def check_thread_error(self):  for thread in (self.predictor.thread, self.disk_io.load_thread, self.disk_io.save_thread, self.patch_threads):",KEEP REP KEEP KEEP KEEP KEEP REP REP REP REP,Rename Method
quality: remove most type: ignore from sets,"@_set_add.register(Interval, Infinity) def _(x, y):","@dispatch(Interval, Infinity)   def _set_add(x, y): ",REP KEEP DEL DEL KEEP REP KEEP,Rename Method
update copyt5 predict,"def batch_t5_correct(self, texts: List[str], max_length: int = 128, batch_size: int = 512, silent: bool = False):","def batch_t5_correct(self, texts: List[str], max_length: int = 128):",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
Added partial support for mapping of tagsets.,"def tagged_words(self, fileids=None, categories=None, tagset=None):","def tagged_words(self, fileids=None, categories=None, simplify_tags=False):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Fixed comparisons for Python 3.,"def _calculate_hashvalue(self, visited):","def _hash(self, visited):",KEEP REP KEEP,Rename Method
Donkeycar 4.x release.  (#644),"def __init__(self, num_outputs=2, input_shape=(120, 160, 3)): super().__init__() self.model = default_n_linear(num_outputs, input_shape)","def __init__(self, num_outputs=2, input_shape=(120, 160, 3), roi_crop=(0, 0), *args, **kwargs): super(KerasLinear, self).__init__(*args, **kwargs) self.model = default_n_linear(num_outputs, input_shape, roi_crop)",KEEP KEEP KEEP KEEP KEEP REP REP DEL DEL DEL DEL DEL DEL KEEP KEEP KEEP REP DEL,Remove Parameter
use tf.train.MonitoredSession. enforce a boundary between graph finalize & session create,"def __init__(self, model, towers):","def __init__(self, sess, model, towers):",KEEP KEEP DEL KEEP KEEP,Remove Parameter
[coordinates.util]: Added a stride option to all coordinates.util transformer functions (for parametrization),"def cluster_assign_centers(data=None, centers=None, stride=1):","def cluster_assign_centers(data=None, centers=None):",KEEP KEEP ADD REP,Add Parameter
Minor: rename Qchem as QChem,def testSpinMultiplicityFromQChemLog(self):,def testSpinMultiplicityFromQchemLog(self):,KEEP REP,Rename Method
Major refactoring of the toolbox in preparation for release. Changes include: Use of configparser for setting up experiments; implementing abstract base classes and methods for model parsing; restructuring repo; updating documentation; adding examples; extending testsuite.,"def get_scale_fac(activations, percentile): """""" Determine the activation value at ``percentile`` of the layer distribution.","def get_scale_fac(activations, idx=0): """"""Determine the maximum activation of a layer.",KEEP KEEP ADD REP REP KEEP ADD ADD REP REP KEEP ADD REP REP,Rename Parameter
env_app fix in pytorch visdom logger,"def plot_mutliple_models_statistics_weights(self, model_dict, env_appendix=None):","def plot_mutliple_models_statistics_weights(self, model_dict, env_app=None):",KEEP KEEP KEEP REP,Rename Parameter
[Angelica] Update docstrings for neuralnets classes.,"def predict(self, images):",def predict(self):,KEEP ADD REP,Add Parameter
[#14] toplist method and results,"def generate_top_stats_array(self, top_nr=10, is_alpha_only=False, class_id=""e_2""):","def generate_top_stats_array(self, top_nr=10):",KEEP KEEP ADD ADD REP,Add Parameter
made port configurable,"def __init__(self, session, pilot, port=8887):  self.port = int(port)","def __init__(self, session, pilot):  self.port = int(os.environ.get(""PORT"", 8887))",KEEP KEEP KEEP ADD REP KEEP KEEP KEEP REP DEL,Add Parameter
Smart Extract code review,"def _padding_from_coverage(self, size, coverage_ratio):","@staticmethod def _padding_from_coverage(size, coverage_ratio):",REP REP REP KEEP,Add Parameter
Adjust format_trials test to new fixed_suggestion,"def test_tuple_to_trial(space, fixed_suggestion, params_tuple):","def test_tuple_to_trial(space, trial, fixed_suggestion):",KEEP KEEP REP REP,Rename Parameter
Fix flake8 and pylint issues,"def _execute(cmdargs, cmdconfig): _, cmdargs = _infer_experiment(cmdargs, cmdconfig)","def execute(cmdargs, cmdconfig): experiment, cmdargs = infer_experiment(cmdargs, cmdconfig)",KEEP REP KEEP REP KEEP KEEP REP KEEP,Rename Method
add output_topk option,"def test(data_loader, model, result_path, class_names, no_average, output_topk):","def test(data_loader, model, result_path, class_names, no_average):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Filter wikipedia articles by their namespace,"def __init__(self, fname, processes=None, lemmatize=utils.HAS_PATTERN, dictionary=None, filter_namespaces=False):","def __init__(self, fname, processes=None, lemmatize=utils.HAS_PATTERN, dictionary=None):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
update rnn_crf and seq2seq with model train.,"def __init__(self, train_path=None, token_2_id=None):","def __init__(self, config, train_path=None, token_2_id=None, dataset_copies=2):",KEEP KEEP DEL KEEP REP DEL,Remove Parameter
path follow using the Intel T265 and odom,"def run_threaded(self, enc_vel_ms): self.enc_vel_ms = enc_vel_ms",def run_threaded(self):,KEEP ADD ADD ADD ADD REP,Add Parameter
Reranker outputs can be converted back to DAs,"def dist_to_cur_da(self, trees, return_classif=False):","def dist_to_cur_da(self, trees):",KEEP KEEP ADD REP,Add Parameter
Address comments to PR,def extract_result(self):,"def extract_result(self, method=None):",KEEP REP DEL,Remove Parameter
Deprecated tests,"def _eval_rewrite_as_polynomial(self, n, m, x, **kwargs):","def _eval_rewrite_as_polynomial(self, n, x, **kwargs):",KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
Improved plotting. Minor fixes.,"def plot_layer_correlation(rates, activations, title, config, path=None, normalize=False):","def plot_layer_correlation(rates, activations, title, config, path=None):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Add type annotations for DeltaGenerator and dataframe mixins (#4733),"def _legacy_add_rows( self: DG, data: ""Data"" = None, **kwargs: Union[ ""DataFrame"", ""npt.NDArray[Any]"", Iterable[Any], Dict[Hashable, Any], None ], ) -> Optional[DG]:","def _legacy_add_rows(self, data=None, **kwargs):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP,Change Return Type
Config Changes + Bugfixes,"def __init__(self, mask_type, output_size, predicted_available=False, **kwargs): super().__init__(mask_type, output_size, predicted_available, **kwargs)","def __init__(self, mask_type, output_size, predicted_available=False, config=None): super().__init__(mask_type, output_size, predicted_available, config)",KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP REP,Remove Parameter
Adding function to rank in documents from corpus. WIP,def get_graph(text): tokens = _clean_text_by_word(text),"def get_graph(text, language=""english""): tokens = _clean_text_by_word(text, language)",KEEP REP DEL KEEP KEEP REP DEL,Remove Parameter
Added a `reactive` attribute to the Molecule class,"def __init__(self, atoms=None, symmetry=-1, multiplicity=-187, reactive=True, props=None, SMILES=''):","def __init__(self, atoms=None, symmetry=-1, multiplicity=-187, props=None, SMILES=''):",KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
Add output checking when generating identifiers,"def _check_output(mol, identifier):","def _is_correctly_parsed(mol, identifier):",KEEP REP KEEP,Rename Method
Update TF to 2.9,"def _amd_predict_with_optimized_batchsizes( self, feed: Union[List[np.ndarray], np.ndarray], batch_size: int) -> Union[List[np.ndarray], np.ndarray]:","def _amd_predict_with_optimized_batchsizes(self, feed, batch_size):",KEEP ADD ADD ADD ADD ADD ADD ADD REP REP REP,Change Return Type
Fixes in tests,"def no_test2(self): t, _, _, h, _ = init_table('tests/screenshots/test2.png')","def test2(self): t, p, gui_signals, h, logger = init_table('tests/screenshots/test2.png')",KEEP REP KEEP REP REP KEEP REP KEEP KEEP,Rename Method
glsl printer: simplify GLSL array constructor usage,def test_Matrices_1x7_base_type_int():,def test_Matrices_1x7_custom_constructor():,KEEP REP,Rename Method
GUI Update,"def build_control(self, choices, dtype, rounding, min_max, sysbrowser, radio_columns, control_width):","def build_control(self, choices, dtype, rounding, min_max, radio_columns, label_width, control_width):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP DEL KEEP,Rename Parameter
"Update facenet, update tensorflow requirement to 1.7.0, add support for facenet models with arbitrary number of embeddings, add example for database","def get_paths(lfw_dir, pairs):","def get_paths(lfw_dir, pairs, file_ext):",KEEP KEEP REP DEL,Remove Parameter
server working after refactor,"def post(self, vehicle_id):",def post(self): ''' Receive post requests as user changes the angle and speed of the vehicle on a the controller webpage,KEEP REP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Add Parameter
[coordinates] add skip parameters to Estimators to allow to skip inital n_frames.,"def iterator(self, stride=1, lag=0, chunk=None, return_trajindex=True, cols=None, skip=0):","def iterator(self, stride=1, lag=0, chunk=None, return_trajindex=True, cols=None):",KEEP KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
[coordinates] added stridden access,"def trajectory_lengths(self, stride=1):",def trajectory_lengths(self):,KEEP ADD REP,Add Parameter
add  include_group_specific argument to predict (#470),"def predict( self, idata, kind=""mean"", data=None, draws=None, inplace=True, include_group_specific=True ):","def predict(self, idata, kind=""mean"", data=None, draws=None, inplace=True):",KEEP ADD REP KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
Adjust regret to new to_pandas(),"def _format_hyperparameters(hyperparameters, names):",def _format_hyperparameters(hyperparameters):,KEEP ADD REP,Add Parameter
[msm] remove dead code,"def count_matrix(self, connected_set=None, subset=None):","def count_matrix(self, connected_set=None, subset=None, effective=False):",KEEP KEEP KEEP REP DEL,Remove Parameter
"Simplify tests suite, remove spy_phase and related functions (#886)","@register(""real"", ""uniform"") def _(dim: Dimension):","@to_ng_space.register(""real"", ""uniform"") def _(_, dim):",REP KEEP KEEP REP REP,Remove Parameter
Major refactoring of the toolbox in preparation for release. Changes include: Use of configparser for setting up experiments; implementing abstract base classes and methods for model parsing; restructuring repo; updating documentation; adding examples; extending testsuite.,"def spiketrains_to_rates(spiketrains_n_b_l_t, duration):",def spiketrains_to_rates(spiketrains_n_b_l_t):,KEEP ADD REP,Add Parameter
"Revert ""Datasource add skip parameter""","def __init__(self, chunksize=1000):","def __init__(self, chunksize=1000, skip=0):",KEEP KEEP REP DEL,Remove Parameter
I think I finally got rid of daemon=True,"def __init__(self, local=True, save=False):","def __init__(self, save=False):",KEEP KEEP ADD KEEP,Add Parameter
updated utils strip_* to allow list of tokens,"def strip_bos(str_, bos_token='<BOS>', is_token_list=False, compat=True): """"""Remove all leading BOS tokens.","def strip_bos(str_, bos_token='<BOS>', compat=True): """"""Remove the leading BOS token.",KEEP KEEP KEEP ADD KEEP KEEP REP KEEP KEEP REP,Add Parameter
Fixed bugs in parsing caffe input models,"def get_facedetection(sourcepath, imagepath, targetpath=None, filename=None):","def get_facedetection(sourcepath, imagepath, targetpath=None, filename=None, flat=False):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
Validate input and move sample_weights to function parameters.,"def predict(self, X, categorical=None, sample_weights=None):","def predict(self, X, categorical=None):",KEEP KEEP KEEP ADD REP,Add Parameter
model_refactor (#571) (#572),def add_util_buttons(self):,"def add_util_buttons(self, cli_options, tk_vars):",KEEP REP DEL DEL,Remove Parameter
[coordinates] add skip parameters to Estimators to allow to skip inital n_frames.,"def n_frames_total(self, stride=1, skip=0):","def n_frames_total(self, stride=1):",KEEP KEEP ADD REP,Add Parameter
Fixes in tests,def no_test_ranges_call_column(self):,def test_ranges_call_column(self):,KEEP REP,Rename Method
Rename functions and variables in resolvconf to be more readable,def fetch_default_options():,def default_options():,KEEP REP,Rename Method
"Added location and task meta data, command line and/or config.","def new_tub_writer(self, inputs, types, location=None, task=None):","def new_tub_writer(self, inputs, types):",KEEP KEEP KEEP ADD ADD REP,Add Parameter
Romc fixes (#393),@staticmethod def _worker_build_region(args):,"def _worker_build_region(self, args):",ADD KEEP REP DEL,Remove Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_invalid_query(single_with_trials, capsys):","def test_invalid_query(clean_db, single_with_trials, capsys):",KEEP REP DEL KEEP,Remove Parameter
Refactor.,def _set_graph_edge_weights(graph):,"def _set_graph_edge_weights(graph, dictionary):",KEEP REP DEL,Remove Parameter
Prefix legacy and arrow commands with _ (#3563),def test_st_legacy_line_chart(self): ,def test_st_line_chart(self): ,KEEP REP,Rename Method
Remove exp.configure and all related methods,def test_configurable_broken_property():,def test_configurable_broken_property(hacked_exp):,KEEP REP,Remove Parameter
foolow pep8 in function naming,"def apply_force(force, body1, body2=None, point1=None, point2=None):","def Force(force, body1, body2=None, point1=None, point2=None):",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
style correction,"def build(self, qc, q, q_ancillas=None):","def build(self, qc, q, q_ancillas=None, params=None):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
Continuing to finalise the parse->read name change,"def read_number(s, start_position):","def parse_number(s, start_position):",KEEP REP KEEP,Rename Method
Fix add_graph for pytorch 1.4 (fixes #545) (#548),"def __init__(self, node_cpp, input_or_output=None, debugName='', tensor_size=[]):","def __init__(self, node_cpp, input_or_output=None, debugName=''):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Comment test_qsvm for now,def todo_test_qsvm_variational_via_run_algorithm(self):,def test_qsvm_variational_via_run_algorithm(self):,KEEP REP,Rename Method
Refactor ElfiStorage,"def read_data(self, node_name, sl):","def read_data(self, sl):",KEEP KEEP ADD KEEP,Add Parameter
begin creating main loop,def main_loop():,def record():,KEEP REP,Rename Method
adding docs for jetson nano setup,"def drive(cfg, model_path=None, model_type=None):","def drive(cfg, model_path=None, model_type=None, camera_type='single', meta=[] ):",KEEP KEEP KEEP REP DEL DEL DEL,Remove Parameter
"added chunksize argument to discretizer to enforce a given chunksize, instead of estimating it.","def __init__(self, reader, transform=None, cluster=None, chunksize=None):","def __init__(self, reader, transform=None, cluster=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Post PR Fixups,"def __init__(self, outputs, mask_input): logger.debug(""Initializing %s: (outputs: '%s', mask_input: '%s')"", self.__class__.__name__, outputs, mask_input)","def __init__(self, side, outputs, mask_input, predict): logger.debug(""Initializing %s: (side: '%s', outputs: '%s', mask_input: '%s', predict: %s"", self.__class__.__name__, side, outputs, mask_input, predict)",KEEP KEEP DEL KEEP REP DEL KEEP KEEP REP KEEP DEL DEL KEEP REP DEL DEL KEEP DEL KEEP REP DEL,Remove Parameter
Lint ProxyConnection and proxy/__main__.py,def close_local_connection(self): ,def finished_local_connection(self): ,KEEP REP,Rename Method
Only require email (not invite code),"def _generate_code(secret, email):","def generate_code(secret, email):",KEEP REP KEEP,Rename Method
Flowsheet object support,"def connect(self,s1,s2): '''Connect two objects The first name dictates the properties of the combined object.","def connect_streams(self,s1,s2): '''Connect two streams The first stream dictates the properties of the combined stream.",KEEP REP KEEP KEEP REP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP,Rename Method
Add command-line option to control generation of plots in CanTherm.,"def execute(self, outputFile, plot):","def execute(self, outputFile):",KEEP KEEP ADD REP,Add Parameter
Positioned and keyword arguments coded to the computational graph,"def add_parent(self, name, parent, param=None): if not isinstance(parent, NodeReference):","def add_parent(self, name, parent): if not isinstance(parent, NodePointer):",KEEP KEEP KEEP ADD REP KEEP KEEP KEEP REP,Add Parameter
Make rmgpy/solver/* unit tests PEP-8 compliant,def test_surface_layering_constraint(self):,def testSurfaceLayeringConstraint(self):,KEEP REP,Rename Method
Make rmgpy/thermo/* unit tests PEP-8 compliant,def test_convert_thermo_data_to_wilhoit(self):,def test_convert_ThermoData_to_Wilhoit(self):,KEEP REP,Rename Method
Added reference temperature attribute T0 to ArrheniusModel class.,"def __init__(self, A=0.0, n=0.0, Ea=0.0, T0=298.15):","def __init__(self, A=0.0, n=0.0, Ea=0.0):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
[Angelica] Add examples to Sphinx docs.,def _get_image_feature_array_from_directory(self):,def get_image_feature_array_from_directory(self):,KEEP REP,Rename Method
"Add Registry, rework how Space is passed to algorithms (#833)","def sample(self, num: int) -> list[Trial]:","def sample(self, num):",KEEP KEEP ADD ADD ADD REP,Change Return Type
Adds timing info for model in GPU (#527),"def graph(model, args, verbose=False, use_cuda=False, **kwargs):","def graph(model, args, verbose=False, **kwargs):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Fix typing,"def init_population(self, pop_size: int) -> list[numpy.ndarray]:","def init_population(self, pop_size: int) -> List[np.array]:",KEEP KEEP KEEP KEEP KEEP REP,Change Return Type
simplify: demand return a function that just annotates (not one that generates an instance of class Annotator),"def cross_validate(annotator_gen_fun, corpus, evaluator, k_num_folds, use_validation_set=True):","def cross_validate(annotator_fun, corpus, evaluator, k_num_folds, use_validation_set=True):",KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
Adding the possibility to use limits on number of nodes,"def get_all_successors(self, cand_tree, cdfs, node_limits=None): """"""Get all possible successors of a candidate tree, given CDFS and node number limits.","def get_all_successors(self, cand_tree, cdfs): """"""Get all possible successors of a candidate tree.",KEEP KEEP KEEP ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD REP,Add Parameter
Gui v3.0b (#436),"def Encoder_original(self, **kwargs): impt = Input(shape=self.IMAGE_SHAPE)  in_conv_filters = self.IMAGE_SHAPE[0] if self.IMAGE_SHAPE[0] <= 128 else 128 + (self.IMAGE_SHAPE[0]-128)//4  x = self.conv(in_conv_filters)(impt) x = self.conv_sep2(256)(x) x = self.conv(512)(x) x = self.conv_sep2(1024)(x)  dense_shape = self.IMAGE_SHAPE[0] // 16",def Encoder_v3(self):  retina = Input(shape=self.IMAGE_SHAPE) x = self.conv_sep_v3(192)(retina) x = self.conv(256)(x) x = self.conv(384)(x) x = self.conv_sep_v3(512)(x) x = self.conv(768)(x) x = self.conv_sep_v3(1024)(x),KEEP REP REP REP KEEP KEEP ADD REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP KEEP REP KEEP KEEP REP KEEP KEEP REP KEEP KEEP ADD REP REP KEEP ADD ADD REP,Rename Method
Minor FixedProducerDispatcher changes. Fix timelapse bug,"def __init__(self, method, shapes, in_queue, out_queue,","def __init__(self, method, shapes,",KEEP KEEP KEEP KEEP ADD ADD,Add Parameter
minor rename,"def _mct_v_chain(qc, control_qubits, target_qubit, ancillary_qubits, dirty_ancilla=False):","def _ccx_v_chain(qc, control_qubits, target_qubit, ancillary_qubits, dirty_ancilla=False):",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
Accept pre-tokenized references & hypothesis for METEOR calculation (#2822),"def wordnetsyn_match( hypothesis: Iterable[str], reference: Iterable[str], wordnet: WordNetCorpusReader = wordnet, ) -> Tuple[List[Tuple[int, int]], List[Tuple[int, str]], List[Tuple[int, str]]]:","def wordnetsyn_match(hypothesis, reference, wordnet=wordnet):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP,Change Return Type
use init term instead of create for methods,"def init_sound_sensor(self, port):","def assign_sound_sensor(self, port):",KEEP REP KEEP,Rename Method
Remove MongoDB dependencies from tests/functional/commands,"def test_three_related_branch_w_a_wout_c(three_family_branch_with_trials, capsys):","def test_three_related_branch_w_a_wout_c( clean_db, three_family_branch_with_trials, capsys ):",KEEP REP REP DEL DEL DEL,Remove Parameter
- Remove incorrect _get_ground_state_energy,"def predict(self, data, quantum_instance=None, minibatch_size=-1, params=None):","def predict(self, data, quantum_instance=None, minibatch_size=-1):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Add concurrent unittests for producer,def test_algo_observe_completed(producer):  assert len(producer.experiment.fetch_trials({})) > 3,def test_update(producer): ,KEEP ADD ADD ADD ADD ADD REP,Rename Method
Excited States algorithms and support for Chemistry (#1354),"def commutator(op_a, op_b, op_c=None, sign=-1, threshold=1e-12):","def commutator(op_a, op_b, op_c=None, threshold=1e-12):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Refactored core modules.,@staticmethod def assert_batch_size(batch_size):,"def assert_batch_size(self, batch_size):",ADD KEEP REP DEL,Remove Parameter
Remove outdate multidispatch,def _(func):,def _df(func):,KEEP REP,Rename Method
Polish BERT example,"@staticmethod def _create_examples(lines, set_type):","def _create_examples(self, lines, set_type):",ADD KEEP REP DEL KEEP,Remove Parameter
Bugfix: Preview for extract in batch mode,"def set_faceswap_output_path(self, location: str, batch_mode: bool = False) -> None:","def set_faceswap_output_path(self, location):",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
-,"def test_interrupt_diff_code(monkeypatch, capsys, storage):","def test_interrupt_diff_code(monkeypatch, capsys):",KEEP KEEP ADD REP,Add Parameter
Term.init no longer needs the full Model,"def __init__(self, name, data, predictor, grouper, categorical=False, prior=None, constant=None, default_priors=PriorFactory(None), auto_scale=True):","def __init__(self, model, name, data, predictor, grouper, categorical=False, prior=None, constant=None):",KEEP KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
Changes poof to show (#973),"def fit_transform_show(self, X, y=None, **kwargs):","def fit_transform_poof(self, X, y=None, **kwargs):",KEEP REP KEEP KEEP KEEP,Rename Method
"remove PredictorFactory, and build offline predictor by tower_func","def __init__(self, model=None, inputs_desc=None, tower_func=None,","def __init__(self, model,",KEEP KEEP ADD ADD REP,Add Parameter
Fix Issue #769,"def test_parse_from_args_and_config_yaml( parser: OrionCmdlineParser, commandline: List[str], yaml_config: List[str], weird_argument: WeirdArgument, ):","def test_parse_from_args_and_config_yaml(parser, commandline, yaml_config):",KEEP ADD ADD ADD ADD ADD ADD ADD REP REP REP,Add Parameter
Consistency tests (#197),def _update_objective_n_batches(self): ,def _update_objective(self): ,KEEP REP,Rename Method
Remove MongoDB dependencies from tests/functional/commands,"def test_experiment_w_trials_wout_ac(single_with_trials, capsys):","def test_experiment_w_trials_wout_ac(clean_db, single_with_trials, capsys):",KEEP REP DEL KEEP,Remove Parameter
hyperband fixes,"def __init__(self, space, seed=None, frequency=numpy.inf):","def __init__(self, space, seed=None, repeat=numpy.inf):",KEEP KEEP KEEP KEEP REP,Rename Parameter
Make rmgpy/tools/* unit tests PEP-8 compliant,def test_remove_isotope_for_species(self):,def testRemoveIsotopeForSpecies(self):,KEEP REP,Rename Method
-,"def test_code_change(self, parent_config, changed_code_config, storage):","def test_code_change(self, parent_config, changed_code_config):",KEEP KEEP KEEP ADD REP,Add Parameter
fixed k-prototypes,"def get_dissim_cat(self, Acat, bx):","def get_dissim_cat(self, Acat, b):",KEEP KEEP KEEP REP,Rename Parameter
[coordinates.transform] Amended parameters of NystroemTICA,"def __init__(self, lag, max_columns,","def __init__(self, lag, max_columns, initial_columns=None, nsel=1, neig=None,",KEEP KEEP KEEP KEEP DEL DEL DEL,Add Parameter
"Simplify tests suite, remove spy_phase and related functions (#886)",def test_has_observed_statedict(self):,"@phase def test_has_observed_statedict(self, mocker, num, attr):",DEL KEEP REP DEL DEL DEL,Remove Parameter
Use doubles instead of numpy arrays in thermo methods of Mode objects.,"def getEntropy(self, T):","def getEntropy(self, Tlist):",KEEP KEEP REP,Rename Parameter
Add L2 Regularization to Structural Losses,"def _set_loss_names(self, outputs):","def _get_loss_names(self, outputs):",KEEP REP KEEP,Rename Method
Add max_trials to algorithm.is_done,def test_is_done_property_no_pending(algorithm):  completed = ['completed'] * 10 broken = ['broken'] * 5 with OrionState(trials=generate_trials(completed + broken)) as cfg:,def test_is_done_property_with_algo(algorithm):   with OrionState(trials=generate_trials((['completed'] * 10) + (['reserved'] * 5))) as cfg:,KEEP REP KEEP REP REP REP KEEP ADD REP REP REP KEEP ADD ADD ADD ADD REP KEEP KEEP,Rename Method
Merge version 0.45.0 (#34),def off_test_ignore_hash(self):,def test_ignore_hash(self):,KEEP REP,Rename Method
Added typing,"def generate_olh_samples( space: Space, n_levels: int, strength: int, index: int, rng: RandomState ) -> Tuple[np.array, int]:","def generate_olh_samples(space, n_levels, strength, index, rng):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP,Change Return Type
GUI: Consolidate settings to single menu,def set_styles(self):,@staticmethod def set_styles():,DEL KEEP REP,Add Parameter
Rename and refactor `Report` machinery (#4141),"def _exclude_blacklisted_paths(self, paths: Set[str]) -> Set[str]:","def _exclude_blacklisted_paths(self, paths: t.Set[str]) -> t.Set[str]:",KEEP KEEP KEEP REP KEEP REP,Change Return Type
Expose Augmentation Options to config,"def __init__(self, model_input_size, model_output_size, training_opts, config):","def __init__(self, model_input_size, model_output_size, training_opts):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Adapt Producer to shared state algorithm,def test_duplicate_within_pool():,"def test_duplicate_within_pool(producer, storage, random_dt):",KEEP REP DEL DEL,Remove Parameter
"Added Chapman-Kolmogorov test for all msm estimators, plots and tests for it.","def _compute_observables(self, model, estimator, mlag=1):","def _compute_observables(self, model, mlag=1):",KEEP KEEP KEEP ADD KEEP,Add Parameter
Add species multiplicity model.py,"def __init__(self, index=-1, label='', multiplicity=103, thermo=None, conformer=None,","def __init__(self, index=-1, label='', thermo=None, conformer=None,",KEEP KEEP KEEP KEEP ADD KEEP KEEP,Add Parameter
add unit tests,"def test_TransferFunction_multiplication_and_division(): G1 = TransferFunction(s + 3, -s**3 + 9) G2 = TransferFunction(s + 1, s - 5) expect = TransferFunction(-s**2 - 4*s - 3, s**4 - 5*s**3 -9*s + 45) assert G1.mul(G2) == expect  G3 = TransferFunction(p, p**4 - 6) G4 = TransferFunction(p + 4, p - 5) expect = TransferFunction(p**2 + 4*p, p**5 - 5*p**4 - 6*p + 30) assert G3.mul(G4) == expect assert G3.mul(s) == TransferFunction(p*s, p**4 - 6) assert G4.mul(p**-1) == TransferFunction(p + 4, p**2 - 5*p)  G5 = TransferFunction(s + 6, s - 5) G6 = TransferFunction(s + 3, s + 1) assert G5.div(G6) == TransferFunction(s**2 + 7*s + 6, s**2 - 2*s - 15) assert G5.div(2) == TransferFunction(s + 6, 2*s - 10)","def test_SISOTransferFunction_series(): G1 = SISOTransferFunction(s + 3, -s**3 + 9) G2 = SISOTransferFunction(s + 1, s - 5) expect = SISOTransferFunction(-s**2 - 4*s - 3, s**4 - 5*s**3 -9*s + 45) assert G1.series(G2) == expect",KEEP REP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
wip for updating constructors,"def __init__(self, num_qubits, depth, entangler_map=None, entanglement='full', z_order=2, data_map_func=self_product):","def init_args(self, num_qubits, depth, entangler_map=None, entanglement='full', z_order=2, data_map_func=self_product): """"""Initializer.  Args: num_qubits (int): number of qubits depth (int): the number of repeated circuits entangler_map (dict): describe the connectivity of qubits entanglement (str): ['full', 'linear'], generate the qubit connectivitiy by predefined topology z_order (str): z order data_map_func (Callable): a mapping function for data x """"""",KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
update with remote,"def __filter(self, qsk, reg=None, qubits=None, norm=True):","def __filter(self, qsk, reg=None, qubits=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
pooling fixes,"def __init__(self, size, stride=1, **kwargs):","def __init__(self, size, regions, stride=1, **kwargs):",KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
Data set for normalization is loaded only for normalization itself to save memory.,def normalize_parameters(self):,"def normalize_parameters(self, X_train):",KEEP REP DEL,Remove Parameter
Allow MPA pages with duplicate names (#4769),"def _create_new_session_message(self, page_script_hash: str) -> ForwardMsg:",def _create_new_session_message(self) -> ForwardMsg:,KEEP ADD ADD REP KEEP KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_debug_mode(self):,def testDebugMode(self):,KEEP REP,Rename Method
changed chunkparser api to use root_label and chunk_label instead of top_node and chunk_node,"def tagstr2tree(s, chunk_label=""NP"", root_label=""S"", sep='/'):","def tagstr2tree(s, chunk_node=""NP"", top_node=""S"", sep='/'):",KEEP KEEP REP REP KEEP,Rename Parameter
kimmo is ready for release to 6.863 class,"def graph_selected(self, event):","def graph_selected(self, value):",KEEP KEEP REP,Rename Parameter
Make rmgpy/tools/* unit tests PEP-8 compliant,def test_cluster_with_species(self):,def testClusterWithSpecies(self):,KEEP REP,Rename Method
Resolve some EVC failures,"def test_rename_missing(self, parent_config, child_config, storage):","def test_rename_missing(self, parent_config, child_config):",KEEP KEEP KEEP ADD REP,Add Parameter
Bugfixes and refactoring in DVS event processing functions.,"def get_eventframe_sequence(event_deque, is_x_first, is_x_flipped, is_y_flipped, shape, data_format, frame_width):","def get_eventframe_sequence(xaddr, yaddr, timestamps, pol, is_x_first, is_x_flipped, is_y_flipped, shape, data_format, frame_width):",KEEP REP DEL DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP,Remove Parameter
FileUploader auto-garbage-collection (#2922),def test_upload_missing_file_error(self):,def test_upload_missing_file(self):,KEEP REP,Rename Method
address some review comments,"def parallel_assessment(experiments, with_evc_tree=True):","def parallel_advantage(experiments, with_evc_tree=True):",KEEP REP KEEP,Rename Method
#94 clean,"def __init__(self, binary_model=""nala/data/default_model"", override_cache=False, expected_max_results=5, pattern_file_name=None):","def __init__(self, binary_model=""nala/data/default_model"", override_cache=False, expected_max_results=5, pattern_file='nala/data/nl_patterns.json'):",KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
De-Multiprocess Extract (#871),"@property def _output_queue(self):  qname = ""extract_align_out"" if self.final_pass else ""extract_align_in"" retval = self._queues[qname] logger.trace(""%s: %s"", qname, retval) return retval  @property def _active_plugins(self):  if self.passes == 1: retval = [self._detector, self._aligner] elif self.passes == 2 and not self.final_pass: retval = [self._detector] else: retval = [self._aligner] logger.trace(""Active plugins: %s"", retval) return retval  def _add_queues(self):  queues = dict() for task in (""extract_detect_in"", ""extract_align_in"", ""extract_align_out""):  self._queue_size = 32 if task == ""extract_detect_in"" or (not self._is_parallel and task == ""extract_align_in""): self._queue_size = 64 queue_manager.add_queue(task, maxsize=self._queue_size) queues[task] = queue_manager.get_queue(task) logger.debug(""Queues: %s"", queues) return queues","@property def output_queue(self):  qname = ""extract_align_out"" if self.final_pass else ""extract_align_in"" retval = self.queues[qname]",KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
Update data module to use new level of theory standard,def test_assert_level_of_theory(self):,def test_assert_model_chemistry(self):,KEEP REP,Rename Method
Ensure that s3.url is an absolute URL (#828),def test_check_conflicts_s3_sharing_mode(self):,def test_check_conflicts_3(self):,KEEP REP,Rename Method
Fixed ranges,"def run_montecarlo(self, logger,original_player_card_list, original_table_card_list, player_amount, ui, maxRuns,","def run_montecarlo(self, original_player_card_list, original_table_card_list, player_amount, ui, maxRuns,",KEEP KEEP REP KEEP KEEP KEEP KEEP,Add Parameter
Now storing dict of edges on Vertex and vertices on Edge.,def test_getSmallestSetOfSmallestRings(self):,def testGetSmallestSetOfSmallestRings(self):,KEEP REP,Rename Method
speed increase,"def get_ocr_number(img_orig, fast=False):",def get_ocr_number(img_orig):,KEEP ADD REP,Add Parameter
[plots]: improved plots,"def cktest(self, mlags=10, conf=0.95, err_est=False):","def cktest(self, mlags=10):",KEEP KEEP ADD ADD REP,Add Parameter
tsf att adv fix gamma and len,"def train_d1_step(self, sess, batch, gamma):","def train_d1_step(self, sess, batch):",KEEP KEEP KEEP ADD REP,Add Parameter
added stero camera option,"def drive(cfg, model_path=None, use_joystick=False, model_type=None, camera_type='single'):","def drive(cfg, model_path=None, use_joystick=False, model_type=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Added http headers in Intent model,"def call_api(url, type,headers={}, parameters = {}, is_json=False):","def call_api(url, type, parameters = {}, is_json=False):",KEEP KEEP REP KEEP KEEP KEEP KEEP,Add Parameter
Fix serving tests,"def test_unknown_parameter(self, client, ephemeral_storage):","def test_unknown_parameter(self, client):",KEEP KEEP ADD REP,Add Parameter
minor update,def test_els_via_run_algorithm_full_dict(self):,def test_elp_via_run_algorithm_full_dict(self):,KEEP REP,Rename Method
Add ignore to SaverRestore (#302),"def __init__(self, model_path, prefix=None, ignore=[]):","def __init__(self, model_path, prefix=None):",KEEP KEEP KEEP ADD REP,Add Parameter
AppSession.handle_backmsg (#4982),def _handle_stop_script_request(self) -> None:,def handle_stop_script_request(self) -> None:,KEEP REP KEEP KEEP,Rename Method
make more general and select which class_id to read only,"def __init__(self, directory, read_only_class_id=MUT_CLASS_ID, delete_incomplete_docs=True, is_predicted=False, read_relations=False):","def __init__(self, directory, read_just_mutations=True, delete_incomplete_docs=True, is_predicted=False, read_relations=False):",KEEP KEEP KEEP REP KEEP KEEP KEEP,Rename Parameter
rename outcome register -> output register,"def logic_and(clause_expr, circuit, variable_register, target_qubit, ancillary_register, mct_mode):","def _and(clause_expr, circuit, variable_register, target_qubit, ancillary_register, mct_mode):",KEEP REP KEEP KEEP KEEP KEEP KEEP,Rename Method
Update Darknet engine.,"def __init__(self, service_name, engine, comm_config, draw=False):","def __init__(self, service_name, engine, comm_config):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
De-Multiprocess Extract (#871),def set_root_logger(loglevel=logging.INFO): ,"def set_root_logger(loglevel=logging.INFO, queue=LOG_QUEUE): """""" Setup the root logger. Loaded in main process and into any spawned processes Automatically added in multithreading.py""""""",KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def sents(self, fileids=None): return concat([IndianCorpusView(fileid, enc,","def sents(self, files=None): return concat([IndianCorpusView(filename, enc,",KEEP KEEP REP KEEP REP KEEP,Rename Parameter
Faceswap 2.0 (#1045),"def _get_raw(self): """""" Obtain the raw loss values.","def get_raw(self):  logger.debug(""Getting Raw Data"")",KEEP ADD ADD REP REP REP REP REP,Rename Method
Fixes Manifold fit_transform bug (#505),"def test_manifold_fit_transform(self, mock_draw): """""" Test manifold fit_transform method """""" X, y = make_s_curve(1000, random_state=888) manifold = Manifold(target=""auto"")  assert not hasattr(manifold, 'fit_time_')  Xp = manifold.fit_transform(X, y) assert Xp.shape == (X.shape[0], 2) ","def test_manifold_fit(self, mock_draw):",KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
Expire media files when ReportSession expires (#1128),"def __init__(self, file_id=None, content=None, mimetype=None, session_count=1): self._file_id = file_id self._content = content self._mimetype = mimetype self.session_count = session_count","def __init__(self, file_id=None, content=None, mimetype=None): self.file_id = file_id self.content = content self.mimetype = mimetype",KEEP KEEP KEEP KEEP ADD REP REP KEEP KEEP REP KEEP KEEP REP KEEP KEEP ADD ADD ADD,Add Parameter
Better error messages for st.cache (#1146),"def _read_from_mem_cache( mem_cache, key, allow_output_mutation, func_or_code, hash_funcs ): if key in mem_cache: entry = mem_cache[key]","def _read_from_mem_cache(mem_cache, key, allow_output_mutation, hash_funcs): if key in mem_cache: entry = mem_cache[key]",KEEP ADD REP KEEP KEEP ADD ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
nltk/corpus/reader/util.py,"def words(self, documents=None): return self._pos_reader.words(documents) def sents(self, documents=None): return self._pos_reader.sents(documents) def paras(self, documents=None): return self._pos_reader.paras(documents) def tagged_words(self, documents=None): return self._pos_reader.tagged_words(documents) def tagged_sents(self, documents=None): return self._pos_reader.tagged_sents(documents) def tagged_paras(self, documents=None): return self._pos_reader.tagged_paras(documents) def chunked_words(self, documents=None): return self._pos_reader.chunked_words(documents) def chunked_sents(self, documents=None): return self._pos_reader.chunked_sents(documents) def chunked_paras(self, documents=None): return self._pos_reader.chunked_paras(documents) def parsed_sents(self, documents=None): return self._mrg_reader.parsed_sents(documents)","def words(self, items=None): return self._pos_reader.words(items) def sents(self, items=None): return self._pos_reader.sents(items) def paras(self, items=None): return self._pos_reader.paras(items) def tagged_words(self, items=None): return self._pos_reader.tagged_words(items) def tagged_sents(self, items=None): return self._pos_reader.tagged_sents(items) def tagged_paras(self, items=None): return self._pos_reader.tagged_paras(items) def chunked_words(self, items=None): return self._pos_reader.chunked_words(items) def chunked_sents(self, items=None): return self._pos_reader.chunked_sents(items) def chunked_paras(self, items=None): return self._pos_reader.chunked_paras(items) def parsed_sents(self, items=None): return self._mrg_reader.parsed_sents(items)",KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP KEEP KEEP REP KEEP REP,Rename Parameter
ScriptRunner thread safety (#811),"def _on_source_file_changed(self):  if self.run_on_save: self._event_queue.enqueue(ScriptEvent.RERUN, self._report)",def maybe_handle_file_changed(self): if self.run_on_save: self.request_rerun() else: self.on_file_change_not_handled.send(),KEEP ADD REP KEEP KEEP REP REP DEL,Rename Method
Add ability to directionally erode mask,"def process(self,   detected_face: ""DetectedFace"", sub_crop_offset: Optional[np.ndarray], centering: Literal[""legacy"", ""face"", ""head""], predicted_mask: Optional[np.ndarray] = None) -> Tuple[np.ndarray, np.ndarray]:","def process(self, detected_face, sub_crop_offset,     centering, predicted_mask=None,):",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP REP REP,Change Return Type
updated with fully working Long division,"def subtract(a, b,b0, c, z,r, rj,n): qc = QuantumCircuit(a, b0, b, c, z, r) qc2 = QuantumCircuit(a, b0, b ,c, z,r)","def subtract(a, b,b0, c, z,r, rj): qc = QuantumCircuit(a , b, b0, c, z, r) qc2 = QuantumCircuit(a, b, b0, c, z,r)",KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP REP REP KEEP DEL KEEP KEEP KEEP KEEP KEEP KEEP REP REP REP KEEP,Add Parameter
GUI fixes,"def __init__(self, parent, tab_name, helptext, wait_time, command=None):","def __init__(self, parent, tab_name, helptext, waittime, command=None):",KEEP KEEP KEEP KEEP KEEP REP KEEP,Rename Parameter
Fix pep8 and pylint,"def insert_trials(experiment_name, points, raise_exc=True):","def insert_trials(experiment_name, points, cmdconfig=None, raise_exc=True):",KEEP KEEP KEEP DEL KEEP,Remove Parameter
transformed camelCase to snake_case test names (#3033),def test_empty_document(self):,def testEmptyDocument(self):,KEEP REP,Rename Method
added peter branch from https://github.com/peterpanstechland/donkeycar,"def start(self, rate_hz=10, max_loop_count=None, verbose=False):","def start(self, rate_hz=10, max_loop_count=None):",KEEP KEEP KEEP ADD REP,Add Parameter
updating,"def dict_fetch(src_dict, tgt_dict_or_keys):","def fetch_subdict(src_dict, tgt_dict_or_keys):",KEEP REP KEEP,Rename Method
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def raw(self, fileids=None, categories=None):","def raw(self, files=None, categories=None):",KEEP KEEP REP KEEP,Rename Parameter
"Add Registry, rework how Space is passed to algorithms (#833)","def has_depth( node: TreeNode[T], children: Sequence[TreeNode[T]] ) -> tuple[Sequence[TreeNode[T]], Sequence[TreeNode[T]] | None]:","def has_depth(node, children):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Change Return Type
Finished parsing of inception modules for GoogleNet.,"def get_imagenet(train_path, test_path, save_path, filename=None, class_idx_path=None):","def get_imagenet(train_path, test_path, save_path, filename=None):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Added doi attribute to Reference classes.,"def __init__(self, authors=None, title='', degree='', school='', year='', doi='', url=''): Reference.__init__(self, authors=authors, title=title, year=year, doi=doi, url=url)","def __init__(self, authors=None, title='', degree='', school='', year='', url=''): Reference.__init__(self, authors=authors, title=title, year=year, url=url)",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Deprecating data parameter from st.deck_gl_chart() (#22),"def marshall(proto, spec=None, **kwargs):","def marshall(proto, data=None, spec=None, **kwargs):",KEEP KEEP DEL KEEP KEEP,Remove Parameter
config: client.showTracebacks (#2770),"@parameterized.expand([(True,), (False,)]) def test_st_exception(self, show_tracebacks: bool):",def test_st_exception(self):,ADD ADD KEEP ADD ADD REP,Add Parameter
Fix Active Devices for plaidML. Add Supports PlaidML to Extractors,def get_vram_free(self):,@staticmethod def get_vram_free():,DEL KEEP REP,Add Parameter
remove deprecated function/method/class,"def __init__(self, operator, var_form, optimizer,","def __init__(self, operator, var_form, optimizer, operator_mode=None,",KEEP KEEP KEEP KEEP KEEP DEL,Remove Parameter
add date limit to rest api,"def __init__(self, limit=2000, date_limit=None, repeat=True, stream=True, fprefix='tweets',","def __init__(self, limit=2000, date_limit=None, repeat=True, fprefix='tweets',",KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Fix various codeQL recommendations (#5601),def handle_uncaught_app_exception(ex: BaseException) -> None:,def handle_uncaught_app_exception(e: BaseException) -> None:,KEEP REP KEEP KEEP KEEP,Rename Parameter
remove sorted and ordered data,"def predict(self, x, beta=None, breaks=None):","def predict(self, x, sorted_data=False, beta=None, breaks=None):",KEEP KEEP KEEP DEL KEEP KEEP,Remove Parameter
Add Livedata (#91),"def triplet_loss(anchor, positive, negative, margin, extra=False, scope=""triplet_loss""):","def triplet_loss(anchor, positive, negative, margin, extra=False):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Improvements to type util types (#4856),def is_pandas_styler(obj: object) -> TypeGuard[Styler]:,"def is_pandas_styler(obj: Any) -> ""TypeGuard[Styler]"":",KEEP KEEP REP KEEP REP,Change Return Type
Update matplotlib requirement,def _initiate_graph(self) -> None:,def initiate_graph(self):,KEEP ADD ADD REP,Rename Method
update evaluate.,def test_clp_data():,def clp_data_test():,KEEP REP,Rename Method
LSH Ensemble Optimal Partitioning (#79),"def benchmark_lshensemble(threshold, num_perm, num_part, m, index_data, query_data):","def benchmark_lshensemble(threshold, num_perm, num_part, l, index_data, query_data):",KEEP KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
Add options to Rxn.ensure_species to make resonance flexible,"def ensure_species(self, reactant_resonance=False, product_resonance=True):",def ensure_species(self):,KEEP ADD ADD REP,Add Parameter
Numeric gradient improvements (#177),"def numgrad(fn, x, h=None, replace_neg_inf=True):","def numgrad(fn, x, h=0.00001):",KEEP KEEP KEEP ADD REP,Add Parameter
Add fixed_initial option to variable builder. Setting fixed_initial=False makes the initial condition of the variable a degree of freedom. The default behavior of APM is fixed_initial=True.,"def CV(self, value=None, lb=None, ub=None, integer=False, fixed_initial=True, name=None):","def CV(self, value=None, lb=None, ub=None, integer=False, name=None):",KEEP KEEP KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
Added ability to change input channel size,"def resnet50_pspnet(n_classes,  input_height=384, input_width=576, channels=3):","def resnet50_pspnet(n_classes,  input_height=384, input_width=576):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Remove custom support template for `orion info`,def format_info(experiment): ,"def format_info(experiment, templates=None): """"""Render a string for all info of experiment  Parameters ---------- experiment: `orion.core.worker.experiment.Experiment` templates: dict Templates for all sections and titles  """"""",KEEP REP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Remove Parameter
Change 'event' to 'outcome'.,"def reorder(pmf, outcomes, alphabet, index=None):","def reorder(pmf, events, alphabet, index=None):",KEEP KEEP REP KEEP KEEP,Rename Parameter
New parser is now the default one.,"def _from_fullformlist_to_fullformsympy(self, pylist: list):","def _convert_pylist_to_sympymform(self, pylist: list):",KEEP REP KEEP KEEP,Rename Method
Remove MongoDB dependencies from tests/functional/commands,"def test_three_unrelated_w_a_wout_c(three_experiments_with_trials, capsys):","def test_three_unrelated_w_a_wout_c(clean_db, three_experiments_with_trials, capsys):",KEEP REP DEL KEEP,Remove Parameter
Changed methods of thermo and kinetics models to use scalars instead of numpy arrays.,"def getHeatCapacity(self, T):","def getHeatCapacity(self, Tlist):",KEEP KEEP REP,Rename Parameter
add web_controller example,def run(self):,"def run(self, time):",KEEP REP DEL,Remove Parameter
Apply reviewer comments,"def _eval_simplify(self, a, b, **kwargs): a = a.simplify(**kwargs).factor() b = b.simplify(**kwargs).factor()","def _eval_simplify(self, *args, **kwargs): a, b = (x.simplify(**kwargs).factor() for x in self.args)",KEEP KEEP ADD REP KEEP REP DEL KEEP REP REP REP REP DEL,Add Parameter
Adding tests.,"def evaluate(val_fn, x_test, y_test):","def evaluate(val_fn, X_test, Y_test):",KEEP KEEP REP REP,Rename Parameter
Added ability to change input channel size,"def unet_mini(n_classes, input_height=360, input_width=480, channels=3):","def unet_mini(n_classes, input_height=360, input_width=480):",KEEP KEEP KEEP ADD REP,Add Parameter
Smart Masks to Convert (#957),"def __init__(self, mask_type, output_size, coverage_ratio, **kwargs): super().__init__(mask_type, output_size, **kwargs) self._do_erode = self.config.get(""erosion"", 0) != 0 self._coverage_ratio = coverage_ratio  def process(self, detected_face, predicted_mask=None):   """""" Obtain the requested mask type and perform any defined mask manipulations.  Parameters ---------- detected_face: :class:`lib.faces_detect.DetectedFace` The DetectedFace object as returned from :class:`scripts.convert.Predictor`. predicted_mask: :class:`numpy.ndarray`, optional The predicted mask as output from the Faceswap Model, if the model was trained with a mask, otherwise ``None``. Default: ``None``.  Returns ------- mask: :class:`numpy.ndarray` The mask with all requested manipulations applied raw_mask: :class:`numpy.ndarray` The mask with no erosion/dilation applied """""" mask = self._get_mask(detected_face, predicted_mask)","def __init__(self, mask_type, output_size, predicted_available, **kwargs): super().__init__(mask_type, output_size, predicted_available, **kwargs) self.do_erode = self.config.get(""erosion"", 0) != 0 self.do_blend = self.config.get(""type"", None) is not None  def process(self, detected_face, predicted_mask=None):  mask = self.get_mask(detected_face, predicted_mask)",KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP DEL KEEP REP KEEP KEEP KEEP KEEP KEEP REP KEEP REP DEL DEL DEL DEL KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP REP KEEP,Rename Parameter
fix bug in using qubit slicing (cannot use list of list... need to iterate),"def build(self, qc, q, q_ancillas=None):","def build(self, qc, q, q_ancillas=None, params=None):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
rewrite method in callbacks,def _trigger_epoch(self):,def trigger_epoch(self):,KEEP REP,Rename Method
Integrated InputFile class into RMG-Py with the addition of pdepSettings and runSettings attributes.,"def enlarge(self, newObject, pdepSettings):","def enlarge(self, newObject):",KEEP KEEP ADD REP,Add Parameter
rename norm to norms,"def __init__(self, class_id, offset, text, confidence=1, norms=None):","def __init__(self, class_id, offset, text, confidence=1, norm=None):",KEEP KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
added variable input image dim,"def default_imu(num_outputs, num_imu_inputs, input_shape):","def default_imu(num_outputs, num_imu_inputs):",KEEP KEEP ADD REP,Add Parameter
Update to formulae 0.3.3 (#488),"def __init__(self, name, term, data, prior=None):","def __init__(self, name, term_dict, data, prior=None):",KEEP KEEP KEEP REP KEEP KEEP,Rename Parameter
[ImpliedTimescales] use joblib for parallel model estimation.,"def __init__(self, estimator, lags=None, nits=None, failfast=False, n_jobs=1):","def __init__(self, estimator, lags=None, nits=None, failfast=False):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
- Added methods to read propbank frames files and verbs.txt list file.,"def __init__(self, root, propfile, framefiles='', verbsfile=None,","def __init__(self, root, propfile, framefiles,",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Speed improvements (#522) (#523),"def main():  global ENABLE_DOCKER, ENABLE_CUDA, CUDA_VERSION, OS_VERSION check_system() check_python() check_pip()","def Main(): global ENABLE_DOCKER, ENABLE_CUDA, CUDA_Version, OS_Version Check_System() Check_Python() Check_PIP()",KEEP ADD REP KEEP KEEP KEEP REP REP REP REP REP,Rename Method
Add Laplacian Pyramid Loss,def _get_free_vram(self) -> List[int]:,def _get_free_vram(self) -> List[float]:,KEEP KEEP KEEP REP,Change Return Type
[MaskRCNN] more than one cfg.DATA.VAL,"def get_eval_dataflow(name, shard=0, num_shards=1):","def get_eval_dataflow(shard=0, num_shards=1):",KEEP ADD REP KEEP,Add Parameter
changing code to follow coding conventions,"def __get_name(self, line): return line[:self.__pos_of_colon(line)]","def __getName(self, line): return line[:self.__posOfColon(line)]",KEEP REP KEEP KEEP REP,Rename Method
Remove cache input mutation check (#823),"def _write_to_disk_cache(key, value):","def _write_to_disk_cache(key, value, args_mutated):",KEEP KEEP REP DEL,Remove Parameter
make dataflow idiomatic python container objects (fix #869) (#872),def __iter__(self): itrs = [v[0].__iter__() for v in self.df_lists],def get_data(self): itrs = [v[0].get_data() for v in self.df_lists],KEEP REP KEEP KEEP REP KEEP KEEP KEEP KEEP,Rename Method
Restructured pipeline and variable allocation in INI-Sim to reduce memory and computations.,@staticmethod def documentation():,def documentation(self):,ADD KEEP REP,Remove Parameter
Added partial support for mapping of tagsets.,"def _tagged_discourses_block_reader(self, stream, tagset=None):","def _tagged_discourses_block_reader(self, stream, simplify_tags=False):",KEEP KEEP KEEP REP,Rename Parameter
make dataflow idiomatic python container objects (fix #869) (#872),def __iter__(self): idxs = np.arange(self.__len__()),def get_data(self): idxs = np.arange(self.size()),KEEP REP KEEP KEEP REP,Rename Method
[coordinates.util]: Added a stride option to all coordinates.util transformer functions (for parametrization),"def cluster_regspace(data=None, dmin=-1, max_centers=1000, stride=1):","def cluster_regspace(data=None, dmin=-1, max_centers=1000):",KEEP KEEP KEEP ADD REP,Add Parameter
allow for multiple targets in the optimization,"def optimize(target_label, reactionModel, rmg, reaction_system_index, error, orig_observable):","def optimize(target_label, reactionModel, rmg, reaction_system_index, error, orig_conv):",KEEP KEEP KEEP KEEP KEEP KEEP REP,Rename Parameter
Remove MongoDB dependencies from tests/unittests/core/io,"def test_operation_remove_fails(monkeypatch, operation, pdatabase):","def test_operation_remove_fails(monkeypatch, operation, clean_test, database):",KEEP KEEP KEEP REP DEL,Remove Parameter
make InputSource subclass methods private,def _get_input_tensors(self):,def get_input_tensors(self):,KEEP REP,Rename Method
added error codes and fixed label Case issue,def dateFromString(timeString):,def dateFromString(time_string):,KEEP REP,Rename Parameter
"Adjust storage to (trial.id, experiment.id) index","def update_trial( self, trial=None, uid=None, experiment_uid=None, where=None, **kwargs ):","def update_trial(self, trial=None, uid=None, where=None, **kwargs):",KEEP ADD REP KEEP KEEP ADD KEEP ADD REP,Add Parameter
Update WikiCorpus tokenization. Fix #1534 (#1537),"def process_article(args, tokenizer_func=tokenize, token_min_len=TOKEN_MIN_LEN, token_max_len=TOKEN_MAX_LEN, lower=True):",def process_article(args):,KEEP ADD ADD ADD ADD REP,Add Parameter
Implemented `streamlit run` as a mechanism to run-on-save/rerun with errors.,"def print_usage(args):  USAGE = """"""","def print_usage():  usage = """"""",KEEP REP KEEP REP KEEP KEEP,Add Parameter
fix pylint errors,def get_chem_operator_config(chemistry_operator_name):,def get_chemistry_operator_configuration(chemistry_operator_name):,KEEP REP,Rename Method
"Extract: Expose ""allow_growth"" option","def __init__(self, model_path, allow_growth): super().__init__(""MTCNN-PNet"", model_path, allow_growth=allow_growth)","def __init__(self, model_path): super().__init__(""MTCNN-PNet"", model_path)",KEEP KEEP ADD REP KEEP ADD REP,Add Parameter
Smart Masks to Convert (#957),"def _patch_faces(self, queue_in, queue_out, sample_size): """""" Patch faces.  Run the convert process on the swapped faces and return the patched faces.  patch_queue_in: :class:`queue.Queue` The input queue for the patching process queue_out: :class:`queue.Queue` The output queue from the patching process sample_size: int The number of samples to be displayed  Returns ------- list The swapped faces patched with the selected convert settings """"""","def patch_faces(self, queue_in, queue_out, sample_size): ",KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
Avoid OrionState in hacked_exp fixture to fix storage fixture issue,"def test_register_duplicate_lies_with_different_results(producer, storage, random_dt):","def test_register_duplicate_lies_with_different_results(producer, random_dt):",KEEP KEEP ADD KEEP,Add Parameter
"* Add support for multi-dimensional model input and making the x, y interface symmetrical on the model / training interface: (#707)","def output_shapes(self) -> Optional[Dict[str, tf.TensorShape]]:",def output_shapes(self):,KEEP ADD ADD ADD REP,Change Return Type
fix Image format issues (#310),def prepare_mxnet(x):,"def prepare_mxnet(x, modality):",KEEP REP DEL,Remove Parameter
Adapt codebase to new name Orion (#61),"def test_remove_many_default(self, exp_config, database, orion_db):","def test_remove_many_default(self, exp_config, database, moptdb):",KEEP KEEP KEEP KEEP REP,Rename Parameter
"Using measurements.dbs rather than overrides.dbs so APM deletes the file after reading. This prevents growing the dbs file on the remote server with repeated solves. This also allows the GUI access to overrides.dbs. Further, the info file is only written on cyclecount < 1 (not successful solves) to avoid redundant file writing and growing of remote server files. Since there is not currently a way to change variable classifications, this shouldn't have any impact.",def generate_dbs_file(self): '''Write options to measurements.dbs file so it gets automatically deleted to prevent file build-up on the server,def generate_overrides_dbs_file(self): '''Write options to overrides.dbs file,KEEP REP KEEP KEEP KEEP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Rename Method
"updates, can load estimator model and replicate",def _test_epoch(sess):,"def _test_epoch(sess, epoch=0):",KEEP REP DEL,Remove Parameter
Model updates,"def _build_decoders( self, inputs: Dict[str, Union[List[keras.models.Model], keras.models.Model]] ) -> Dict[str, keras.models.Model]:","def _build_decoders(self, inputs):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Change Return Type
Better error messages for st.cache (#1146),"def _read_from_cache( mem_cache, key, persist, allow_output_mutation, func_or_code, hash_funcs=None ): """"""Read a value from the cache.  Our goal is to read from memory if possible. If the data was mutated (hash changed), we show a warning. If reading from memory fails, we either read from disk or rerun the code.","def _read_from_cache(mem_cache, key, persisted, allow_output_mutation, hash_funcs=None): """""" Read the value from the cache. Our goal is to read from memory if possible. If the data was mutated (hash changed), we show a warning. If reading from memory fails, we either read from disk or rerun the code.",KEEP ADD REP KEEP REP KEEP ADD REP REP REP REP KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
Major refactoring to prepare splitting in modules,"def load_templates(self, p):",def load_templates(self):,KEEP ADD REP,Add Parameter
Add model for picking best gazetteer result,"def format_geonames_old(self, res, searchterm = None):","def format_geonames(self, res, searchterm = None):",KEEP REP KEEP KEEP KEEP KEEP,Rename Method
add unittest for HHL using qasm_simulator,def test_hhl_negative_eigs_sv(self):,def test_hhl_negative_eigs(self):,KEEP REP,Rename Method
Remove unittest dependency and test fixtures (#904),"def test_manifold_warning(self, algorithm):",def test_manifold_warning(self):,KEEP ADD REP,Add Parameter
Add support for all other (except KerasLatent) models: (#884),"def __init__(self, interpreter: Interpreter = KerasInterpreter(), input_shape: Tuple[int, ...] = (120, 160, 3), seq_length=20, num_outputs=2): self.num_outputs = num_outputs self.seq_length = seq_length super().__init__(interpreter, input_shape) self.img_seq: List[np.ndarray] = []  def seq_size(self) -> int: return self.seq_length  def create_model(self): return build_3d_cnn(self.input_shape, s=self.seq_length, num_outputs=self.num_outputs)  def compile(self): self.interpreter.compile(loss='mse', optimizer=self.optimizer)  def x_transform(self, records: Union[TubRecord, List[TubRecord]]) -> XY:  assert isinstance(records, list), 'List[TubRecord] expected' assert len(records) == self.seq_length, \ f""Record list of length {self.seq_length} required but "" \ f""{len(records)} was passed"" img_arrays = [rec.image(cached=True) for rec in records] return np.array(img_arrays)  def x_translate(self, x: XY) -> Dict[str, Union[float, np.ndarray]]: """""" Translates x into dictionary where all model input layer's names must be matched by dictionary keys. """""" img_arr = x return {'img_in': img_arr}  def x_transform_and_process( self, record: Union[TubRecord, List[TubRecord]], img_processor: Callable[[np.ndarray], np.ndarray]) -> XY: """""" Transforms the record sequence into x for training the model to x, y. """""" img_seq = self.x_transform(record) assert isinstance(img_seq, np.ndarray), 'Expected np.ndarray'  x_process = [img_processor(img) for img in img_seq] return np.array(x_process)  def y_transform(self, records: Union[TubRecord, List[TubRecord]]) -> XY:  assert isinstance(records, list), 'List[TubRecord] expected' angle = records[-1].underlying['user/angle'] throttle = records[-1].underlying['user/throttle'] return angle, throttle  def y_translate(self, y: XY) -> Dict[str, Union[float, List[float]]]: assert isinstance(y, tuple), 'Expected tuple' return {'outputs': list(y)}  def run(self, img_arr, other_arr=None): if img_arr.shape[2] == 3 and self.input_shape[2] == 1: img_arr = dk.utils.rgb2gray(img_arr)  while len(self.img_seq) < self.seq_length: self.img_seq.append(img_arr)  self.img_seq = self.img_seq[1:] self.img_seq.append(img_arr) new_shape = (self.seq_length, *self.input_shape) img_arr = np.array(self.img_seq).reshape(new_shape) img_arr_norm = normalize_image(img_arr) return self.inference(img_arr_norm, other_arr)  def interpreter_to_output(self, interpreter_out) \ -> Tuple[Union[float, np.ndarray], ...]: steering = interpreter_out[0] throttle = interpreter_out[1] return steering, throttle  def output_shapes(self):  img_shape = self.get_input_shapes()[0][1:]  shapes = ({'img_in': tf.TensorShape(img_shape)}, {'outputs': tf.TensorShape([self.num_outputs])}) return shapes   class KerasLatent(KerasPilot): def __init__(self, interpreter: Interpreter = KerasInterpreter(), input_shape: Tuple[int, ...] = (120, 160, 3), num_outputs: int = 2): self.num_outputs = num_outputs super().__init__(interpreter, input_shape)  def create_model(self): return default_latent(self.num_outputs, self.input_shape)  def compile(self): loss = {""img_out"": ""mse"", ""n_outputs0"": ""mse"", ""n_outputs1"": ""mse""} weights = {""img_out"": 100.0, ""n_outputs0"": 2.0, ""n_outputs1"": 1.0} self.interpreter.compile(optimizer=self.optimizer, loss=loss, loss_weights=weights)","def __init__(self, input_shape=(120, 160, 3), seq_length=20, num_outputs=2): super().__init__() self.input_shape = input_shape self.model = build_3d_cnn(input_shape, s=seq_length, num_outputs=num_outputs) self.seq_length = seq_length self.img_seq = []  def compile(self): self.model.compile(loss='mean_squared_error', optimizer=self.optimizer, metrics=['accuracy'])  def inference(self, img_arr, other_arr):  if img_arr.shape[2] == 3 and self.input_shape[2] == 1: img_arr = dk.utils.rgb2gray(img_arr)  while len(self.img_seq) < self.seq_length: self.img_seq.append(img_arr)  self.img_seq = self.img_seq[1:] self.img_seq.append(img_arr)  img_arr = np.array(self.img_seq).reshape((1, self.seq_length, *self.input_shape)) outputs = self.model([img_arr]) steering = outputs[0][0].numpy() throttle = outputs[0][1].numpy() return steering, throttle",KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP KEEP KEEP KEEP ADD ADD REP REP KEEP ADD ADD ADD REP REP KEEP ADD ADD ADD ADD REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP KEEP ADD ADD ADD REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP ADD ADD ADD REP REP REP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD REP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP KEEP KEEP REP KEEP KEEP REP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD,Add Parameter
Python DTM changes. SeqCorpus removed. LDAVis support. Notebook update (#831),"def lda_seq_infer(self, corpus, topic_suffstats, gammas, lhoods, iter_, lda_inference_max_iter, chunksize):","def lda_seq_infer(self, seq_corpus, topic_suffstats, gammas, lhoods, iter_, lda_inference_max_iter):",KEEP KEEP REP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Add type annotations for layouts (#4683),"def columns(self, spec: SpecType) -> List[""DeltaGenerator""]:","def columns(self, spec: SpecType):",KEEP KEEP KEEP ADD ADD REP,Change Return Type
reintroduce max_dist to FastSS query,"def query(self, word, max_dist=None):","def query(self, word):",KEEP KEEP ADD REP,Add Parameter
Switch all testing to pytest.,"@pytest.mark.parametrize('q', np.arange(-2, 2.5, 0.5)) def test_tsallis_entropy_1(q):",def test_tsallis_entropy_1():,ADD ADD ADD ADD KEEP REP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_maintain_sparsity_with_num_best(self):,def testMaintainSparsityWithNumBest(self):,KEEP REP,Rename Method
add optional stopwords to the wrapped pattern lemmatizer,"def lemmatize(content, allowed_tags=re.compile('(NN|VB|JJ|RB)'), light=False, stopwords=frozenset()):","def lemmatize(content, allowed_tags=re.compile('(NN|VB|JJ|RB)'), light=False):",KEEP KEEP KEEP ADD REP,Add Parameter
Beginning of test harness.,"def talk_to_mitie(text, ner_model):",def talk_to_mitie(text):,KEEP ADD REP,Add Parameter
refactoring,"def _euclidean_dissim(a, b):","def _euclidean_dissim_num(a, b):",KEEP REP KEEP,Rename Method
Api updates (#189),"def get_parents(self, child_name):","def parent_names(self, child_name):",KEEP REP KEEP,Rename Method
Added ability to change input channel size,"def vgg_unet(n_classes, input_height=416, input_width=608, encoder_level=3, channels=3):","def vgg_unet(n_classes, input_height=416, input_width=608, encoder_level=3):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
"[MaskRCNN] some renames to avoid the name of ""COCO""","def _build_predictor(self, idx): return self.trainer.get_predictor(self._in_names, self._out_names, device=idx)","def _build_coco_predictor(self, idx): graph_func = self.trainer.get_predictor(self._in_names, self._out_names, device=idx) return lambda img: detect_one_image(img, graph_func)",KEEP REP KEEP REP DEL KEEP KEEP KEEP DEL DEL DEL DEL DEL,Rename Method
Fixes binary ROCAUC with decision function only models bug (#533),def test_binary_probability_decision(self):,def test_binary_rocauc(self):,KEEP REP,Rename Method
"Clean up some Python module names (vega_lite, for example) and do some linting.","def _get_first_match(available_names, wanted_names):","def get_first_match(available_names, wanted_names):",KEEP REP KEEP,Rename Method
fix back-compatibility of LMDBDataPoint (#215),"def __init__(self, *args, **kwargs):","def __init__(self, lmdb_data):",KEEP KEEP ADD REP,Remove Parameter
transformed camelCase to snake_case test names (#3033),def test_generator(self):,def testGenerator(self):,KEEP REP,Rename Method
exposed top/bottom crop to config for categorical and linear,"def __init__(self, num_outputs=2, input_shape=(120, 160, 3), roi_crop=(0, 0), *args, **kwargs):","def __init__(self, num_outputs=2, input_shape=(120, 160, 3), *args, **kwargs):",KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD KEEP KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_num_best(self):,def testNumBest(self):,KEEP REP,Rename Method
Remove MongoDB dependencies from tests/functional/commands,"def test_exp_name_with_child(three_experiments, monkeypatch, capsys):","def test_exp_name_with_child(clean_db, three_experiments, monkeypatch, capsys):",KEEP REP DEL KEEP KEEP,Remove Parameter
add more parameters to demos and fix python2.6 compatibility issues,"def demo_subjectivity(trainer, save_analyzer=False, n_instances=None, output=None):","def demo_subjectivity(trainer, save_analyzer=False):",KEEP KEEP ADD ADD REP,Add Parameter
Allow to map from any Wordnet version,"def map_to_many(self, version=""wordnet""): sensekey_map1 = self.index_sense(version)","def map_to_many(self): sensekey_map1 = self.index_sense(""wordnet"")",KEEP ADD REP KEEP KEEP REP,Add Parameter
add strict mode in ThreadedMapData (#139),"def __init__(self, ds, nr_thread, map_func, buffer_size=200, strict=False):","def __init__(self, ds, nr_thread, map_func, buffer_size=200):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Added datasets for testing,"def __init__(self, lag=1, reversible=True, count_mode='sliding', sparse=False, connectivity='largest', dt_traj='1 step', maxiter=1000000, maxerr=1e-8):","def __init__(self, lag=1, reversible=True, sparse=False, connectivity='largest', dt_traj='1 step', maxiter=1000000, maxerr=1e-8):",KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
refactoring,def resnext101(**kwargs):,def resnet101(**kwargs):,KEEP REP,Rename Method
Can now also load species dictionary when loading Chemkin file.,"def loadChemkinFile(path, dictionaryPath=None):",def loadChemkinFile(path):,KEEP ADD REP,Add Parameter
[TRAMMBAR] added missing **kwargs to TRAM.estimate,"def estimate(self, X, equilibrium=None, **params):","def estimate(self, X):",KEEP KEEP ADD ADD REP,Add Parameter
Extract filter: Allow saving of filtered images,"def __init__(self, min_scale: float, max_scale: float, distance: float, save_output: bool) -> None: logger.debug(""Initializing %s: (min_scale: %s, max_scale: %s, distance: %s, "" ""save_output: %s)"", self.__class__.__name__, min_scale, max_scale, distance, save_output)","def __init__(self, min_scale: float, max_scale: float, distance: float): logger.debug(""Initializing %s: (min_scale: %s, max_scale: %s, distance: %s)"", self.__class__.__name__, min_scale, max_scale, distance)",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD KEEP KEEP KEEP KEEP ADD REP,Add Parameter
change doclevelrelationships evaluator to be more flexible. Accept ignoring cases (None),def test_DocumentLevelRelationEvaluator_arbitrary_relation_accept_fun_order_matters(self):,def test_DocumentLevelRelationEvaluator_arbitrary_relation_equiv_fun_order_matters(self):,KEEP REP,Rename Method
Add draw param support to Movidius engine.,"def __init__(self, service_name, engine, comm_config, draw=False):","def __init__(self, service_name, engine, comm_config):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
updated make_vocab.py to allow printing word counts,"def make_vocab(filenames, max_vocab_size=-1, newline_token=None, return_type=""list"", return_count=False):","def make_vocab(filenames, max_vocab_size=-1, newline_token=None, return_type=""list""):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Switch to using memory-mapped files when reading. (#691),"def __init__(self, catalog_path, read_only=False, start_index=0):","def __init__(self, catalog_path, start_index=0):",KEEP KEEP KEEP ADD KEEP,Add Parameter
"move auto_resize and auto_hermitian parameters to HHL algorithm, updates to unittest","def __init__(self, matrix=None, vector=None):","def __init__(self, matrix=None, vector=None, auto_hermitian=False, auto_resize=False):",KEEP KEEP KEEP REP DEL DEL,Remove Parameter
Expose Augmentation Options to config,"def __init__(self, model, images, batch_size, configfile):","def __init__(self, model, images, batch_size):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
"Add Registry, rework how Space is passed to algorithms (#833)","def get_nodes_at_depth(self: Self, depth: int) -> list[Self]:","def get_nodes_at_depth(self, depth):",KEEP ADD ADD ADD ADD REP REP,Change Return Type
Adapt codebase to new name Orion (#61),"def test_duplicate_key_error(self, monkeypatch, orion_db, exp_config):","def test_duplicate_key_error(self, monkeypatch, moptdb, exp_config):",KEEP KEEP KEEP REP KEEP,Rename Parameter
[serialization_mixin] get parameters of all estimators in hierarchy.,@classmethod def _get_model_param_names(cls):,def _get_model_param_names(self):,ADD KEEP REP,Rename Parameter
borderMode in STN,"def sample(img, coords, borderMode):","def sample(img, coords):",KEEP KEEP ADD REP,Add Parameter
Minor redesign of the corpus readers.  Instead of using 'items' or,"def tagged_sents(self, files=None):","def tagged_sents(self, documents=None, categories=None):",KEEP KEEP REP DEL,Remove Parameter
GUI Updates (#940),def _clear_image_cache(self): ,def clear_image_cache(self): ,KEEP REP,Rename Method
BOLFI + NUTS (#135),"def _unnormalized_likelihood(self, x): return np.exp(self._unnormalized_loglikelihood(x))","def _unnormalized_likelihood_density(self, x): return np.exp(self._unnormalized_loglikelihood_density(x))",KEEP REP KEEP KEEP REP,Rename Method
Force CONFIGURATION static prop for pluggable classes,def __init__(self): super().__init__(copy.deepcopy(SVM_Classical.CONFIGURATION)),"def __init__(self, configuration=None): super().__init__(configuration or copy.deepcopy(SVM_Classical.SVM_Classical_CONFIGURATION))",KEEP REP REP DEL DEL DEL,Remove Parameter
"Revert ""Merge remote-tracking branch 'upstream/develop' into feature/i9e""",def test_add_styled_rows_to_unstyled_rows(self):,"@parameterized.expand([ ('dataframe', 'data_frame'), ('table', 'table') ]) def test_add_styled_rows_to_unstyled_rows(self, element, proto):",DEL DEL DEL DEL DEL DEL KEEP REP DEL DEL,Remove Parameter
Change drivers import and refactor driver discovery,def __init__(self): super().__init__()  @staticmethod def check_driver_valid(): return True,"def __init__(self, configuration=None): """""" Args: configuration (dict): driver configuration """""" super(HDF5Driver, self).__init__(configuration)",KEEP REP REP REP REP REP REP REP REP DEL DEL DEL,Remove Parameter
Smart Training Implementation (#914),"def _set_tensorboard(self): """""" Set up Tensorboard callback for logging loss.  Bypassed if command line option ""no-logs"" has been selected.  Returns ------- dict: 2 Dictionary keys of ""a"" and ""b"" the values of which are the :class:`tf.keras.callbacks.TensorBoard` objects for the respective sides. """""" if self._model.training_opts[""no_logs""]:","def set_tensorboard(self):  if self.model.training_opts[""no_logs""]:",KEEP ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP ADD KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Rename Method
Release 0.43.0 (#1044),"def __init__(self, ioloop, script_path, script_argv, is_preheat):","def __init__(self, ioloop, script_path, script_argv):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
"Reorder var/param creation function arguments to be consistent: value, [lb,ub,integer,] name. Name is always last since it is not intended to be used very often.","def MV(self, value=None, lb=None, ub=None, integer=False, name=None):","def FV(self, name=None,value=None, lb=None, ub=None, integer=False):",KEEP REP REP KEEP KEEP ADD REP,Rename Method
Use PassManager in QuantumInstance transpile (#1382),"def transpile(self, circuits: Union[QuantumCircuit, List[QuantumCircuit]]) -> List[QuantumCircuit]:","def transpile(self, circuits):",KEEP KEEP ADD ADD ADD ADD REP,Change Return Type
fix missing underscore before function calls.,def test__modified_precision(self):,def test_modified_precision(self):,KEEP REP,Rename Method
Added entry frame to GUI to choose percentile for normalization. Fixed bug in softmax activation function.,"def linear_activation(self, impulse, time, updates):","def relu(self, impulse, time, updates):",KEEP REP KEEP KEEP KEEP,Rename Method
Fix code trying to iterate NoneType (#1414),"def _optimize(self, optimizer, use_bound):","def _optimize(self, optimizer):",KEEP KEEP ADD REP,Add Parameter
Check if an estimator is already fitted before calling fit (#925),"def __init__( self, model, ax=None, fig=None, classes=None, is_fitted=""auto"", **kwargs ):","def __init__(self, model, ax=None, fig=None, classes=None, **kwargs):",KEEP ADD REP KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
Added `converters` argument to some optimization algorithms (#1260),"def __init__(self, min_eigen_solver: MinimumEigensolver, penalty: Optional[float] = None, converters: Optional[Union[QuadraticProgramConverter, List[QuadraticProgramConverter]]] = None) -> None:","def __init__(self, min_eigen_solver: MinimumEigensolver, penalty: Optional[float] = None ) -> None:",KEEP KEEP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD REP REP KEEP KEEP,Add Parameter
setup.py: implement logging,def _check_missing_dep(self) -> None:,def check_missing_dep(self):,KEEP ADD ADD REP,Rename Method
Fix linting issues,def _has_named_children(exp): return any(node.name != exp.name for node in exp.node),"def _has_named_children(exp, experiments): return any(node.name != exp.name for node in exp.node)",KEEP REP DEL KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Remove Parameter
model_refactor (#571) (#572),"def __init__(self, parent, selected_id, helptext): logger.debug(""Initializing: %s: (parent, %s, selected_id: %s, helptext: '%s')"", self.__class__.__name__, parent, selected_id, helptext) super().__init__(parent) self.pack(side=tk.TOP, padx=5, pady=5, expand=True, fill=tk.X, anchor=tk.N)  self.session = None  ","def __init__(self, parent, filename, selected_id, helptext, scaling_factor): ttk.Frame.__init__(self, parent) self.pack(side=tk.TOP, padx=5, pady=5, expand=True, fill=tk.X, anchor=tk.N)  self.filename = filename self.loaded_data = None",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP REP REP KEEP KEEP KEEP KEEP KEEP KEEP KEEP REP DEL DEL DEL KEEP KEEP,Remove Parameter
Handle properly all types in config during branch,"def test_try_resolve_default(self, dimension_conflict):","def test_try_resolve_default(self, missing_dimension_conflict):",KEEP KEEP REP,Rename Parameter
Remove MongoDB dependencies from tests/functional/commands,"def test_two_unrelated_w_trials_wout_ac(unrelated_with_trials, capsys):","def test_two_unrelated_w_trials_wout_ac(clean_db, unrelated_with_trials, capsys):",KEEP REP DEL KEEP,Remove Parameter
nltk/corpus/reader/util.py,"def chunked_sents(self, documents=None):","def chunked_sents(self, items=None):",KEEP KEEP REP,Rename Parameter
Added partial support for mapping of tagsets.,"def _tagged_turns_block_reader(self, stream, tagset=None): return self._tagged_discourses_block_reader(stream, tagset)[0]","def _tagged_turns_block_reader(self, stream, simplify_tags=False): return self._tagged_discourses_block_reader(stream, simplify_tags)[0]",KEEP KEEP KEEP REP KEEP KEEP REP,Rename Parameter
new age and gender val,"def get_ga(self, aligned):","def get_gender(self, aligned): input_blob = np.expand_dims(aligned, axis=0) data = mx.nd.array(input_blob) db = mx.io.DataBatch(data=(data,)) self.gender_model.forward(db, is_train=False) ret = self.gender_model.get_outputs()[0].asnumpy().flatten() ret = np.argmax(ret) return ret",KEEP REP KEEP DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL DEL,Rename Method
Refactore ImageDataGenerator to accept rotation_angle,"def test_should_produce_augmented_sample_with_time_delay(self): generator = ImageDataGenerator(time_delay=3, rotation_angle=50, horizontal_flip=True) data = np.random.rand(1, 3, 10, 10, 3) augmented_data = get_next_batch(generator, data) self.assertFalse(np.array_equal(data, augmented_data))","def test_should_produce_augmented_sample_without_time_delay(self): generator = ImageDataGenerator(time_delay=3, rotation_range=0.5, horizontal_flip=True) data = np.random.rand(2, 3, 64, 64, 1) augmented_data = get_next_batch(generator, data) self.assertFalse(np.array_equal(data, augmented_data)) ",KEEP REP KEEP KEEP KEEP REP KEEP KEEP KEEP REP KEEP REP REP REP KEEP KEEP KEEP KEEP KEEP KEEP,Rename Method
formatting,"def train(self, data, weights, penalty=False, quantum_instance=None, shots=None):","def train(self, data, weights, penalty=False):",KEEP KEEP KEEP KEEP ADD ADD REP,Add Parameter
options,"def __init__(self, image, classes, training_options=None): if training_options is None: training_options = { ""anchor_target"": { ""allowed_border"": 0, ""clobber_positives"": False, ""negative_overlap"": 0.3, ""positive_overlap"": 0.7, }, ""object_proposal"": { ""maximum_proposals"": 300, ""minimum_size"": 16, ""stride"": 16 }, ""proposal_target"": { ""fg_fraction"": 0.5, ""fg_thresh"": 0.7, ""bg_thresh_hi"": 0.5, ""bg_thresh_lo"": 0.1, } } ","def __init__(self, image, classes):",KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP,Add Parameter
rpn regression loss,"def __init__(self, features, image_shape, delta=3, scales=None, ratios=None, stride=16, **kwargs): self.delta = delta","def __init__(self, features, image_shape, scales=None, ratios=None, stride=16, **kwargs):",KEEP KEEP KEEP KEEP ADD KEEP KEEP KEEP KEEP ADD ADD ADD,Add Parameter
Changed treebank corpus to use TreebankTaggedTokenizer.,"def tokenize(self, token, addlocs=False, addcontexts=False):","def tokenize(self, token, addlocs=False):",KEEP KEEP KEEP ADD REP,Add Parameter
"Validation, reconstructing trees from outputs","def process_das(self, das):","def process_batch(self, das):",KEEP REP KEEP,Rename Method
Update metadata during config consolidation,"def test_comparison(self, yaml_config, yaml_diff_config, script_path):","def test_comparison(self, yaml_config, yaml_diff_config):",KEEP KEEP KEEP ADD REP,Add Parameter
Prepared branch for merge with master.,"def get_eventframe_sequence(xaddr, yaddr, timestamps, shape, frame_width):","def get_eventframe_sequence(xaddr, yaddr, timestamps, pol, is_x_first, is_x_flipped, is_y_flipped, shape, data_format, frame_width):",KEEP KEEP KEEP KEEP DEL DEL DEL DEL KEEP DEL KEEP,Remove Parameter
transformed camelCase to snake_case test names (#3033),def test_identity(self):,def testIdentity(self):,KEEP REP,Rename Method
docs,"def _init(self, sess):","def init(self, sess):",KEEP REP KEEP,Rename Method
Fix all functional tests to work with manual res,"def test_auto_resolution_not_force_prompt(init_full_x_full_y, monkeypatch):","def test_auto_resolution_forces_prompt(init_full_x_full_y, monkeypatch):",KEEP REP KEEP,Rename Method
moved kprototypes to its own file,"def _labels_cost(X, centroids):","def _labels_cost_kmodes(X, centroids):",KEEP REP KEEP,Rename Method
Remove MongoDB dependencies from tests/unittests/core/worker/test_producer.py,"def test_naive_algo_not_trained_when_all_trials_completed(producer, random_dt):","def test_naive_algo_not_trained_when_all_trials_completed( producer, database, random_dt ):",KEEP REP REP DEL DEL DEL,Remove Parameter
Check if an estimator is already fitted before calling fit (#925),"def __init__(self, model, ax=None, is_fitted=""auto"", **kwargs):","def __init__(self, model, ax=None, **kwargs):",KEEP KEEP KEEP KEEP ADD KEEP,Add Parameter
[coor/featurizer] added feature sin/cos hstack for angle based features. Fixed potential,"def add_backbone_torsions(self, deg=False, cossin=False):","def add_backbone_torsions(self, deg=False):",KEEP KEEP ADD REP,Add Parameter
Make FSObserver watch only the main file by default. And add option to,"def _initialize_observer_with_fallback(self, source_file_path):","def _initialize_observer_with_fallback(self, path_to_observe):",KEEP KEEP REP,Rename Parameter
"updated module interfaces, put  in  rather than as an argument to __init__","def __init__(self, decoder_state_size, hparams=None): ConnectorBase.__init__(self, decoder_state_size, hparams)","def __init__(self, decoder_state_size, hparams=None, name=""mlp_connector""): ConnectorBase.__init__(self, decoder_state_size, hparams, name)",KEEP KEEP KEEP REP DEL KEEP KEEP REP DEL,Remove Parameter
"Simplify tests suite, remove spy_phase and related functions (#886)","def assert_dim_type_supported(self, test_space: dict):","def assert_dim_type_supported(self, mocker, num, attr, test_space):",KEEP KEEP REP REP DEL DEL,Remove Parameter
Fix bugs in EvolutionaryES and adjust test-suite,"def __init__(self, evolution_es, budgets, repetition_id):","def __init__(self, evolution_es, budgets, repetition_id, space):",KEEP KEEP KEEP KEEP REP DEL,Remove Parameter
[Angelica] Add featureextractor and imageprocessor to sphinx docs.,"def _extract_hog_feature(self, params, image):","def extract_hog_feature(self, params, image):",KEEP REP KEEP KEEP,Rename Method
Added AffineAdapter class with necessary changes and pytests,"def __init__(self, in_filters, out_filters):",def __init__(self):,KEEP ADD ADD REP,Add Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def __init__(self, fileid, sentnum, wordnum, tagger, roleset,","def __init__(self, filename, sentnum, wordnum, tagger, roleset,",KEEP KEEP REP KEEP KEEP KEEP KEEP,Rename Parameter
play a bit with the printing of Path鈥檚,"def str_token_only(self, token_to_string_fun=lambda token: token.word): return __class__.__NODE_SEPARATOR.join(n.str_token_only(token_to_string_fun) for n in self.middle)",def str_token_only(self): return __class__.__NODE_SEPARATOR.join(n.str_token_only() for n in self.middle),KEEP ADD ADD ADD REP KEEP REP KEEP KEEP KEEP KEEP,Add Parameter
transformed camelCase to snake_case test names (#3033),def test_custom_scorer(self):,def testCustomScorer(self):,KEEP REP,Rename Method
improve the backward capability and add more tests,"def simplify(self, copy=False):",def simplify(self):,KEEP ADD REP,Add Parameter
BOLFI + NUTS (#135),"def __init__(self, model, target=None, outputs=None, batch_size=1, initial_evidence=None, update_interval=10, bounds=None, target_model=None,","def __init__(self, model, target=None, outputs=None, batch_size=1, n_acq=150, initial_evidence=10, update_interval=10, bounds=None, target_model=None,",KEEP KEEP KEEP KEEP KEEP KEEP REP DEL KEEP KEEP KEEP,Remove Parameter
[#60] regex optimize,"def num_lower_chars(self, str):","def n_lower_chars(self, str):",KEEP REP KEEP,Rename Method
Improve lr_scheduler (add engine),"def factory_scheduler(optimizer, engine=None):",def factory_scheduler(optimizer):,KEEP ADD REP,Add Parameter
Added memory efficient forward pass and backprop for inverse pass (implementation_inv),"def __init__(self, Fm, Gm=None, implementation=1, keep_input=False, implementation_inv=2):","def __init__(self, Fm, Gm=None, implementation=1, keep_input=False):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
[MaskRCNN] parallel offline evaluation; NORM=None,"def paste_mask(box, mask, shape):","def fill_full_mask(box, mask, shape):",KEEP REP KEEP KEEP,Rename Method
Bugfix for coordinations in delex instructions,"def _delex_texts(self): """"""Delexicalize texts in the buffers and save them separately in the member variables, along with the delexicalization instructions used for the operation."""""" self._delexed_texts = [] self._absts = [] for text_idx, (text, da) in enumerate(zip(self._sents, self._das)):","def _delex_texts(self, subrange):  out = [] for idx, (text, da) in enumerate(zip(self._sents[subrange], self._das[subrange]), start=subrange.start):",KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP REP REP KEEP KEEP ADD ADD ADD KEEP REP KEEP KEEP KEEP REP REP DEL,Remove Parameter
added more tests,"def has_value(self, to_test): return self.values.__contains__(to_test)","def has_value(self, toTest): return self.values.__contains__(toTest)",KEEP KEEP REP KEEP REP,Rename Parameter
#24: add option for custom dissimilarity function; some refactoring,"def __init__(self, n_clusters=8, max_iter=100, num_dissim=euclidean_dissim, cat_dissim=matching_dissim, init='Huang', n_init=10, gamma=None, verbose=0):","def __init__(self, n_clusters=8, gamma=None, init='Huang', n_init=10, max_iter=100, verbose=0):",KEEP KEEP KEEP ADD ADD REP KEEP KEEP REP KEEP,Add Parameter
ObjectProposal layer,"def __init__(self, maximum_proposals=300, min_size=16, stride=16, **kwargs):","def __init__(self, maximum_proposals=300, **kwargs): self.output_dim = (None, None, 4)",KEEP KEEP KEEP REP REP REP DEL DEL DEL,Add Parameter
"renamed parse_ methods to read_ or load_, resolves issue 656","def read_logic(s, logic_parser=None, encoding=None):","def parse_logic(s, logic_parser=None, encoding=None):",KEEP REP KEEP KEEP,Rename Method
Rename process_runner methods again.,"def run_handling_errors_in_subprocess(cmd_in, cwd=None):","def run_with_out_of_process_error_handler(cmd_in, cwd=None):",KEEP REP KEEP,Rename Method
#merge branches master to develop,"def import_json_to_db(documents, jsonlist):",def import_json_to_db():,KEEP ADD REP,Add Parameter
"Fixed large error in METEOR score, see #2751 (#2763)",def _enum_align_words(,def _enum_allign_words(,KEEP REP,Rename Method
Further simplifications of the logging methods during simulation. Various bug-fixes for Brian2 simulation. Adapted MegaSim to new abstract base class for SNN output.,"def get_vmem(self, **kwargs): return np.array([np.array(v).transpose() for v in self.statemonitors[kwargs['monitor_index']].v]) ","def get_vmem(self, layer, i): return np.array([np.array(v).transpose() for v in self.statemonitors[i].v]) ",KEEP KEEP REP DEL KEEP KEEP KEEP KEEP KEEP REP,Remove Parameter
fix bug in using qubit slicing (cannot use list of list... need to iterate),"def build(self, qc, q, q_ancillas=None):  q_state = [q[i] for i in self.i_state] q_objective = q[self.i_objective]","def build(self, qc, q, q_ancillas=None, params=None):",KEEP KEEP KEEP KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP REP,Remove Parameter
Changed api,"def __new__(cls, sym, success, failure, p):","def __new__(cls, sym, p):",KEEP KEEP KEEP ADD ADD KEEP,Add Parameter
Update _object_detection.py,"def detections(num_output, metadata, deltas, proposals, scores):",def detections(num_output):,KEEP ADD ADD ADD ADD REP,Add Parameter
Refactor experiment build into ExperimentBuilder,def _execute(cmdargs): experiment = ExperimentBuilder().build_from(cmdargs),"def _execute(cmdargs, cmdconfig): experiment = _infer_experiment(cmdargs, cmdconfig)",KEEP REP DEL KEEP KEEP REP DEL,Remove Parameter
"Revert ""1 error to go""","def _select_file(self, itraj): if itraj != self._selected_itraj: self._itraj = self._selected_itraj = itraj assert self._it is not None self._it._select_file(itraj)",def _select_file(self): assert self._it is not None assert self._it._itraj == self._itraj self._it._select_file(),KEEP ADD ADD ADD ADD ADD ADD ADD ADD ADD ADD REP KEEP KEEP KEEP KEEP KEEP REP DEL DEL DEL DEL,Add Parameter
Don't pass pdepSettings around between functions when they can get it themselves.,"def updateUnimolecularReactionNetworks(self, database):","def updateUnimolecularReactionNetworks(self, database,pdepSettings):",KEEP KEEP REP,Remove Parameter
Added s3fd-amd + minor fixes (#837),"def get_queue(self, name, maxsize=0, multiprocessing_queue=True):","def get_queue(self, name, maxsize=0):",KEEP KEEP KEEP ADD REP,Add Parameter
initial average result assessment,"def status(self, notebook=False):",def status(self):,KEEP ADD REP,Add Parameter
Updating F1 measurements to work on tokens as well,"def precision(gold, pred, eval_type=EvalTypes.NODE): ccount, pcount, _ = corr_pred_gold(gold, pred, eval_type) return ccount / float(pcount)","def precision(gold_ttree, pred_ttree, eval_type=EvalTypes.NODE):  correct, predicted, _ = corr_pred_gold(gold_ttree, pred_ttree, eval_type) return correct / float(predicted)",KEEP REP REP KEEP REP REP DEL KEEP KEEP REP REP KEEP KEEP REP KEEP REP,Rename Parameter
Adapt codebase to new name Orion (#61),"def test_read_trials(self, exp_config, orion_db):","def test_read_trials(self, exp_config, moptdb):",KEEP KEEP KEEP REP,Rename Parameter
"locations for streaming, retries for fatal error","def search_tweets(self, keywords, count=100, lang='en', retries_after_twython_exception=0):","def search_tweets(self, keywords, count=100, lang='en'):",KEEP KEEP KEEP KEEP ADD REP,Add Parameter
[plots] plot cktest now can handle multiple cktests,"def _add_ck_subplot(cktest, test_index, ax, i, j, ipos=None, jpos=None, y01=True, units='steps', dt=1., **plot_kwargs):","def _add_ck_subplot(cktest, ax, i, j, ipos=None, jpos=None, y01=True, units='steps', dt=1., **plot_kwargs):",KEEP KEEP ADD KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP KEEP,Add Parameter
Mask updates,"def load_feed_face(self, image, size=64, coverage_ratio=0.625, dtype=None, is_aligned_face=False):","def load_feed_face(self, image, size=64, coverage_ratio=0.625, dtype=None):",KEEP KEEP KEEP KEEP KEEP ADD REP,Add Parameter
Update test_bleu.py,def test_corpus_bleu_with_bad_sentence(self):,def test_corpus_bleu_with_emulate_multibleu(self):,KEEP REP,Rename Method
Make rmgpy/statmech/* unit tests PEP-8 compliant,def test_get_entropy_classical(self):,def test_getEntropy_classical(self):,KEEP REP,Rename Method
Added the updated version of the megasim target sim and also added one more parameter in the settings dictionary named scaling_factor for scaling megasims parameters,"def poisson_spike_generator_megasim(self, mnist_digit):","def poisson_spike_generator_megasim_flatten(self, mnist_digit):",KEEP REP KEEP,Rename Method
Started refactoring project.,"def check_runlabel(self, p):  if self.initialized:  self.settings['log_dir_of_current_run'].set( os.path.join(self.gui_log.get(), p)) if not os.path.exists( self.settings['log_dir_of_current_run'].get()): os.makedirs(self.settings['log_dir_of_current_run'].get())  def check_dataset_path(self, p):","def check_runlabel(self, P):  if self.initialized:  self.settings['log_dir_of_current_run'].set( os.path.join(self.gui_log.get(), P)) if not os.path.exists( self.settings['log_dir_of_current_run'].get()): os.makedirs(self.settings['log_dir_of_current_run'].get()) ",KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP KEEP REP KEEP KEEP KEEP KEEP KEEP ADD ADD ADD ADD,Rename Parameter
[test-featurizer] changed test to exclude chi5 because of bug in mdtraj,def test_backbone_dihedrials_chi1(self):,def test_backbone_dihedrials_chi(self):,KEEP REP,Rename Method
remove load_classifier option from train() method,def demo_sent140(classifier_type):,def demo_sent140():,KEEP REP,Add Parameter
"Adding tools.py as main script for using tools, as well as integrating all feature requests from #255 and #278 (#298)",@staticmethod def estimate_blur(image):,"def estimate_blur(self, image):",ADD KEEP REP DEL,Remove Parameter
Flip Develop Into Master  / DexterOS 1.2 (#137),"def __init__(self, port=""SERVO1"", gpg=None, use_mutex=False):","def __init__(self, port=""SERVO1"", gpg=None):",KEEP KEEP KEEP ADD REP,Add Parameter
Turn fetch_active_trials into noncompleted,def _produce_lies(self):,def _produces_lies(self):,KEEP REP,Rename Method
Finish rv_names -> rv_mode for dit.algorithms.,"def meet(dist, rvs, rv_mode=None, int_outcomes=True):","def meet(dist, rvs, rv_names=None, int_outcomes=True):",KEEP KEEP KEEP REP KEEP,Rename Parameter
"Changed: files->fileids and filename->fileid, as documented in more detail in issue 251.","def parsed_sents(self, fileids=None, pos_in_tree=None):","def parsed_sents(self, files=None, pos_in_tree=None):",KEEP KEEP REP KEEP,Rename Parameter
